{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "YCSZsPuwLKyE",
        "2WydREVsLvK6",
        "YHP055wEL1VK",
        "ukHetAQQ6NUY",
        "SxkRJ4MZ6S8L",
        "HDHKkjY4YLuN",
        "G7S-EeUYepJP",
        "xSXMko7RMRI2"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "48d6a8976d2c41b0a4c8078e15476cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65168248f79f471ea7f77c02b27c681f",
              "IPY_MODEL_aaa742a35905491db54d60802e183d60",
              "IPY_MODEL_dd63f1fcb3304999b0114d34e9daae4b"
            ],
            "layout": "IPY_MODEL_d497d4cd4b714f50984981d47dc6f279"
          }
        },
        "65168248f79f471ea7f77c02b27c681f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5462588db9e54438931f7134b0a9683f",
            "placeholder": "​",
            "style": "IPY_MODEL_2559274361764d149887467f87f3ff27",
            "value": " 90%"
          }
        },
        "aaa742a35905491db54d60802e183d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0997af8b61c1449bae87f1d7068bf26c",
            "max": 30,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9e893d873ba4eb9bfe836c88ff0f68c",
            "value": 27
          }
        },
        "dd63f1fcb3304999b0114d34e9daae4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09b7e2e8db594819819949e3c1ad0959",
            "placeholder": "​",
            "style": "IPY_MODEL_cf5c7a672ccf420287b31399da4d5a57",
            "value": " 27/30 [11:03:35&lt;1:25:03, 1701.10s/it]"
          }
        },
        "d497d4cd4b714f50984981d47dc6f279": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5462588db9e54438931f7134b0a9683f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2559274361764d149887467f87f3ff27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0997af8b61c1449bae87f1d7068bf26c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9e893d873ba4eb9bfe836c88ff0f68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "09b7e2e8db594819819949e3c1ad0959": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf5c7a672ccf420287b31399da4d5a57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow==11.0.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2rJ4PEqOm_A",
        "outputId": "d2c537ea-4359-441f-d27c-813011df7828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow==11.0.0 in /usr/local/lib/python3.10/dist-packages (11.0.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow==11.0.0) (1.25.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PdimRXrnQHwX",
        "outputId": "a0458fc2-f326-4471-f697-69a52957f507"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.11.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXNT1D72YEzi",
        "outputId": "882ad967-423f-4a99-8b83-bb91c782528c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openml\n",
            "  Downloading openml-0.14.2.tar.gz (144 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/144.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m143.4/144.5 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting liac-arff>=2.4.0 (from openml)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict (from openml)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openml) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from openml) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from openml) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from openml) (2.0.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from openml) (1.11.4)\n",
            "Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from openml) (1.25.2)\n",
            "Collecting minio (from openml)\n",
            "  Downloading minio-7.2.5-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openml) (14.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->openml) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (3.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2024.2.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2.0.7)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (23.1.0)\n",
            "Collecting pycryptodome (from minio->openml)\n",
            "  Downloading pycryptodome-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from minio->openml) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.6)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->minio->openml) (21.2.0)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->minio->openml) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->minio->openml) (2.22)\n",
            "Building wheels for collected packages: openml, liac-arff\n",
            "  Building wheel for openml (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.14.2-py3-none-any.whl size=158699 sha256=56ead104e16bb36e0a29a5a84d4e620aad6c74b8751dfcd350fcefd6f81f9e04\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/4e/af/5e721761d86375dbca82e63cc2470019e97815bc39f11451ea\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11716 sha256=48e39110a6523f3d61a203fd307de5d911c4a9b2563f30db61cc56aa40f49541\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built openml liac-arff\n",
            "Installing collected packages: xmltodict, pycryptodome, liac-arff, minio, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.2.5 openml-0.14.2 pycryptodome-3.20.0 xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install category_encoders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-zMSRztLTDw",
        "outputId": "60a9b3e9-78ff-47d3-daad-e23e06df01f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/81.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.1)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.0.3)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.4.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.0)\n",
            "Installing collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import pandas as pd\n",
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import SelectKBest, SelectFromModel, GenericUnivariateSelect\n",
        "from sklearn.feature_selection import chi2, mutual_info_classif\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import linear_model, metrics, model_selection, svm, neighbors, preprocessing, datasets, pipeline, ensemble\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.covariance import empirical_covariance\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.datasets import load_breast_cancer, fetch_openml\n",
        "from IPython.display import display\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn import compose\n",
        "import warnings\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.covariance import empirical_covariance\n",
        "from sklearn. preprocessing import normalize\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.model_selection import KFold\n",
        "import sklearn.feature_selection as fs\n",
        "from sklearn.datasets import load_diabetes, make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.covariance import empirical_covariance\n",
        "from sklearn. preprocessing import normalize\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.utils import resample\n",
        "%pylab inline\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_diabetes, make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.svm import SVC\n",
        "from lightgbm import LGBMClassifier, LGBMRegressor\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from itertools import combinations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOcRofHstIOY",
        "outputId": "557d4071-fc4d-437a-fc40-b2ded2817583"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Кодирование признаков"
      ],
      "metadata": {
        "id": "YCSZsPuwLKyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import sklearn.preprocessing as skpr\n",
        "import category_encoders as ce\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import copy\n",
        "import math\n",
        "\n",
        "\n",
        "class CircularEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, limits=None, fit_replace=True, tol=1e-8):\n",
        "        self.limits = limits\n",
        "        self.fit_replace = fit_replace\n",
        "        self.tol = tol\n",
        "        self._shape = (0, 0)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"Circular Encoder\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Circular Encoder\"\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        # Shape setting\n",
        "        self._shape = self.__set_shape(X)\n",
        "\n",
        "        # Defining limit\n",
        "        if self.fit_replace:\n",
        "            self.limits = self.__set_limits(X)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        if self.limits is None:\n",
        "            return copy.deepcopy(X)\n",
        "\n",
        "        # column_names only for DataFrame\n",
        "        column_names = None\n",
        "\n",
        "        # cast to numpy array\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X_ndarray = X.to_numpy().reshape(self._shape)\n",
        "            column_names = np.zeros(2 * X.columns.shape[0], dtype=object)\n",
        "        else:\n",
        "            X_ndarray = X.reshape(self._shape)\n",
        "\n",
        "        # main encoding\n",
        "        result_sin = np.sin((2 * np.pi * X_ndarray) / self.limits)\n",
        "        result_cos = np.cos((2 * np.pi * X_ndarray) / self.limits)\n",
        "\n",
        "        result_sin[np.abs(result_sin) < self.tol] = 0.0\n",
        "        result_cos[np.abs(result_cos) < self.tol] = 0.0\n",
        "\n",
        "        # combine encoded arrays\n",
        "        result = np.zeros((self._shape[0], self._shape[1] * 2))\n",
        "        result[:, np.arange(0, result.shape[1], 2)] = result_sin\n",
        "        result[:, np.arange(1, result.shape[1], 2)] = result_cos\n",
        "\n",
        "        # set column_names names and return result\n",
        "        if column_names is not None:\n",
        "            column_names[np.arange(0, result.shape[1], 2)] = np.array([f'sin_{col}' for col in X.columns])\n",
        "            column_names[np.arange(1, result.shape[1], 2)] = np.array([f'cos_{col}' for col in X.columns])\n",
        "            return pd.DataFrame(result, columns=column_names).infer_objects()\n",
        "        else:\n",
        "            return result\n",
        "\n",
        "    @staticmethod\n",
        "    def __set_shape(X):\n",
        "        if len(X.shape) == 1:\n",
        "            return (X.shape[0], 1)\n",
        "        elif len(X.shape) > 2:\n",
        "            raise ValueError(f\"You need 2 dimensions instead of {len(X.shape)}\")\n",
        "        else:\n",
        "            return X.shape\n",
        "\n",
        "    @staticmethod\n",
        "    def __set_limits(X):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            return np.max(np.abs(X.to_numpy()), axis=0) + 1\n",
        "        else:\n",
        "            return np.max(np.abs(X), axis=0) + 1\n",
        "\n",
        "\n",
        "class DateTimeEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None, fit_replace=False,\n",
        "                 drop=True, min_rescale=False, fast_mode=True,\n",
        "                 confidence_level=0.99, worst_proportion=0.01):\n",
        "        self.cols = np.array(cols) if cols is not None else None\n",
        "        self.fit_replace = fit_replace\n",
        "        self.drop = drop\n",
        "        self.min_rescale = min_rescale\n",
        "\n",
        "        # stochastic approach\n",
        "        eps = 1e-6\n",
        "        confidence_level = max(eps, min(confidence_level, 1 - eps))\n",
        "        worst_proportion = max(eps, min(worst_proportion, 1 - eps))\n",
        "        self.fast_random_size = math.ceil(math.log(1 - confidence_level) / math.log(1 - worst_proportion))\n",
        "        self.fast_mode = fast_mode\n",
        "\n",
        "        # encoders for months, days and hours\n",
        "        self.encoders = {'months': CircularEncoder(limits=[12], fit_replace=False),\n",
        "                         'days': CircularEncoder(limits=[30], fit_replace=False),\n",
        "                         'hours': CircularEncoder(limits=[24], fit_replace=False)}\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"DateTimeEncoder\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"DateTimeEncoder\"\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if self.cols is None or self.fit_replace:\n",
        "            if self.fast_mode and self.fast_random_size < X.shape[0]:\n",
        "                self.cols = self.define_cols_fast(X)\n",
        "            else:\n",
        "                self.cols = self.define_cols(X)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        try:\n",
        "            if self.cols is None or not self.cols.shape[0]:\n",
        "                return copy.deepcopy(X)\n",
        "        except IndexError:\n",
        "            raise IndexError(\"cols should be a numpy array\")\n",
        "\n",
        "        # save self.cols and get indices for X\n",
        "        saved_cols = self.cols.copy()\n",
        "        self.cols = self.cols_to_numeric(X)\n",
        "\n",
        "        if not self.cols.shape[0]:\n",
        "            self.cols = saved_cols\n",
        "            return copy.deepcopy(X)\n",
        "\n",
        "        column_names = None\n",
        "\n",
        "        # cast to pandas DataFrame\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            column_names = X.columns.to_numpy(dtype=object).copy()\n",
        "            X_df = X\n",
        "        else:\n",
        "            X_df = pd.DataFrame(X)\n",
        "\n",
        "        # shift for dropping columns\n",
        "        shift = 0 if self.drop else 1\n",
        "\n",
        "        # creating an empty result matrix\n",
        "        result = np.zeros((X_df.shape[0], X_df.shape[1] + (6 + shift) * len(self.cols)), dtype=object)\n",
        "        column_names_zeros = np.zeros(X_df.shape[1] + (6 + shift) * len(self.cols), dtype=object)\n",
        "\n",
        "        # creating indices for fast numpy operation\n",
        "        modified_inds = np.array([self.cols[i] + i * (6 + shift) for i in range(len(self.cols))])\n",
        "        not_cols = list(set(np.arange(X.shape[1])) - set(self.cols))\n",
        "        unmodified_inds = np.array([i + (7 + shift) * (not_cols[i] - i) for i in range(len(not_cols))])\n",
        "\n",
        "        # setting not date columns\n",
        "        if unmodified_inds.shape[0] > 0:\n",
        "            result[:, unmodified_inds] = X_df.to_numpy()[:, not_cols]\n",
        "            if not self.drop:\n",
        "                result[:, modified_inds] = X_df.to_numpy()[:, self.cols]\n",
        "            if column_names is not None:\n",
        "                column_names_zeros[unmodified_inds] = column_names[not_cols]\n",
        "                if not self.drop:\n",
        "                    column_names_zeros[modified_inds] = column_names[self.cols]\n",
        "\n",
        "        # for fast mode\n",
        "        preventive_delete = []\n",
        "\n",
        "        # tranform each datetime column\n",
        "        for num, col in enumerate(self.cols):\n",
        "            transformed_column = self.column_transform(X_df.iloc[:, col])\n",
        "            # for fast mode\n",
        "            if transformed_column is None:\n",
        "                result[:, modified_inds[num] + 6 + shift] = X_df.iloc[:, col]\n",
        "                column_names_zeros[modified_inds[num] + 6 + shift] = X_df.iloc[:, col].name\n",
        "                preventive_delete += list(np.arange(modified_inds[num] + shift, modified_inds[num] + 6 + shift))\n",
        "                continue\n",
        "            result[:, np.arange(modified_inds[num] + shift, modified_inds[num] + 7 + shift)] = transformed_column.to_numpy()\n",
        "            column_names_zeros[np.arange(modified_inds[num] + shift, modified_inds[num] + 7 + shift)] = transformed_column.columns.to_numpy(dtype=object).copy()\n",
        "\n",
        "        # delete unsuccessful transformations\n",
        "        if len(preventive_delete) > 0:\n",
        "            result = np.delete(result, preventive_delete, 1)\n",
        "            column_names_zeros = np.delete(column_names_zeros, preventive_delete)\n",
        "\n",
        "        # self.cols backup\n",
        "        self.cols = saved_cols\n",
        "\n",
        "        if column_names is not None:\n",
        "            # saving dtypes\n",
        "            saved_dtypes = X_df.dtypes.to_dict()\n",
        "            unmodified_dtypes = dict([(X.columns[col], saved_dtypes[X.columns[col]]) for col in not_cols])\n",
        "\n",
        "            return pd.DataFrame(result, columns=column_names_zeros).infer_objects().astype(dtype=unmodified_dtypes)\n",
        "        else:\n",
        "            return result\n",
        "\n",
        "    def column_transform(self, column):\n",
        "        column_name = None\n",
        "\n",
        "        # cast to pandas Series\n",
        "        if not isinstance(column, pd.Series):\n",
        "            pd_column = copy.deepcopy(pd.Series(column))\n",
        "        else:\n",
        "            pd_column = copy.deepcopy(column)\n",
        "            column_name = column.name\n",
        "\n",
        "        try:\n",
        "            pd_column = pd.to_datetime(pd_column.astype(str))\n",
        "        except (ValueError, TypeError):\n",
        "            return None\n",
        "\n",
        "        # rescaling by the start time\n",
        "        if self.min_rescale:\n",
        "            pd_column = pd_column.astype(int)\n",
        "            min_seconds = pd_column.min()\n",
        "            pd_column = pd_column.apply(lambda val: val - min_seconds)\n",
        "            pd_column = pd.to_datetime(pd_column)\n",
        "\n",
        "        # defining main columns\n",
        "        years = pd_column.dt.year.to_numpy()\n",
        "        months = self.encoders['months'].fit_transform(pd_column.dt.month.to_numpy())\n",
        "        days = self.encoders['days'].fit_transform(pd_column.dt.day.to_numpy())\n",
        "        hours = self.encoders['hours'].fit_transform(pd_column.dt.hour.to_numpy())\n",
        "        result = np.array([years, months.T[0], months.T[1], days.T[0],\n",
        "                           days.T[1], hours.T[0], hours.T[1]]).T\n",
        "\n",
        "        # cast to the original type\n",
        "        if column_name is not None:\n",
        "            column_names = np.array([f'{column_name}_year', f'{column_name}_month_sin',\n",
        "                                     f'{column_name}_month_cos', f'{column_name}_day_sin',\n",
        "                                     f'{column_name}_day_cos', f'{column_name}_hour_sin',\n",
        "                                     f'{column_name}_hour_cos'])\n",
        "            result = pd.DataFrame(result, columns=column_names).infer_objects()\n",
        "\n",
        "        return result\n",
        "\n",
        "    def cols_to_numeric(self, X):\n",
        "        if self.cols is None or not self.cols.shape[0]:\n",
        "            return np.array([])\n",
        "\n",
        "        inds = self.cols.copy()\n",
        "\n",
        "        try:\n",
        "            inds = inds.astype(int)\n",
        "            return inds\n",
        "        except (ValueError, TypeError):\n",
        "            if not isinstance(X, pd.DataFrame):\n",
        "                return np.array([])\n",
        "            else:\n",
        "                columns_array = X.columns.to_numpy(dtype=object).copy()\n",
        "                names_dict = dict((columns_array[i], i) for i in range(columns_array.shape[0]))\n",
        "                inds = np.array([names_dict[name] for name in inds if name in names_dict])\n",
        "                return inds\n",
        "\n",
        "    def define_cols(self, X):\n",
        "        # cast to pandas DataFrame\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X_df = X\n",
        "        else:\n",
        "            X_df = pd.DataFrame(X)\n",
        "\n",
        "        # check all the columns\n",
        "        datetime_cols = []\n",
        "        for num, col in enumerate(X_df):\n",
        "            if not pd.api.types.is_categorical_dtype(X_df[col]) and not pd.api.types.is_numeric_dtype(X_df[col]):\n",
        "                if self.is_datetime(X_df[col].iloc[np.random.randint(0, X_df.shape[0])]):\n",
        "                    datetime_cols.append(num)\n",
        "        return np.array(datetime_cols)\n",
        "\n",
        "    def define_cols_fast(self, X):\n",
        "        # cast to pandas DataFrame\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X_df = X\n",
        "        else:\n",
        "            X_df = pd.DataFrame(X)\n",
        "\n",
        "        # check all the columns\n",
        "        datetime_cols = []\n",
        "        for num, col in enumerate(X_df):\n",
        "            if not pd.api.types.is_categorical_dtype(X_df[col]) and not pd.api.types.is_numeric_dtype(X_df[col]):\n",
        "                append_need = True\n",
        "                for i in range(self.fast_random_size):\n",
        "                    if not self.is_datetime(X_df[col].iloc[np.random.randint(0, X_df.shape[0])]):\n",
        "                        append_need = False\n",
        "                        break\n",
        "                if append_need:\n",
        "                    datetime_cols.append(num)\n",
        "        return np.array(datetime_cols)\n",
        "\n",
        "    def get_cols(self):\n",
        "        if self.cols is not None:\n",
        "            return self.cols.copy()\n",
        "        else:\n",
        "            return np.array([])\n",
        "\n",
        "    def is_datetime(self, col):\n",
        "        arg = None\n",
        "        if not isinstance(col, pd.Series):\n",
        "            arg = col\n",
        "        else:\n",
        "            arg = col.astype(str)\n",
        "\n",
        "        try:\n",
        "            pd.to_datetime(arg, errors='raise')\n",
        "            return True\n",
        "        except (ValueError, TypeError):\n",
        "            return False\n",
        "\n",
        "\n",
        "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None, fit_replace=False, encoder='binary',\n",
        "                 category_rate=0.1, rated_search=True, fast_mode=True,\n",
        "                 confidence_level=0.99, worst_proportion=0.01, **encoder_params):\n",
        "\n",
        "        self._hashing_enc_name = 'hashing'\n",
        "        self._encoders_list = {'onehot': ce.OneHotEncoder,\n",
        "                               'target_loo': ce.LeaveOneOutEncoder,\n",
        "                               self._hashing_enc_name: ce.HashingEncoder,\n",
        "                               'binary': ce.BinaryEncoder}\n",
        "        self._target_encoders_list = np.array(['target_loo'])\n",
        "\n",
        "        # stochastic approach\n",
        "        eps = 1e-6\n",
        "        confidence_level = max(eps, min(confidence_level, 1 - eps))\n",
        "        worst_proportion = max(eps, min(worst_proportion, 1 - eps))\n",
        "        self.fast_random_size = math.ceil(math.log(1 - confidence_level) / math.log(1 - worst_proportion))\n",
        "        self.fast_mode = fast_mode\n",
        "\n",
        "        self.cols = np.array(cols) if cols is not None else None\n",
        "        self.fit_replace = fit_replace\n",
        "        self.encoder_name = encoder\n",
        "        self.category_rate = category_rate\n",
        "        self.rated_search = rated_search\n",
        "        self.encoder_params = encoder_params\n",
        "        self._encoder = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"CategoricalEncoder\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"CategoricalEncoder\"\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        # defining categorical columns\n",
        "        if self.cols is None or self.fit_replace:\n",
        "            self.cols = self.define_cols(X)\n",
        "\n",
        "        try:\n",
        "            if not self.cols.shape[0]:\n",
        "                return self\n",
        "        except IndexError:\n",
        "            raise IndexError(\"cols should be a numpy array\")\n",
        "\n",
        "        # save self.cols and get indices for X\n",
        "        saved_cols = self.cols.copy()\n",
        "        self.cols = self.cols_to_numeric(X)\n",
        "\n",
        "        if not self.cols.shape[0]:\n",
        "            self.cols = saved_cols\n",
        "            return self\n",
        "\n",
        "        # defining the encoder\n",
        "        self.encoder_params['cols'] = X.columns[self.cols] if isinstance(X, pd.DataFrame) else self.cols\n",
        "        self._encoder = self._encoders_list[self.encoder_name](**self.encoder_params)\n",
        "\n",
        "        # transforming y if it's not numeric\n",
        "        y_copy = None\n",
        "\n",
        "        if y is not None:\n",
        "            y_copy = copy.deepcopy(y)\n",
        "            if not self.is_y_approved(y_copy):\n",
        "                y_copy = skpr.LabelEncoder().fit_transform(y_copy)\n",
        "\n",
        "        # fitting the encoder\n",
        "        self._encoder.fit(pd.DataFrame(X), y_copy, **fit_params)\n",
        "\n",
        "        # self.cols backup\n",
        "        self.cols = saved_cols\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        try:\n",
        "            if self.cols is None or not self.cols.shape[0] or self._encoder is None:\n",
        "                return copy.deepcopy(X)\n",
        "        except IndexError:\n",
        "            raise IndexError(\"cols should be a numpy array\")\n",
        "\n",
        "        # save self.cols and get indices for X\n",
        "        saved_cols = self.cols.copy()\n",
        "        self.cols = self.cols_to_numeric(X)\n",
        "\n",
        "        if not self.cols.shape[0]:\n",
        "            self.cols = saved_cols\n",
        "            return copy.deepcopy(X)\n",
        "\n",
        "        # transforming y if it's not numeric\n",
        "        y_copy = None\n",
        "\n",
        "        if y is not None:\n",
        "            y_copy = copy.deepcopy(y)\n",
        "            if not self.is_y_approved(y_copy):\n",
        "                y_copy = skpr.LabelEncoder().fit_transform(y_copy)\n",
        "\n",
        "        # checking whether it's a target encoder or not\n",
        "        if self.encoder_name in self._target_encoders_list:\n",
        "            result = self._encoder.transform(pd.DataFrame(X), y_copy, override_return_df=True)\n",
        "        else:\n",
        "            result = self._encoder.transform(pd.DataFrame(X), override_return_df=True)\n",
        "\n",
        "        # adjusting the column names\n",
        "        cols_before = self._encoder.get_feature_names_in()\n",
        "        cols_after = self._encoder.get_feature_names_out()\n",
        "        new_columns = self._rename_transformed_cols(cols_before, cols_after)\n",
        "\n",
        "        result = result.rename(columns={cols_after[i]: new_columns[i] for i in range(cols_after.shape[0])})\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # saving X dtypes\n",
        "            not_cols = list(set(np.arange(X.shape[1])) - set(self.cols))\n",
        "            saved_dtypes = X.dtypes.to_dict()\n",
        "            unmodified_dtypes = dict([(X.columns[col], saved_dtypes[X.columns[col]]) for col in not_cols])\n",
        "\n",
        "            # self.cols backup\n",
        "            self.cols = saved_cols\n",
        "\n",
        "            return result.astype(dtype=unmodified_dtypes)\n",
        "        else:\n",
        "            # self.cols backup\n",
        "            self.cols = saved_cols\n",
        "\n",
        "            return result.to_numpy()\n",
        "\n",
        "    def fit_transform(self, X, y=None, **fit_params):\n",
        "        # transforming y if it's not numeric\n",
        "        y_copy = None\n",
        "\n",
        "        if y is not None:\n",
        "            y_copy = copy.deepcopy(y)\n",
        "            if not self.is_y_approved(y_copy):\n",
        "                y_copy = skpr.LabelEncoder().fit_transform(y_copy)\n",
        "\n",
        "        self.fit(X, y_copy, **fit_params)\n",
        "        return self.transform(X, y_copy)\n",
        "\n",
        "    def _rename_transformed_cols(self, before, after):\n",
        "        if after is None:\n",
        "            return np.array([])\n",
        "        if self._encoder is None:\n",
        "            return copy.deepcopy(after)\n",
        "\n",
        "        result = copy.deepcopy(after)\n",
        "\n",
        "        # hashing encoder unique renaming\n",
        "        if self.encoder_name == self._hashing_enc_name:\n",
        "            for i in range(self._encoder.n_components):\n",
        "                result[i] = f'{self._hashing_enc_name}_{i}'\n",
        "        else:\n",
        "            # getting the columns transformed\n",
        "            set_before = set(before)\n",
        "            set_after = set(after)\n",
        "            sample_names = set_before.intersection(set_after)\n",
        "\n",
        "            # checking whether set is not empty\n",
        "            if bool(sample_names):\n",
        "                # renaming\n",
        "                for num, col in enumerate(result):\n",
        "                    if col not in sample_names:\n",
        "                        result[num] = f'{self.encoder_name}_{result[num]}'\n",
        "\n",
        "        return result\n",
        "\n",
        "    def is_y_approved(self, y):\n",
        "        try:\n",
        "            y.astype(float)\n",
        "            return True\n",
        "        except (ValueError, TypeError):\n",
        "            return False\n",
        "\n",
        "    def cols_to_numeric(self, X):\n",
        "        if self.cols is None or not self.cols.shape[0]:\n",
        "            return np.array([])\n",
        "\n",
        "        inds = self.cols.copy()\n",
        "\n",
        "        try:\n",
        "            inds = inds.astype(int)\n",
        "            return inds\n",
        "        except (ValueError, TypeError):\n",
        "            if not isinstance(X, pd.DataFrame):\n",
        "                return np.array([])\n",
        "            else:\n",
        "                columns_array = X.columns.to_numpy(dtype=object).copy()\n",
        "                names_dict = dict((columns_array[i], i) for i in range(columns_array.shape[0]))\n",
        "                inds = np.array([names_dict[name] for name in inds if name in names_dict])\n",
        "                return inds\n",
        "\n",
        "    def define_cols(self, X):\n",
        "        # cast to pandas DataFrame with inferring object types\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X_df = pd.DataFrame(X).infer_objects()\n",
        "        else:\n",
        "            X_df = X.infer_objects()\n",
        "\n",
        "        # check all the columns\n",
        "        category_cols = []\n",
        "        for num, col in enumerate(X_df):\n",
        "            # if dtype is 'category'\n",
        "            if pd.api.types.is_categorical_dtype(X_df[col]):\n",
        "                category_cols.append(num)\n",
        "            # checking object type (strings)\n",
        "            elif pd.api.types.is_object_dtype(X_df[col]):\n",
        "                # stochastic approach\n",
        "                if self.fast_mode:\n",
        "                    append_need = True\n",
        "                    for i in range(self.fast_random_size):\n",
        "                        if not self.is_one_word(X_df[col].iloc[np.random.randint(0, X_df.shape[0])]):\n",
        "                            append_need = False\n",
        "                            break\n",
        "                    if append_need:\n",
        "                        category_cols.append(num)\n",
        "                else:\n",
        "                    # basic approach\n",
        "                    if np.all(np.vectorize(self.is_one_word)(X_df[col])):\n",
        "                        category_cols.append(num)\n",
        "            # checking numeric columns\n",
        "            elif self.rated_search and pd.api.types.is_numeric_dtype(X_df[col]) and not pd.api.types.is_float_dtype(X_df[col]):\n",
        "                if X_df[col].nunique() < self.category_rate * X_df.shape[0]:\n",
        "                    category_cols.append(num)\n",
        "        return np.array(category_cols)\n",
        "\n",
        "    def is_one_word(self, s):\n",
        "        if s is None or not isinstance(s, str):\n",
        "            return False\n",
        "\n",
        "        stripped_string = s.strip()\n",
        "        if not stripped_string or ' ' in stripped_string:\n",
        "            return False\n",
        "        else:\n",
        "            return True\n",
        "\n",
        "    def get_cols(self):\n",
        "        if self.cols is not None:\n",
        "            return self.cols.copy()\n",
        "        else:\n",
        "            return np.array([])\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder_name\n",
        "\n",
        "    def get_available_encoders(self):\n",
        "        return np.array(list(self._encoders_list.keys()))\n",
        "\n",
        "\n",
        "class NumericalEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, cols=None, fit_replace=False, encoder='standard', numeric_rate=0.1,\n",
        "                 rated_search=True, only_float=True, **encoder_params):\n",
        "\n",
        "        self._encoders_list = {'standard': skpr.StandardScaler,\n",
        "                          'min_max': skpr.MinMaxScaler,\n",
        "                          'normalizer': skpr.Normalizer,\n",
        "                          'max_abs': skpr.MaxAbsScaler}\n",
        "\n",
        "        self.only_float = only_float\n",
        "        self.cols = np.array(cols) if cols is not None else None\n",
        "        self.fit_replace = fit_replace\n",
        "        self.encoder_name = encoder\n",
        "        self.numeric_rate = numeric_rate\n",
        "        self.rated_search = rated_search\n",
        "        self.encoder_params = encoder_params\n",
        "        self._encoder = None\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"NumericalEncoder\"\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"NumericalEncoder\"\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        # defining numerical columns\n",
        "        if self.cols is None or self.fit_replace:\n",
        "            self.cols = self.define_cols(X)\n",
        "\n",
        "        try:\n",
        "            if not self.cols.shape[0]:\n",
        "                return self\n",
        "        except IndexError:\n",
        "            raise IndexError(\"cols should be a numpy array\")\n",
        "\n",
        "        # save self.cols and get indices for X\n",
        "        saved_cols = self.cols.copy()\n",
        "        self.cols = self.cols_to_numeric(X)\n",
        "\n",
        "        if not self.cols.shape[0]:\n",
        "            self.cols = saved_cols\n",
        "            return self\n",
        "\n",
        "        # defining the encoder\n",
        "        self._encoder = self._encoders_list[self.encoder_name](**self.encoder_params)\n",
        "\n",
        "        # fitting the encoder\n",
        "        X_ndarray = X.to_numpy()[:, self.cols] if isinstance(X, pd.DataFrame) else X[:, self.cols]\n",
        "        self._encoder.fit(X_ndarray, y, **fit_params)\n",
        "\n",
        "        # self.cols backup\n",
        "        self.cols = saved_cols\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        try:\n",
        "            if self.cols is None or not self.cols.shape[0] or self._encoder is None:\n",
        "                return copy.deepcopy(X)\n",
        "        except IndexError:\n",
        "            raise IndexError(\"cols should be a numpy array\")\n",
        "\n",
        "        # save self.cols and get indices for X\n",
        "        saved_cols = self.cols.copy()\n",
        "        self.cols = self.cols_to_numeric(X)\n",
        "\n",
        "        if not self.cols.shape[0]:\n",
        "            self.cols = saved_cols\n",
        "            return copy.deepcopy(X)\n",
        "\n",
        "        column_names = None\n",
        "\n",
        "        # cast to numpy array\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X_ndarray = X.iloc[:, self.cols].to_numpy().astype(float)\n",
        "            column_names = X.columns.to_numpy(dtype=object).copy()\n",
        "        else:\n",
        "            X_ndarray = X[:, self.cols].astype(float)\n",
        "\n",
        "        # getting the resulting column names\n",
        "        if column_names is not None:\n",
        "            column_names[self.cols] = np.array([f'{self.encoder_name}_{name}' for name in column_names[self.cols]])\n",
        "\n",
        "        # only numerical columns here\n",
        "        result = self._encoder.transform(X_ndarray)\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            # saving X dtypes\n",
        "            not_cols = list(set(np.arange(X.shape[1])) - set(self.cols))\n",
        "            saved_dtypes = X.dtypes.to_dict()\n",
        "            unmodified_dtypes = dict([(X.columns[col], saved_dtypes[X.columns[col]]) for col in not_cols])\n",
        "\n",
        "            X_ndarray = copy.deepcopy(X.to_numpy(dtype=object))\n",
        "            X_ndarray[:, self.cols] = result\n",
        "            result = pd.DataFrame(X_ndarray, columns=column_names).astype(dtype=unmodified_dtypes).infer_objects()\n",
        "        else:\n",
        "            X_ndarray = copy.deepcopy(X)\n",
        "            X_ndarray[:, self.cols] = result\n",
        "            result = X_ndarray\n",
        "\n",
        "        # self.cols backup\n",
        "        self.cols = saved_cols\n",
        "\n",
        "        return result\n",
        "\n",
        "    def define_cols(self, X):\n",
        "        # cast to pandas DataFrame with inferring object types\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X_df = pd.DataFrame(X).infer_objects()\n",
        "        else:\n",
        "            X_df = X.infer_objects()\n",
        "\n",
        "        # check all the columns\n",
        "        numeric_cols = []\n",
        "        for num, col in enumerate(X_df):\n",
        "            # if dtype is 'numeric'\n",
        "            if pd.api.types.is_numeric_dtype(X_df[col]):\n",
        "                # appending if float\n",
        "                if pd.api.types.is_float_dtype(X_df[col]):\n",
        "                    numeric_cols.append(num)\n",
        "                elif not self.only_float:\n",
        "                    # checking rated_search\n",
        "                    if self.rated_search:\n",
        "                        if X_df[col].nunique() >= self.numeric_rate * X_df.shape[0]:\n",
        "                            numeric_cols.append(num)\n",
        "                    else:\n",
        "                        numeric_cols.append(num)\n",
        "        return np.array(numeric_cols)\n",
        "\n",
        "    def cols_to_numeric(self, X):\n",
        "        if self.cols is None or not self.cols.shape[0]:\n",
        "            return np.array([])\n",
        "\n",
        "        inds = self.cols.copy()\n",
        "\n",
        "        try:\n",
        "            inds = inds.astype(int)\n",
        "            return inds\n",
        "        except (ValueError, TypeError):\n",
        "            if not isinstance(X, pd.DataFrame):\n",
        "                return np.array([])\n",
        "            else:\n",
        "                columns_array = X.columns.to_numpy(dtype=object).copy()\n",
        "                names_dict = dict((columns_array[i], i) for i in range(columns_array.shape[0]))\n",
        "                inds = np.array([names_dict[name] for name in inds if name in names_dict])\n",
        "                return inds\n",
        "\n",
        "    def get_cols(self):\n",
        "        if self.cols is not None:\n",
        "            return self.cols.copy()\n",
        "        else:\n",
        "            return np.array([])\n",
        "\n",
        "    def get_encoder(self):\n",
        "        return self.encoder_name\n",
        "\n",
        "    def get_available_encoders(self):\n",
        "        return np.array(list(self._encoders_list.keys()))\n",
        "\n",
        "\n",
        "class CustomEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, categorical_args=None,\n",
        "                 numerical_args=None, datetime_args=None, categorical_enabled=True,\n",
        "                 numerical_enabled=True, datetime_enabled=True, target_encoder='label',\n",
        "                 target_encoding=False):\n",
        "        self.target_encoder = target_encoder\n",
        "        self.target_encoding = target_encoding\n",
        "        self._target_encoders_list = {'label': skpr.LabelEncoder}\n",
        "\n",
        "        self.categorical_args = categorical_args if categorical_args is not None else dict()\n",
        "        self.numerical_args = numerical_args if numerical_args is not None else dict()\n",
        "        self.datetime_args = datetime_args if datetime_args is not None else dict()\n",
        "        self.categorical_enc = CategoricalEncoder(**self.categorical_args)\n",
        "        self.numerical_enc = NumericalEncoder(**self.numerical_args)\n",
        "        self.datetime_enc = DateTimeEncoder(**self.datetime_args)\n",
        "\n",
        "        self.categorical_enabled = categorical_enabled\n",
        "        self.numerical_enabled = numerical_enabled\n",
        "        self.datetime_enabled = datetime_enabled\n",
        "\n",
        "    def fit(self, X, y=None, **fit_params):\n",
        "        if self.categorical_enabled:\n",
        "            self.categorical_enc.fit(X, y, **fit_params)\n",
        "\n",
        "        if self.numerical_enabled:\n",
        "            self.numerical_enc.fit(X, y, **fit_params)\n",
        "\n",
        "        if self.datetime_enabled:\n",
        "            self.datetime_enc.fit(X, y, **fit_params)\n",
        "\n",
        "        cat_cols = self.cols_to_numeric(X, self.categorical_enc.get_cols())\n",
        "        num_cols = self.cols_to_numeric(X, self.numerical_enc.get_cols())\n",
        "        dt_cols = self.cols_to_numeric(X, self.datetime_enc.get_cols())\n",
        "\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X_columns = X.columns.to_numpy(dtype=object).copy()\n",
        "            self.categorical_enc.cols = X_columns[cat_cols] if len(cat_cols) > 0 else np.array([])\n",
        "            self.numerical_enc.cols = X_columns[num_cols] if len(num_cols) > 0 else np.array([])\n",
        "            self.datetime_enc.cols = X_columns[dt_cols] if len(dt_cols) > 0 else np.array([])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        # target encoding\n",
        "        y_copy = None\n",
        "        if y is not None:\n",
        "            X_result, y_copy = self.fill_omissions(X, y)\n",
        "            if self.target_encoding:\n",
        "                if self.target_encoder in self._target_encoders_list:\n",
        "                    y_copy = self._target_encoders_list[self.target_encoder].fit_transform(y_copy)\n",
        "                else:\n",
        "                    y_copy = skpr.LabelEncoder().fit_transform(y_copy)\n",
        "        else:\n",
        "            X_result = self.fill_omissions(X)\n",
        "\n",
        "        # main encoding\n",
        "        if not isinstance(X_result, pd.DataFrame):\n",
        "            X_result = pd.DataFrame(X_result)\n",
        "\n",
        "        if self.numerical_enabled:\n",
        "            X_result = self.numerical_enc.transform(X_result, y_copy)\n",
        "\n",
        "        if self.categorical_enabled:\n",
        "            X_result = self.categorical_enc.transform(X_result, y_copy)\n",
        "\n",
        "        if self.datetime_enabled:\n",
        "            X_result = self.datetime_enc.transform(X_result, y_copy)\n",
        "\n",
        "        if not isinstance(X, pd.DataFrame):\n",
        "            X_result = X_result.to_numpy()\n",
        "\n",
        "        # getting the result\n",
        "        if self.target_encoding:\n",
        "            return X_result, y_copy\n",
        "        else:\n",
        "            return X_result\n",
        "\n",
        "    def fill_omissions(self, X, y=None):\n",
        "        if y is not None:\n",
        "            return copy.deepcopy(X), copy.deepcopy(y)\n",
        "        else:\n",
        "            return copy.deepcopy(X)\n",
        "\n",
        "    def print_cols(self):\n",
        "        print('Categorical columns: ', sep=', ', end='')\n",
        "        print(*self.categorical_enc.get_cols(), sep=', ')\n",
        "        print('Numerical columns: ', sep=', ', end='')\n",
        "        print(*self.numerical_enc.get_cols(), sep=', ')\n",
        "        print('Datetime columns: ', sep=', ', end='')\n",
        "        print(*self.datetime_enc.get_cols(), sep=', ')\n",
        "\n",
        "    def cols_to_numeric(self, X, cols):\n",
        "        if cols is None or not cols.shape[0]:\n",
        "            return np.array([])\n",
        "\n",
        "        inds = cols.copy()\n",
        "\n",
        "        try:\n",
        "            inds = inds.astype(int)\n",
        "            return inds\n",
        "        except (ValueError, TypeError):\n",
        "            if not isinstance(X, pd.DataFrame):\n",
        "                return np.array([])\n",
        "            else:\n",
        "                columns_array = X.columns.to_numpy(dtype=object).copy()\n",
        "                names_dict = dict((columns_array[i], i) for i in range(columns_array.shape[0]))\n",
        "                inds = np.array([names_dict[name] for name in inds if name in names_dict])\n",
        "                return inds\n",
        "\n",
        "    def get_cols(self):\n",
        "        return {'categorical': self.categorical_enc.get_cols(),\n",
        "                'numerical': self.numerical_enc.get_cols(),\n",
        "                'datetime': self.datetime_enc.get_cols()}"
      ],
      "metadata": {
        "id": "hsBmAT8uLJLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Отбор признаков"
      ],
      "metadata": {
        "id": "82JYdo1MKto6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SelectNullDistributionBaseline(BaseEstimator, TransformerMixin):\n",
        "  def __get_feature_importances(s, X, y, shuffle, seed=None):\n",
        "    f_num = X.shape[1]\n",
        "    if shuffle:\n",
        "        np.random.shuffle(y)\n",
        "\n",
        "    #TODO hardcode\n",
        "    dtrain = lgb.Dataset(X, y,params={'verbose': -1}, free_raw_data=False)\n",
        "    lgb_params = {\n",
        "        'objective': 'binary',\n",
        "        'boosting_type': 'rf',\n",
        "        'subsample': 0.623,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'num_leaves': 127,\n",
        "        'max_depth': 8,\n",
        "        'seed': seed,\n",
        "        'bagging_freq': 1,\n",
        "        'n_jobs': 4,\n",
        "        'verbose': -1\n",
        "    }\n",
        "    categorical_feats = []\n",
        "    # Fit the model\n",
        "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=200, categorical_feature=categorical_feats)\n",
        "\n",
        "    # Get feature importances\n",
        "    imp_df = pd.DataFrame()\n",
        "    imp_df[\"feature\"] = np.arange(f_num)\n",
        "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
        "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type='split')\n",
        "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(X))\n",
        "\n",
        "    return imp_df\n",
        "\n",
        "  def __get_null_feature_importances(s, X, y):\n",
        "    null_imp_df = pd.DataFrame()\n",
        "    dsp = ''\n",
        "    for i in range(s.n_runs):\n",
        "        X_train, y_train = resample(X, y)\n",
        "        imp_df = s.__get_feature_importances(X_train, y_train, shuffle=True)\n",
        "        imp_df['run'] = i + 1\n",
        "        null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n",
        "    return null_imp_df\n",
        "\n",
        "  def __create_mask(s):\n",
        "    n_feats = len(s.feat_scores)\n",
        "    n_feat_selected = n_feats if s.max_features is None else min(s.max_features, n_feats)\n",
        "    if s.threshold == 'median':\n",
        "      s.feat_mask = s.feat_scores >= np.median(s.feat_scores)\n",
        "    elif s.threshold == 'mean':\n",
        "      s.feat_mask = s.feat_scores >= np.mean(s.feat_scores)\n",
        "    else:\n",
        "      s.feat_mask = s.feat_scores >= s.threshold\n",
        "\n",
        "    s.feats_ind = np.arange(n_feats)[s.feat_mask][:n_feat_selected]\n",
        "\n",
        "  def __init__(self, typ = 'class', threshold=None, max_features=None, n_runs=300, n_bins=20, n_gauss_components=5, score_func=(lambda x: 0.5 * x) ):\n",
        "    self.typ = typ\n",
        "    self.threshold = threshold if threshold is not None else 'median'\n",
        "    self.max_features = max_features\n",
        "    self.n_runs = n_runs\n",
        "    self.n_bins = n_bins\n",
        "    self.n_gauss_components = n_gauss_components\n",
        "    self.score_func = score_func\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    actual_imp_df = self.__get_feature_importances(X, y, shuffle=False)\n",
        "    null_imp_df = self.__get_null_feature_importances(X, y)\n",
        "\n",
        "    self.feat_scores = []\n",
        "    for feat in range(X.shape[1]):\n",
        "      actual_feat_imp = actual_imp_df.loc[actual_imp_df['feature'] == feat]\n",
        "      null_feat_imp = null_imp_df.loc[null_imp_df['feature'] == feat]\n",
        "      actual_imp = actual_feat_imp['importance_gain'].iloc[0]\n",
        "      null_imp = null_feat_imp['importance_gain']\n",
        "      #TODO choose bin strategy\n",
        "      # act_len = np.max(actual_imp) - np.min(actual_imp)\n",
        "      # null_len  = np.max(null_imp) - np.min(null_imp)\n",
        "      # total_len = max(np.max(null_imp), np.max(actual_imp)) - min(np.min(null_imp), np.min(actual_imp))\n",
        "      # bin_count = max(total_len // null_len * n_bins, total_len // act_len * n_bins)\n",
        "      _sf_p = np.percentile(null_imp, 75)\n",
        "      print(_sf_p, actual_imp)\n",
        "      # print(actual_imp)\n",
        "      # print(null_imp)\n",
        "      # print(substr_imp)\n",
        "      # plt.hist(substr_imp, bins=20, label='diff', density=True)\n",
        "      # plt.hist(null_imp, bins=20, label='null', density=True)\n",
        "      # plt.hist(actual_imp, bins=20, label='actual', density=True)\n",
        "      # plt.legend(loc='upper right')\n",
        "      # plt.show()\n",
        "\n",
        "      feat_score = np.log(actual_imp/_sf_p)\n",
        "      print('f', feat_score, 'g', type(feat_score))\n",
        "      self.feat_scores.append(feat_score)\n",
        "    # print(self.feat_scores)\n",
        "    # print(np.array(self.feat_scores).argsort().argsort())\n",
        "    self.__create_mask()\n",
        "\n",
        "  def transform(self, X):\n",
        "    return X[:, self.feats_ind]\n",
        "  def get_support(self, indices=False):\n",
        "    return self.feats_ind if indices else self.feat_mask\n",
        "\n",
        "class SelectNullDistribution(BaseEstimator, TransformerMixin):\n",
        "  def __get_feature_importances(s, X, y, shuffle, seed=None):\n",
        "    f_num = X.shape[1]\n",
        "    if shuffle:\n",
        "        np.random.shuffle(y)\n",
        "\n",
        "    #TODO hardcode\n",
        "    dtrain = lgb.Dataset(X, y,params={'verbose': -1}, free_raw_data=False, silent=True)\n",
        "    lgb_params = {\n",
        "        'objective': 'binary',\n",
        "        'boosting_type': 'rf',\n",
        "        'subsample': 0.623,\n",
        "        'colsample_bytree': 0.7,\n",
        "        'num_leaves': 127,\n",
        "        'max_depth': 8,\n",
        "        'seed': seed,\n",
        "        'bagging_freq': 1,\n",
        "        'n_jobs': 4,\n",
        "        'verbose': -1\n",
        "    }\n",
        "    categorical_feats = []\n",
        "    # Fit the model\n",
        "    clf = lgb.train(params=lgb_params, train_set=dtrain, num_boost_round=200, categorical_feature=categorical_feats)\n",
        "\n",
        "    # Get feature importances\n",
        "    imp_df = pd.DataFrame()\n",
        "    imp_df[\"feature\"] = np.arange(f_num)\n",
        "    imp_df[\"importance_gain\"] = clf.feature_importance(importance_type='gain')\n",
        "    imp_df[\"importance_split\"] = clf.feature_importance(importance_type='split')\n",
        "    imp_df['trn_score'] = roc_auc_score(y, clf.predict(X))\n",
        "\n",
        "    return imp_df\n",
        "\n",
        "  def __get_real_feature_importances(s, X, y):\n",
        "    real_imp_df = pd.DataFrame()\n",
        "    dsp = ''\n",
        "    for run in range(s.n_runs):\n",
        "      # skf = StratifiedKFold(n_splits=n_splits, random_state=None, shuffle=True)\n",
        "      # for i, (train_index, _) in enumerate(skf.split(X, y)):\n",
        "      #     imp_df = s.__get_feature_importances(X[train_index, :], y[train_index], shuffle=False)\n",
        "      #     imp_df['run'] = run * n_splits + i + 1\n",
        "      #     real_imp_df = pd.concat([real_imp_df, imp_df], axis=0)\n",
        "      X_train, y_train = resample(X, y)\n",
        "      imp_df = s.__get_feature_importances(X_train, y_train, shuffle=False)\n",
        "      imp_df['run'] = run + 1\n",
        "      real_imp_df = pd.concat([real_imp_df, imp_df], axis=0)\n",
        "    return real_imp_df\n",
        "\n",
        "  def __get_null_feature_importances(s, X, y):\n",
        "    null_imp_df = pd.DataFrame()\n",
        "    dsp = ''\n",
        "    for i in range(s.n_runs):\n",
        "        X_train, y_train = resample(X, y)\n",
        "        imp_df = s.__get_feature_importances(X_train, y_train, shuffle=True)\n",
        "        imp_df['run'] = i + 1\n",
        "        null_imp_df = pd.concat([null_imp_df, imp_df], axis=0)\n",
        "    return null_imp_df\n",
        "\n",
        "  def __create_mask(s):\n",
        "    n_feats = len(s.feat_scores)\n",
        "    n_feat_selected = n_feats if s.max_features is None else min(s.max_features, n_feats)\n",
        "    if s.threshold == 'median':\n",
        "      s.feat_mask = s.feat_scores >= np.median(s.feat_scores)\n",
        "    elif s.threshold == 'mean':\n",
        "      s.feat_mask = s.feat_scores >= np.mean(s.feat_scores)\n",
        "    else:\n",
        "      s.feat_mask = s.feat_scores >= s.threshold\n",
        "\n",
        "    s.feats_ind = np.arange(n_feats)[s.feat_mask][:n_feat_selected]\n",
        "\n",
        "  def __init__(self, typ = 'class', threshold=None, max_features=None, n_runs=300, n_bins=20, n_gauss_components=5, score_func=(lambda x: 0.5 * x) ):\n",
        "    self.typ = typ\n",
        "    self.threshold = threshold if threshold is not None else 'median'\n",
        "    self.max_features = max_features\n",
        "    self.n_runs = n_runs\n",
        "    self.n_bins = n_bins\n",
        "    self.n_gauss_components = n_gauss_components\n",
        "    self.score_func = score_func\n",
        "\n",
        "  def fit(self, X, y=None):\n",
        "    actual_imp_df = self.__get_real_feature_importances(X, y)\n",
        "    null_imp_df = self.__get_null_feature_importances(X, y)\n",
        "\n",
        "    self.feat_scores = []\n",
        "    for feat in range(X.shape[1]):\n",
        "      actual_feat_imp = actual_imp_df.loc[actual_imp_df['feature'] == feat]\n",
        "      null_feat_imp = null_imp_df.loc[null_imp_df['feature'] == feat]\n",
        "      actual_imp = actual_feat_imp['importance_gain']\n",
        "      null_imp = null_feat_imp['importance_gain']\n",
        "      #TODO choose bin strategy\n",
        "      # act_len = np.max(actual_imp) - np.min(actual_imp)\n",
        "      # null_len  = np.max(null_imp) - np.min(null_imp)\n",
        "      # total_len = max(np.max(null_imp), np.max(actual_imp)) - min(np.min(null_imp), np.min(actual_imp))\n",
        "      # bin_count = max(total_len // null_len * n_bins, total_len // act_len * n_bins)\n",
        "      substr_imp = np.sum(np.array(np.meshgrid(actual_imp, -null_imp)).T.reshape(-1,2), axis=1)\n",
        "      # print(actual_imp)\n",
        "      # print(null_imp)\n",
        "      # print(substr_imp)\n",
        "      # plt.hist(substr_imp, bins=20, label='diff', density=True)\n",
        "      # plt.hist(null_imp, bins=20, label='null', density=True)\n",
        "      # plt.hist(actual_imp, bins=20, label='actual', density=True)\n",
        "      # plt.legend(loc='upper right')\n",
        "      # plt.show()\n",
        "      gm_model = GaussianMixture(n_components=self.n_gauss_components)\n",
        "      gm_model.fit(substr_imp.reshape(-1, 1))\n",
        "      means_ = gm_model.means_\n",
        "      score_func_vf = np.vectorize(self.score_func)\n",
        "      feat_score = np.sum(score_func_vf(means_))\n",
        "      self.feat_scores.append(feat_score)\n",
        "    # print(self.feat_scores)\n",
        "    # print(np.array(self.feat_scores).argsort().argsort())\n",
        "    self.__create_mask()\n",
        "\n",
        "  def transform(self, X):\n",
        "    return X[:, self.feats_ind]\n",
        "  def get_support(self, indices=False):\n",
        "    return self.feats_ind if indices else self.feat_mask\n",
        "\n"
      ],
      "metadata": {
        "id": "VodK3ErpL6T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FDZ-WHV_sZgp"
      },
      "outputs": [],
      "source": [
        "class FeatureSelectionTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, typ='skb_mutual_info_classif', k=50, task_type = 'class', n_estimators = 500):\n",
        "      if task_type == 'class':\n",
        "        if typ[0:3] == 'skb':\n",
        "            func = getattr(fs, typ[4:])\n",
        "            self.predictor = SelectKBest(score_func=mutual_info_classif, k=k)\n",
        "        elif typ == 'rtree':\n",
        "            self.predictor = SelectFromModel(ensemble.RandomForestClassifier(n_estimators = n_estimators), max_features=k)\n",
        "        elif typ == 'lsvm':\n",
        "            self.predictor = SelectFromModel(svm.LinearSVC(C=0.1, penalty=\"l1\", dual=False), max_features=k)\n",
        "        elif typ == 'null_importance':\n",
        "            self.predictor = SelectNullDistributionBaseline()\n",
        "        elif typ == 'null_importance_mod':\n",
        "            self.predictor = SelectNullDistribution()\n",
        "      elif task_type == 'reg':\n",
        "        if typ[0:2] == 'skb':\n",
        "            func = getattr(fs, typ[3:])\n",
        "            self.predictor = SelectKBest(score_func=mutual_info_classif, k=k)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self.predictor.fit(X, y)\n",
        "\n",
        "    def transform(self, X):\n",
        "        return self.predictor.transform(X)\n",
        "\n",
        "    def get_support(self, indices):\n",
        "        return self.predictor.get_support(indices=indices)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Генерация признаков"
      ],
      "metadata": {
        "id": "1hWqk6TpQ_4e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "ccc = np.array([\n",
        "    [1, 0],\n",
        "    [2, 0],\n",
        "    [1, 3]\n",
        "])\n",
        "\n",
        "corr = np.random.rand(10, 10)*1\n",
        "print(corr)\n",
        "cc = np.ones(10, dtype=bool)\n",
        "# corr[(corr - np.eye(10)) > 0.7] = 1\n",
        "# corr[(corr - np.eye(10)) <= 0.7] = 0\n",
        "G = nx.Graph()\n",
        "pairs_indxs_mat = np.array(list(combinations(range(corr.shape[1]), 2)))\n",
        "pairs_indxs_mat = np.array([[[i, j] for j in range(corr.shape[1])] for i in range(corr.shape[0])])\n",
        "print(pairs_indxs_mat)\n",
        "pairs_indxs_mat = pairs_indxs_mat[abs(corr) > 0.7]\n",
        "print(pairs_indxs_mat)\n",
        "pairs_indxs_mat = pairs_indxs_mat[pairs_indxs_mat[:, 0] > pairs_indxs_mat[:, 1]]\n",
        "# G = nx.from_numpy_array(corr)\n",
        "print(pairs_indxs_mat)\n",
        "G.add_edges_from(pairs_indxs_mat)\n",
        "print(\"Граф G:\")\n",
        "print(G.edges())\n",
        "components = nx.connected_components(G)\n",
        "selected_nodes = np.array([min(component) for component in components])\n",
        "print(selected_nodes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RD6A6-uyLCrB",
        "outputId": "c27cbfa3-2b43-4814-9ddc-3a17b8dcb8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.49672449 0.10734732 0.79612461 0.30100695 0.72943342 0.80731707\n",
            "  0.14758712 0.90180102 0.44263404 0.33827975]\n",
            " [0.62318306 0.90063496 0.42230134 0.8850605  0.65986275 0.37227935\n",
            "  0.30492412 0.8323567  0.07042549 0.50032002]\n",
            " [0.35768779 0.80445048 0.06653349 0.34333044 0.55784344 0.74408727\n",
            "  0.63557933 0.31614826 0.56000139 0.03983452]\n",
            " [0.26536943 0.84962255 0.910101   0.40462762 0.91835448 0.50800407\n",
            "  0.85040089 0.81521562 0.77596582 0.32569623]\n",
            " [0.86097446 0.84599502 0.70527702 0.43999696 0.21107591 0.94853523\n",
            "  0.35459917 0.48044149 0.15924056 0.73582528]\n",
            " [0.76865014 0.05291791 0.75595137 0.27838414 0.62512667 0.80665514\n",
            "  0.46576927 0.1458699  0.54163727 0.3006136 ]\n",
            " [0.01191472 0.01623461 0.69000397 0.11808455 0.18791094 0.24817694\n",
            "  0.33681465 0.27817308 0.0588439  0.90256006]\n",
            " [0.49278641 0.48792604 0.81852128 0.21760171 0.27706006 0.10887234\n",
            "  0.8986938  0.16745948 0.11380702 0.13958612]\n",
            " [0.33488539 0.99777632 0.89683613 0.81070344 0.69404464 0.42839352\n",
            "  0.52425875 0.04050205 0.66092022 0.86214387]\n",
            " [0.63073653 0.33227403 0.3920165  0.10217318 0.37418347 0.54716724\n",
            "  0.838926   0.51836348 0.17386449 0.71090442]]\n",
            "[[[0 0]\n",
            "  [0 1]\n",
            "  [0 2]\n",
            "  [0 3]\n",
            "  [0 4]\n",
            "  [0 5]\n",
            "  [0 6]\n",
            "  [0 7]\n",
            "  [0 8]\n",
            "  [0 9]]\n",
            "\n",
            " [[1 0]\n",
            "  [1 1]\n",
            "  [1 2]\n",
            "  [1 3]\n",
            "  [1 4]\n",
            "  [1 5]\n",
            "  [1 6]\n",
            "  [1 7]\n",
            "  [1 8]\n",
            "  [1 9]]\n",
            "\n",
            " [[2 0]\n",
            "  [2 1]\n",
            "  [2 2]\n",
            "  [2 3]\n",
            "  [2 4]\n",
            "  [2 5]\n",
            "  [2 6]\n",
            "  [2 7]\n",
            "  [2 8]\n",
            "  [2 9]]\n",
            "\n",
            " [[3 0]\n",
            "  [3 1]\n",
            "  [3 2]\n",
            "  [3 3]\n",
            "  [3 4]\n",
            "  [3 5]\n",
            "  [3 6]\n",
            "  [3 7]\n",
            "  [3 8]\n",
            "  [3 9]]\n",
            "\n",
            " [[4 0]\n",
            "  [4 1]\n",
            "  [4 2]\n",
            "  [4 3]\n",
            "  [4 4]\n",
            "  [4 5]\n",
            "  [4 6]\n",
            "  [4 7]\n",
            "  [4 8]\n",
            "  [4 9]]\n",
            "\n",
            " [[5 0]\n",
            "  [5 1]\n",
            "  [5 2]\n",
            "  [5 3]\n",
            "  [5 4]\n",
            "  [5 5]\n",
            "  [5 6]\n",
            "  [5 7]\n",
            "  [5 8]\n",
            "  [5 9]]\n",
            "\n",
            " [[6 0]\n",
            "  [6 1]\n",
            "  [6 2]\n",
            "  [6 3]\n",
            "  [6 4]\n",
            "  [6 5]\n",
            "  [6 6]\n",
            "  [6 7]\n",
            "  [6 8]\n",
            "  [6 9]]\n",
            "\n",
            " [[7 0]\n",
            "  [7 1]\n",
            "  [7 2]\n",
            "  [7 3]\n",
            "  [7 4]\n",
            "  [7 5]\n",
            "  [7 6]\n",
            "  [7 7]\n",
            "  [7 8]\n",
            "  [7 9]]\n",
            "\n",
            " [[8 0]\n",
            "  [8 1]\n",
            "  [8 2]\n",
            "  [8 3]\n",
            "  [8 4]\n",
            "  [8 5]\n",
            "  [8 6]\n",
            "  [8 7]\n",
            "  [8 8]\n",
            "  [8 9]]\n",
            "\n",
            " [[9 0]\n",
            "  [9 1]\n",
            "  [9 2]\n",
            "  [9 3]\n",
            "  [9 4]\n",
            "  [9 5]\n",
            "  [9 6]\n",
            "  [9 7]\n",
            "  [9 8]\n",
            "  [9 9]]]\n",
            "[[0 2]\n",
            " [0 4]\n",
            " [0 5]\n",
            " [0 7]\n",
            " [1 1]\n",
            " [1 3]\n",
            " [1 7]\n",
            " [2 1]\n",
            " [2 5]\n",
            " [3 1]\n",
            " [3 2]\n",
            " [3 4]\n",
            " [3 6]\n",
            " [3 7]\n",
            " [3 8]\n",
            " [4 0]\n",
            " [4 1]\n",
            " [4 2]\n",
            " [4 5]\n",
            " [4 9]\n",
            " [5 0]\n",
            " [5 2]\n",
            " [5 5]\n",
            " [6 9]\n",
            " [7 2]\n",
            " [7 6]\n",
            " [8 1]\n",
            " [8 2]\n",
            " [8 3]\n",
            " [8 9]\n",
            " [9 6]\n",
            " [9 9]]\n",
            "[[2 1]\n",
            " [3 1]\n",
            " [3 2]\n",
            " [4 0]\n",
            " [4 1]\n",
            " [4 2]\n",
            " [5 0]\n",
            " [5 2]\n",
            " [7 2]\n",
            " [7 6]\n",
            " [8 1]\n",
            " [8 2]\n",
            " [8 3]\n",
            " [9 6]]\n",
            "Граф G:\n",
            "[(2, 1), (2, 3), (2, 4), (2, 5), (2, 7), (2, 8), (1, 3), (1, 4), (1, 8), (3, 8), (4, 0), (0, 5), (7, 6), (6, 9)]\n",
            "[0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.covariance import empirical_covariance\n",
        "from sklearn. preprocessing import normalize\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm.notebook import tqdm\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "import networkx as nx\n",
        "\n",
        "\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "EPS = 1e-20\n",
        "EPS_LOG = 1e-3\n",
        "THRESHOLD = 0.2\n",
        "INF = 1e30\n",
        "\n",
        "class FeatureGenerationTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, thr=THRESHOLD, features_mask=None, important_features=None, stand_gen=True, corr_gen=True):\n",
        "        self.thr = thr\n",
        "        self._features_mask = features_mask\n",
        "        self._important_features = important_features\n",
        "        self._stand_gen = stand_gen\n",
        "        self._corr_gen = corr_gen\n",
        "        self.desc_dict = {}\n",
        "\n",
        "    #Construction of a matrix of correlation coefficients of features\n",
        "    def _correlation_create(self, X):\n",
        "        return np.corrcoef(X.T)\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = np.array(X)\n",
        "\n",
        "        self._cnt_columns = X.shape[1]\n",
        "\n",
        "        if self._features_mask is None:\n",
        "            self._features_mask = np.arange(X.shape[1])\n",
        "        else:\n",
        "            self._features_mask = np.array(self._features_mask)\n",
        "\n",
        "        self._corr_mat = self._correlation_create(X[:, self._features_mask])\n",
        "        pairs_indxs_mat = np.array(list(combinations(range(self._corr_mat.shape[0]), 2)))\n",
        "        pairs_indxs_mat = np.array([[[i, j] for j in range(self._corr_mat.shape[1])] for i in range(self._corr_mat.shape[0])])\n",
        "        pairs_indxs_mat = pairs_indxs_mat[abs(self._corr_mat) > 0.6]\n",
        "        pairs_indxs_mat = pairs_indxs_mat[pairs_indxs_mat[:, 0] >= pairs_indxs_mat[:, 1]]\n",
        "        # print(self._corr_mat)\n",
        "\n",
        "        G = nx.Graph()\n",
        "        G.add_edges_from(pairs_indxs_mat)\n",
        "        components = nx.connected_components(G)\n",
        "        # print(\"Граф G:\")\n",
        "        # print(G.edges())\n",
        "        self.selected_cols = np.array([min(component) for component in components])\n",
        "        self._features_mask = self.selected_cols\n",
        "        # print(self._features_mask)\n",
        "        del G\n",
        "\n",
        "\n",
        "        if self._important_features is None:\n",
        "            self._important_features = self._features_mask\n",
        "        else:\n",
        "            self._important_features = np.array(self._important_features)\n",
        "\n",
        "        if self._important_features.size < 2:\n",
        "            self._corr_gen = False\n",
        "\n",
        "        # if self._corr_gen:\n",
        "        #     self._corr_mat = self._correlation_create(X[:, self._important_features])\n",
        "\n",
        "        # if self._corr_gen:\n",
        "        #     self._corr_mat = self._correlation_create(X[:, self._features_mask])\n",
        "\n",
        "\n",
        "        if self._stand_gen:\n",
        "            self._cnt_columns = self._standard_generation(X, self._cnt_columns)\n",
        "        if self._corr_gen:\n",
        "            self._cnt_columns = self._correlation_generation(X, self._cnt_columns)\n",
        "\n",
        "        return self\n",
        "\n",
        "    #Generating features using standard functions\n",
        "    def _standard_generation(self, X, cnt_columns=None):\n",
        "        features_mask = self._features_mask\n",
        "        important_features = self._important_features\n",
        "\n",
        "        if cnt_columns is None:\n",
        "            cnt_columns = X.shape[1]\n",
        "\n",
        "        if features_mask.size:\n",
        "            #exponent\n",
        "            self.desc_dict['s_exp'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            cnt_columns += features_mask.shape[0]\n",
        "\n",
        "            #x^2\n",
        "            self.desc_dict['s_^2'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            cnt_columns += features_mask.shape[0]\n",
        "\n",
        "            # #x^3\n",
        "            # self.desc_dict['s_^3'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            # cnt_columns += features_mask.shape[0]\n",
        "\n",
        "            # #sin\n",
        "            # self.desc_dict['s_sin'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            # cnt_columns += features_mask.shape[0]\n",
        "\n",
        "            # #cos\n",
        "            # self.desc_dict['s_cos'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            # cnt_columns += features_mask.shape[0]\n",
        "\n",
        "            # #sinh\n",
        "            # self.desc_dict['s_sinh'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            # cnt_columns += features_mask.shape[0]\n",
        "\n",
        "            # #cosh\n",
        "            # self.desc_dict['s_cosh'] = [features_mask, np.arange(cnt_columns, cnt_columns + features_mask.shape[0])]\n",
        "            # cnt_columns += features_mask.shape[0]\n",
        "\n",
        "\n",
        "        # if important_features.size:\n",
        "        #     #logarithm\n",
        "        #     self.desc_dict['s_log'] = [important_features, np.arange(cnt_columns, cnt_columns + important_features.shape[0])]\n",
        "        #     cnt_columns += important_features.shape[0]\n",
        "\n",
        "        #     #x^0.5\n",
        "        #     self.desc_dict['s_^0.5'] = [important_features, np.arange(cnt_columns, cnt_columns + important_features.shape[0])]\n",
        "        #     cnt_columns += important_features.shape[0]\n",
        "\n",
        "        return cnt_columns\n",
        "\n",
        "    #Generating features from two that have a correlation coefficient less than the threshold\n",
        "    def _correlation_generation(self, X, cnt_columns=None):\n",
        "        if cnt_columns is None:\n",
        "            cnt_columns = X.shape[1]\n",
        "\n",
        "        important_features = self._important_features\n",
        "\n",
        "\n",
        "        pairs_indxs_mat = np.array([[[i, j] for j in range(self._important_features.shape[0])] for i in range(self._important_features.shape[0])])\n",
        "        pairs_indxs_mat = pairs_indxs_mat.reshape(-1, 2)\n",
        "        pairs_indxs_mat = pairs_indxs_mat[pairs_indxs_mat[:, 0] > pairs_indxs_mat[:, 1]]\n",
        "\n",
        "        #x1 * x2\n",
        "        self.desc_dict['p_*'] = [important_features[pairs_indxs_mat], np.arange(cnt_columns, cnt_columns + pairs_indxs_mat.shape[0])]\n",
        "        cnt_columns += pairs_indxs_mat.shape[0]\n",
        "\n",
        "        #x1 / x2, x2 / x1\n",
        "        self.desc_dict['p_/'] = [np.hstack([important_features[pairs_indxs_mat], important_features[pairs_indxs_mat][:,::-1]]).reshape(-1, 2),\n",
        "                               np.arange(cnt_columns, cnt_columns + 2 * pairs_indxs_mat.shape[0])]\n",
        "        cnt_columns += 2 * pairs_indxs_mat.shape[0]\n",
        "\n",
        "        # if pairs_indxs_mat.size:\n",
        "        #     #x1 + x2\n",
        "        #     self.desc_dict['p_+'] = [important_features[pairs_indxs_mat], np.arange(cnt_columns, cnt_columns + pairs_indxs_mat.shape[0])]\n",
        "        #     cnt_columns += pairs_indxs_mat.shape[0]\n",
        "\n",
        "        #     #x1 - x2, x2 - x1\n",
        "        #     self.desc_dict['p_-'] = [np.hstack([important_features[pairs_indxs_mat], important_features[pairs_indxs_mat][:,::-1]]).reshape(-1, 2),\n",
        "        #                            np.arange(cnt_columns, cnt_columns + 2 * pairs_indxs_mat.shape[0])]\n",
        "        #     cnt_columns += 2 * pairs_indxs_mat.shape[0]\n",
        "\n",
        "        return cnt_columns\n",
        "\n",
        "    def transform(self, X):\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            X = np.array(X)\n",
        "\n",
        "        cnt_columns = 0\n",
        "        for k, v in self.desc_dict.items():\n",
        "            if k != '_':\n",
        "                cnt_columns += self.desc_dict[k][1].shape[0]\n",
        "\n",
        "        X = np.hstack([X, np.zeros((X.shape[0], cnt_columns))])\n",
        "\n",
        "        #exponent\n",
        "        if 's_exp' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_exp'][1]] =  np.exp(np.clip(X[:,self.desc_dict['s_exp'][0]], -750, 700))\n",
        "\n",
        "        #x^2\n",
        "        if 's_^2' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_^2'][1]] =  np.power(X[:,self.desc_dict['s_^2'][0]], 2)\n",
        "\n",
        "        #x^3\n",
        "        if 's_^3' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_^3'][1]] =  np.power(X[:,self.desc_dict['s_^3'][0]], 3)\n",
        "\n",
        "        #sin\n",
        "        if 's_sin' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_sin'][1]] =  np.sin(X[:,self.desc_dict['s_sin'][0]])\n",
        "\n",
        "        #cos\n",
        "        if 's_cos' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_cos'][1]] =  np.cos(X[:,self.desc_dict['s_cos'][0]])\n",
        "\n",
        "        #sinh\n",
        "        if 's_sinh' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_sinh'][1]] =  np.sinh(X[:,self.desc_dict['s_sinh'][0]])\n",
        "\n",
        "        #cosh\n",
        "        if 's_cosh' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_cosh'][1]] =  np.cosh(X[:,self.desc_dict['s_cosh'][0]])\n",
        "\n",
        "        #logarithm\n",
        "        if 's_log' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_log'][1]] =  np.where(X[:, self.desc_dict['s_log'][0]] <= -1, np.log(EPS_LOG),\n",
        "                                                         np.log(X[:,self.desc_dict['s_log'][0]] + 1, where=X[:,self.desc_dict['s_log'][0]] > -1))\n",
        "\n",
        "        #x^0.5\n",
        "        if 's_^0.5' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['s_^0.5'][1]] = np.where(X[:,self.desc_dict['s_^0.5'][0]] < 0, -np.power(-X[:,self.desc_dict['s_^0.5'][0]], 0.5,\n",
        "                                                          where=X[:,self.desc_dict['s_^0.5'][0]] < 0), np.power(X[:,self.desc_dict['s_^0.5'][0]], 0.5,\n",
        "                                                          where=X[:,self.desc_dict['s_^0.5'][0]] >= 0))\n",
        "        #x1 * x2\n",
        "        if 'p_*' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['p_*'][1]] = np.prod(X.T[self.desc_dict['p_*'][0]], axis=1).T\n",
        "\n",
        "        #x1 / x2, x2 / x1\n",
        "        if 'p_/' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['p_/'][1]] = X.T[self.desc_dict['p_/'][0][:, 0]].T / (X.T[self.desc_dict['p_/'][0][:, 1]].T + EPS)\n",
        "\n",
        "        #x1 + x2\n",
        "        if 'p_+' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['p_+'][1]] = np.sum(X.T[self.desc_dict['p_+'][0]], axis=1).T\n",
        "\n",
        "        #x1 - x2, x2 - x1\n",
        "        if 'p_-' in self.desc_dict.keys():\n",
        "            X[:, self.desc_dict['p_-'][1]] = X.T[self.desc_dict['p_-'][0][:, 0]].T - X.T[self.desc_dict['p_-'][0][:, 1]].T\n",
        "\n",
        "        X = np.clip(X, -INF, INF)\n",
        "\n",
        "        return X"
      ],
      "metadata": {
        "id": "QeYQ-_DNREhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Алгоритм отбора признаков с генерацией"
      ],
      "metadata": {
        "id": "qGbWhOMIKzQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_desc_dict(dict1, dict2, bias=0):\n",
        "  rdict = {}\n",
        "  pointer = bias\n",
        "  for op in dict1.keys():\n",
        "    val = np.unique(np.concatenate((dict1[op][0],dict2[op][0]), axis=0), axis=0)\n",
        "    rdict[op] = [val, np.arange(pointer, pointer+val.shape[0])]\n",
        "    if op != \"_\":\n",
        "      pointer += val.shape[0]\n",
        "  return rdict"
      ],
      "metadata": {
        "id": "jQcLzl0WJ8W5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeatProcessing(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, task_type, n_fold_splits, gen_kwargs={}, sel_for_gen_kwargs={}, sel_from_gen_kwargs={}, for_k_limit=50):\n",
        "      self.n_fold_splits = n_fold_splits\n",
        "      self.gen_kwargs = gen_kwargs\n",
        "      self.sel_for_gen_kwargs = sel_for_gen_kwargs\n",
        "      self.sel_from_gen_kwargs = sel_from_gen_kwargs\n",
        "      self.for_k_limit = for_k_limit\n",
        "\n",
        "      self.desc_dict = {}\n",
        "    def fit(self, X, y=None):\n",
        "      print(X.shape)\n",
        "\n",
        "\n",
        "      if 'k' not in self.sel_for_gen_kwargs.keys():\n",
        "        for_k = min(X.shape[1], self.for_k_limit)\n",
        "        self.sel_for_gen_kwargs['k'] = for_k\n",
        "      else:\n",
        "        for_k = self.sel_for_gen_kwargs['k']\n",
        "\n",
        "      if 'k' not in self.sel_from_gen_kwargs.keys():\n",
        "        from_k = X.shape[1]\n",
        "        self.sel_from_gen_kwargs['k'] = from_k\n",
        "        # self.sel_from_gen_kwargs['thr'] = -np.inf\n",
        "      else:\n",
        "        from_k = self.sel_from_gen_kwargs['k']\n",
        "\n",
        "\n",
        "      kf = KFold(n_splits=self.n_fold_splits)\n",
        "\n",
        "      for i, (train_index, val_index) in enumerate(kf.split(X)):\n",
        "\n",
        "        X_train, X_val, y_train, y_val = X[train_index, :], X[val_index, :], y[train_index], y[val_index]\n",
        "        obj_count, f_dim = X_train.shape[0], X_train.shape[1]\n",
        "        #1 SEL\n",
        "        self.sel_for_gen = FeatureSelectionTransformer(**self.sel_for_gen_kwargs)\n",
        "        self.sel_for_gen.fit(X_train, y_train)\n",
        "        important_features = self.sel_for_gen.get_support(indices=True)[:for_k]\n",
        "\n",
        "        #Константа просчитывается с учетом того, что под вычисления отводится 8 гб ОЗУ\n",
        "        for_k_limit_important = int(((1073741824 / (X.shape[0] / 0.8) / 3 - X.shape[1] * 10) / 3) ** 0.5)\n",
        "        #GEN\n",
        "        self.gen = FeatureGenerationTransformer(features_mask=important_features, important_features=important_features[:abs(min(for_k, for_k_limit_important))], **self.gen_kwargs)\n",
        "        self.gen.fit(X_train, y_train)\n",
        "        # print('X_val', X_val.shape)\n",
        "        X_gen = self.gen.transform(X_val)\n",
        "        # print('X_gen', X_gen.shape)\n",
        "\n",
        "        pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "        X_gen[:, X_val.shape[1]:] = pipe_sc.fit_transform(X_gen[:,  X_val.shape[1]:])\n",
        "        #2 SEL\n",
        "        # print(X_gen.shape)\n",
        "        # X_gen = np.delete(X_gen, np.setdiff1d(np.arange(X_train.shape[1]), self.gen.selected_cols), axis=1)\n",
        "        # print(X_gen.shape)\n",
        "        # print('nexxxxxxxt')\n",
        "        self.sel_from_gen = FeatureSelectionTransformer(**self.sel_from_gen_kwargs)\n",
        "        self.sel_from_gen.fit(X_gen, y_val)\n",
        "        #Prepare indicies\n",
        "        fos = important_features # индексы в исходном векторе,\n",
        "        # выбранных признаков\n",
        "        frs = self.sel_from_gen.get_support(indices=True)[:from_k] # индексы в сгенерированном векторе,\n",
        "        # выбранных признаков\n",
        "\n",
        "\n",
        "        desc =  self.gen.desc_dict\n",
        "        # print(desc)\n",
        "        desc['_'] = [np.arange(0, f_dim), np.arange(0, f_dim)]\n",
        "        sort_desc = {}\n",
        "        map = np.zeros(X_gen.shape[0])\n",
        "\n",
        "        #for keys\n",
        "        for op in desc.keys():\n",
        "           #Начинается с 0\n",
        "          # print(frs, fos, desc[op][0])\n",
        "          mask = np.in1d(desc[op][1], frs) #remove generating which are not selected\n",
        "          sort_desc[op] = [desc[op][0][mask], desc[op][1][mask]]\n",
        "          # print(sort_desc[op])\n",
        "\n",
        "          # if op != '_':\n",
        "          #   sort_desc[op][0] = fos[sort_desc[op][0]]\n",
        "        if len(self.desc_dict.keys()) == 0:\n",
        "          self.desc_dict = sort_desc\n",
        "        else:\n",
        "          self.desc_dict = merge_desc_dict(self.desc_dict, sort_desc, bias=f_dim) # union algorythms\n",
        "        # print(self.desc_dict)\n",
        "\n",
        "      self.gen.desc_dict = self.desc_dict #!!!!!\n",
        "\n",
        "    def transform(self, X):\n",
        "\n",
        "      X_res = self.gen.transform(X)\n",
        "\n",
        "      # for i in list(set(range(X.shape[1])) - set(self.desc_dict['_'][0])):\n",
        "\n",
        "      #   X_res = np.delete(X_res, i, 1)\n",
        "      return X_res\n",
        "\n"
      ],
      "metadata": {
        "id": "b-wTUzlqJkph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ValidTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, task_type, **kwargs):\n",
        "      self.task_type = task_type\n",
        "      self.kwargs = kwargs\n",
        "      if 'work_time' in kwargs.keys():\n",
        "        self.work_time = kwargs['work_time']\n",
        "      else:\n",
        "        self.work_time = 1\n",
        "      if 'val_size' in kwargs.keys():\n",
        "        self.val_size = kwargs['val_size']\n",
        "      else:\n",
        "        self.val_size = 0.2\n",
        "      if 'random_state' in kwargs.keys():\n",
        "        self.random_state = kwargs['random_state']\n",
        "      else:\n",
        "        self.random_state = 42\n",
        "    def fit(self, X, y=None):\n",
        "      obj_count, f_dim = X.shape[0], X.shape[1]\n",
        "\n",
        "      if 'encoder' in self.kwargs.keys():\n",
        "        self.encoder = CategoricalEncoder(**self.kwargs['encoder'])\n",
        "      else:\n",
        "        self.encoder = CategoricalEncoder()\n",
        "      self.encoder = preprocessing.StandardScaler() # TODO add normalization after generation\n",
        "      if 'processor' in self.kwargs.keys():\n",
        "        self.trans = FeatProcessing(**self.kwargs['processor'])\n",
        "      else:\n",
        "        self.trans = FeatProcessing(self.task_type, 2)\n",
        "      # self.encoder.fit(X, y)\n",
        "      self.trans.fit(X, y)\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "      # Perform arbitary transformation\n",
        "      X = self.encoder.transform(X)\n",
        "      return self.trans.transform(X)"
      ],
      "metadata": {
        "id": "olXaxHhbJhas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Тестирование"
      ],
      "metadata": {
        "id": "6TRcYsrDK7Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Попытка с AutoML Banchmark"
      ],
      "metadata": {
        "id": "2WydREVsLvK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/openml/automlbenchmark.git --branch stable --depth 1\n",
        "!cd automlbenchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A4Dy7Slf3iZ",
        "outputId": "c51c06c0-58d8-4973-cffb-dd81ff3eb859"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'automlbenchmark'...\n",
            "remote: Enumerating objects: 496, done.\u001b[K\n",
            "remote: Counting objects: 100% (496/496), done.\u001b[K\n",
            "remote: Compressing objects: 100% (424/424), done.\u001b[K\n",
            "remote: Total 496 (delta 82), reused 368 (delta 52), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (496/496), 6.48 MiB | 16.83 MiB/s, done.\n",
            "Resolving deltas: 100% (82/82), done.\n",
            "Note: switching to '73823c55d8674761aab25520a75cbeea065ca124'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izGBoXt3gJlQ",
        "outputId": "298754b9-fd02-4ebb-beb0-933a34cb6c89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "automlbenchmark  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install --upgrade pip\n",
        "!python -m pip install -r automlbenchmark/requirements.txt"
      ],
      "metadata": {
        "id": "aDQomVcrgA8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python automlbenchmark/runbenchmark.py benchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0z4GiC8g_lw",
        "outputId": "477b1c6f-b79c-45b3-8885-688cc7a44497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
            "  warnings.warn(\"Setuptools is replacing distutils.\")\n",
            "Running benchmark `benchmark` on `test` framework in `local` mode.\n",
            "Loading frameworks definitions from ['/content/automlbenchmark/resources/frameworks.yaml'].\n",
            "\n",
            "ERROR:\n",
            "Incorrect framework `benchmark`: not listed in ['/content/automlbenchmark/resources/frameworks.yaml'].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Тестирование с OpenML"
      ],
      "metadata": {
        "id": "YHP055wEL1VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X, y, X_t, y_t):\n",
        "  models = [('linear_svm', svm.LinearSVC(max_iter=2000, random_state=42), 'decision_function'),\n",
        "            ('logistic', linear_model.LogisticRegression(solver = 'lbfgs', random_state=42, max_iter=1000, penalty='l2', C=1), 'predict_proba'),\n",
        "            ('linear_discriminant_analysis', LinearDiscriminantAnalysis(), 'predict_proba'),\n",
        "            ('gradboost', ensemble.GradientBoostingClassifier(random_state=42, n_estimators=10), 'predict_proba'),\n",
        "            ('randomforest', ensemble.RandomForestClassifier(random_state=42), 'predict_proba')]\n",
        "  ans = {}\n",
        "  for name, model, loss_func in models:\n",
        "      model.fit(X, y)\n",
        "      ans[name] = model.score(X_t, y_t)\n",
        "  return ans"
      ],
      "metadata": {
        "id": "ZbMvM4qmmKoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openml\n",
        "\n",
        "suite_id = 218\n",
        "benchmark_suite = openml.study.get_suite(suite_id)\n",
        "\n",
        "tasks_list = benchmark_suite.tasks\n",
        "task = openml.tasks.get_task(tasks_list[6]) #indexes 0 - 38\n",
        "\n",
        "dataset = task.get_dataset()\n",
        "print(dataset.description)"
      ],
      "metadata": {
        "id": "nuKyzUcZpxG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
        "X.info()"
      ],
      "metadata": {
        "id": "QiXFxZet7ra1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iL4XChK7cj1B",
        "outputId": "1d6062f3-b1f8-4dbc-a857-9b0fcbd64b49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6465"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for col_ind in X.dtypes[X.dtypes == 'category'].index:\n",
        "    X[col_ind] = X[col_ind].cat.add_categories([0.000001])"
      ],
      "metadata": {
        "id": "zZEp6RLlXipr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.fillna(0.000001, inplace=True)"
      ],
      "metadata": {
        "id": "Lu2L5C75Y8jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.isnull().sum().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKeuG53RZQLe",
        "outputId": "87e21cf0-b44b-4bc2-c7ab-230a30f76833"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение меток классов и их строковое представление\n",
        "class_labels = set(y)\n",
        "# Создание словаря для преобразования строковых меток в числовые индексы\n",
        "class_labels_map = {label: i for i, label in enumerate(class_labels)}\n",
        "y_numeric = [class_labels_map[label] for label in y]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_numeric), test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "7KGj2Sfzl-ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = CategoricalEncoder(encoder='binary', category_rate=0.9)\n",
        "X_train = enc.fit_transform(X_train)\n",
        "X_test = enc.transform(X_test)"
      ],
      "metadata": {
        "id": "EIDIo8mEyA7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = NumericalEncoder(numeric_rate=0.9)\n",
        "enc.fit_transform(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "JN2LeYr0_c0m",
        "outputId": "6551e84d-f324-4082-ba5a-6fadb0fa90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       binary_age_0  binary_age_1  binary_age_2  binary_age_3  binary_age_4  \\\n",
              "0                 0             0             0             0             0   \n",
              "1                 0             0             0             0             0   \n",
              "2                 0             0             0             0             0   \n",
              "3                 0             0             0             0             1   \n",
              "4                 0             0             0             0             1   \n",
              "...             ...           ...           ...           ...           ...   \n",
              "39068             0             1             0             0             0   \n",
              "39069             0             0             0             0             0   \n",
              "39070             0             0             0             0             1   \n",
              "39071             0             0             0             0             1   \n",
              "39072             0             1             1             0             1   \n",
              "\n",
              "       binary_age_5  binary_age_6  binary_workclass_0  binary_workclass_1  \\\n",
              "0                 0             1                   0                   0   \n",
              "1                 1             0                   0                   0   \n",
              "2                 1             1                   0                   1   \n",
              "3                 0             0                   0                   0   \n",
              "4                 0             1                   0                   0   \n",
              "...             ...           ...                 ...                 ...   \n",
              "39068             0             1                   0                   0   \n",
              "39069             1             1                   0                   0   \n",
              "39070             0             0                   0                   0   \n",
              "39071             0             1                   0                   1   \n",
              "39072             1             1                   0                   0   \n",
              "\n",
              "       binary_workclass_2  ...  binary_hours-per-week_3  \\\n",
              "0                       0  ...                        0   \n",
              "1                       1  ...                        0   \n",
              "2                       0  ...                        0   \n",
              "3                       0  ...                        0   \n",
              "4                       0  ...                        0   \n",
              "...                   ...  ...                      ...   \n",
              "39068                   0  ...                        0   \n",
              "39069                   0  ...                        0   \n",
              "39070                   0  ...                        0   \n",
              "39071                   1  ...                        0   \n",
              "39072                   0  ...                        0   \n",
              "\n",
              "       binary_hours-per-week_4  binary_hours-per-week_5  \\\n",
              "0                            0                        0   \n",
              "1                            0                        1   \n",
              "2                            0                        0   \n",
              "3                            0                        0   \n",
              "4                            0                        1   \n",
              "...                        ...                      ...   \n",
              "39068                        0                        0   \n",
              "39069                        0                        1   \n",
              "39070                        0                        0   \n",
              "39071                        0                        0   \n",
              "39072                        0                        1   \n",
              "\n",
              "       binary_hours-per-week_6  binary_native-country_0  \\\n",
              "0                            1                        0   \n",
              "1                            0                        0   \n",
              "2                            1                        0   \n",
              "3                            1                        0   \n",
              "4                            1                        0   \n",
              "...                        ...                      ...   \n",
              "39068                        1                        0   \n",
              "39069                        1                        0   \n",
              "39070                        1                        0   \n",
              "39071                        1                        0   \n",
              "39072                        0                        0   \n",
              "\n",
              "       binary_native-country_1  binary_native-country_2  \\\n",
              "0                            0                        0   \n",
              "1                            0                        0   \n",
              "2                            0                        0   \n",
              "3                            0                        0   \n",
              "4                            0                        0   \n",
              "...                        ...                      ...   \n",
              "39068                        0                        0   \n",
              "39069                        0                        0   \n",
              "39070                        0                        0   \n",
              "39071                        0                        0   \n",
              "39072                        0                        0   \n",
              "\n",
              "       binary_native-country_3  binary_native-country_4  \\\n",
              "0                            0                        0   \n",
              "1                            0                        0   \n",
              "2                            0                        0   \n",
              "3                            0                        0   \n",
              "4                            0                        0   \n",
              "...                        ...                      ...   \n",
              "39068                        0                        0   \n",
              "39069                        0                        0   \n",
              "39070                        0                        0   \n",
              "39071                        0                        0   \n",
              "39072                        0                        0   \n",
              "\n",
              "       binary_native-country_5  \n",
              "0                            1  \n",
              "1                            1  \n",
              "2                            1  \n",
              "3                            1  \n",
              "4                            1  \n",
              "...                        ...  \n",
              "39068                        1  \n",
              "39069                        1  \n",
              "39070                        1  \n",
              "39071                        1  \n",
              "39072                        1  \n",
              "\n",
              "[39073 rows x 52 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6b38730-63bb-408c-be46-aae456835275\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>binary_age_0</th>\n",
              "      <th>binary_age_1</th>\n",
              "      <th>binary_age_2</th>\n",
              "      <th>binary_age_3</th>\n",
              "      <th>binary_age_4</th>\n",
              "      <th>binary_age_5</th>\n",
              "      <th>binary_age_6</th>\n",
              "      <th>binary_workclass_0</th>\n",
              "      <th>binary_workclass_1</th>\n",
              "      <th>binary_workclass_2</th>\n",
              "      <th>...</th>\n",
              "      <th>binary_hours-per-week_3</th>\n",
              "      <th>binary_hours-per-week_4</th>\n",
              "      <th>binary_hours-per-week_5</th>\n",
              "      <th>binary_hours-per-week_6</th>\n",
              "      <th>binary_native-country_0</th>\n",
              "      <th>binary_native-country_1</th>\n",
              "      <th>binary_native-country_2</th>\n",
              "      <th>binary_native-country_3</th>\n",
              "      <th>binary_native-country_4</th>\n",
              "      <th>binary_native-country_5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39068</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39069</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39070</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39071</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39072</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39073 rows × 52 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6b38730-63bb-408c-be46-aae456835275')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6b38730-63bb-408c-be46-aae456835275 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6b38730-63bb-408c-be46-aae456835275');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc463cf1-ea53-48de-8e2f-c39d182f8bb5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc463cf1-ea53-48de-8e2f-c39d182f8bb5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc463cf1-ea53-48de-8e2f-c39d182f8bb5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()"
      ],
      "metadata": {
        "id": "AyiEwbxnAuXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc.get_cols()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dHaDgNqd6l6",
        "outputId": "d084d016-53a3-4c1a-8c29-cfc31359a28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([11, 37, 38])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "pipe_sc.fit(X_train[:, enc.get_cols()])\n",
        "X_train[:, enc.get_cols()] = pipe_sc.transform(X_train[:, enc.get_cols()])\n",
        "X_test[:, enc.get_cols()] = pipe_sc.transform(X_test[:, enc.get_cols()])"
      ],
      "metadata": {
        "id": "Ljt11Itl7n0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvnAzDEvMYxg",
        "outputId": "e505314f-7a80-4e36-8ba3-0ee5da5914a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39073, 52)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_accuracy(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgSHUSd3MjuT",
        "outputId": "23fcd008-cfad-4514-b48b-21ef90bec194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'linear_svm': 0.8479885351622479,\n",
              " 'logistic': 0.8461459719520934,\n",
              " 'linear_discriminant_analysis': 0.8358071450506704,\n",
              " 'gradboost': 0.8210666393694339,\n",
              " 'randomforest': 0.8551540587572934}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_lim(X, y, X_t, y_t):\n",
        "  models = [('linear_svm', svm.LinearSVC(max_iter=10000, random_state=42), 'decision_function'),\n",
        "            ('logistic', linear_model.LogisticRegression(solver = 'lbfgs', random_state=42, max_iter=10000, penalty='l2', C=1), 'predict_proba'),\n",
        "            ('linear_discriminant_analysis', LinearDiscriminantAnalysis(), 'predict_proba'),\n",
        "            ('gradboost', ensemble.GradientBoostingClassifier(random_state=42, n_estimators=10), 'predict_proba'),\n",
        "            ('randomforest', ensemble.RandomForestClassifier(random_state=42), 'predict_proba')]\n",
        "  ans = {}\n",
        "  for name, model, loss_func in models:\n",
        "      model.fit(X, y)\n",
        "      ans[name] = model.score(X_t, y_t)\n",
        "  return ans"
      ],
      "metadata": {
        "id": "JUHojlqAOxIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_datasets = [9952, 146822, 3917, 34] #9952, 146822, 3917\n",
        "for task_id in tqdm(small_datasets):\n",
        "    try:\n",
        "        task = openml.tasks.get_task(task_id)\n",
        "        dataset = task.get_dataset()\n",
        "\n",
        "        X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
        "        print(X.info())\n",
        "\n",
        "        # Заполнения пропусков\n",
        "        # null -> 0.000001\n",
        "        for col_ind in X.dtypes[X.dtypes == 'category'].index:\n",
        "            X[col_ind] = X[col_ind].cat.add_categories([0.000001])\n",
        "        X.fillna(0.000001, inplace=True)\n",
        "\n",
        "        # Получение меток классов и их строковое представление\n",
        "        class_labels = set(y)\n",
        "\n",
        "        # Создание словаря для преобразования строковых меток в числовые индексы\n",
        "        class_labels_map = {label: i for i, label in enumerate(class_labels)}\n",
        "        y_numeric = [class_labels_map[label] for label in y]\n",
        "\n",
        "        # Разделяем на трейн и тест\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_numeric), test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "        enc = CustomEncoder(categorical_args={'encoder':'target_loo'})\n",
        "        X_train = enc.fit_transform(X_train, y_train).to_numpy()\n",
        "        X_test = enc.transform(X_test).to_numpy()\n",
        "\n",
        "        # # Кодируем категориальные\n",
        "        # enc = CategoricalEncoder(encoder='binary', category_rate=0.9)\n",
        "        # X_train = enc.fit_transform(X_train)\n",
        "        # X_test = enc.transform(X_test)\n",
        "\n",
        "        # # Ищем и нормируем вещественные\n",
        "        # enc = NumericalEncoder(numeric_rate=0.9)\n",
        "        # enc.fit_transform(X_train)\n",
        "        # X_train = X_train.to_numpy()\n",
        "        # X_test = X_test.to_numpy()\n",
        "        # if enc.get_cols().shape[0] > 0:\n",
        "        #     pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "        #     pipe_sc.fit(X_train[:, enc.get_cols()])\n",
        "        #     X_train[:, enc.get_cols()] = pipe_sc.transform(X_train[:, enc.get_cols()])\n",
        "        #     X_test[:, enc.get_cols()] = pipe_sc.transform(X_test[:, enc.get_cols()])\n",
        "\n",
        "        acc_b = calc_accuracy_lim(X_train, y_train, X_test, y_test)\n",
        "        print('Номер датасета:', task_id)\n",
        "\n",
        "        # feat_gen = FeatureGenerationTransformer()\n",
        "        # start_time = time.time()\n",
        "        # feat_gen.fit_transform(X_train)\n",
        "\n",
        "        trans = FeatProcessing('class', 2 if X_train.shape[0] < 3000 else 3, {'corr_gen': True}, sel_for_gen_kwargs={'typ': 'rtree'}, sel_from_gen_kwargs={'typ': 'rtree'})\n",
        "        trans.fit(X_train, y_train)\n",
        "        X_train_gen = trans.transform(X_train)\n",
        "        X_test_gen = trans.transform(X_test)\n",
        "\n",
        "        # X_train_gen = feat_gen.transform(X_train)\n",
        "        # X_test_gen = feat_gen.transform(X_test)\n",
        "        # X_train_gen = np.delete(X_train_gen, np.setdiff1d(np.arange(X_train.shape[1]), feat_gen.selected_cols), axis=1)\n",
        "        # X_test_gen = np.delete(X_test_gen, np.setdiff1d(np.arange(X_train.shape[1]), feat_gen.selected_cols), axis=1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "        print(f'Время генерации: {elapsed_time:.5f}')\n",
        "        print('Размер до генерации', X_train.shape)\n",
        "        print('Размер после генерации', X_train_gen.shape)\n",
        "\n",
        "        pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "        pipe_sc.fit(X_train_gen[:, X_train.shape[1]:])\n",
        "        X_train_gen[:, X_train.shape[1]:] = pipe_sc.transform(X_train_gen[:,  X_train.shape[1]:])\n",
        "        X_test_gen[:,  X_train.shape[1]:] = pipe_sc.transform(X_test_gen[:,  X_train.shape[1]:])\n",
        "\n",
        "        acc_a = calc_accuracy_lim(X_train_gen, y_train, X_test_gen, y_test)\n",
        "\n",
        "        # print(X_train_gen[:, 18])\n",
        "        print('Качество до генерации', acc_b)\n",
        "        print('Качество после генерации', acc_a)\n",
        "\n",
        "        pr = 0\n",
        "        pr += 1 if acc_a['linear_svm'] - acc_b['linear_svm'] >= 0 else 0\n",
        "        pr += 1 if acc_a['logistic'] - acc_b['logistic'] >= 0 else 0\n",
        "        pr += 1 if acc_a['linear_discriminant_analysis'] - acc_b['linear_discriminant_analysis'] >= 0 else 0\n",
        "        pr += 1 if acc_a['gradboost'] - acc_b['gradboost'] >= 0 else 0\n",
        "        pr += 1 if acc_a['randomforest'] - acc_b['randomforest'] >= 0 else 0\n",
        "\n",
        "        print('Количество моделей с приростом качества или без ухудшения:', pr)\n",
        "        print('------------------------------------------------------------')\n",
        "    except Exception:\n",
        "        print('ошибка на номере', )"
      ],
      "metadata": {
        "id": "m0jRRdipOYvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "'linear_svm': 0.8578199052132701, 'logistic': 0.8649289099526066, 'linear_discriminant_analysis': 0.8554502369668247, 'gradboost': 0.8388625592417062, 'randomforest': 0.8483412322274881"
      ],
      "metadata": {
        "id": "LzMUM2AUXw_d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Сомнительно, нооо ОКЭЙ..."
      ],
      "metadata": {
        "id": "ukHetAQQ6NUY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype(float)\n",
        "X_test = X_test.astype(float)"
      ],
      "metadata": {
        "id": "rTTsqBxj5Nsz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[np.isnan(X_train)] = 0\n",
        "X_test[np.isnan(X_test)] = 0"
      ],
      "metadata": {
        "id": "f-lcEiIW4fF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf9K8uz64t7Y",
        "outputId": "045877de-ab01-4349-faf0-868de7188262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "pipe_sc.fit(X_train, y_train)\n",
        "X_train = pipe_sc.transform(X_train)\n",
        "X_test = pipe_sc.transform(X_test)"
      ],
      "metadata": {
        "id": "NfpHw9D6mAqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Продолжение"
      ],
      "metadata": {
        "id": "SxkRJ4MZ6S8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "calc_accuracy(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWprNynF7zwS",
        "outputId": "3ab7ed85-8a2f-4af0-b61f-8610a63c0c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'linear_svm': 0.2344149861807759,\n",
              " 'logistic': 0.8017197256628109,\n",
              " 'linear_discriminant_analysis': 0.8358071450506704,\n",
              " 'gradboost': 0.8694851059473846,\n",
              " 'randomforest': 0.8560753403623708}"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_chgd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvEFIzCnSHqt",
        "outputId": "0e2a6980-cab7-4808-c646-702ac392a6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11984, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CJ-zuQESPlZ",
        "outputId": "b59866ea-c3ae-4af9-83c1-632f98822773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1600, 698)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans = FeatProcessing('class', 3, {'thr': 0.5},\n",
        "                              sel_for_gen_kwargs={'typ': 'lsvm'}, sel_from_gen_kwargs={'typ': 'rtree'})\n",
        "trans.fit(X_train, y_train)\n",
        "X_train_chgd = trans.transform(X_train)\n",
        "X_test_chgd = trans.transform(X_test)\n",
        "calc_accuracy(X_train_chgd, y_train, X_test_chgd, y_test)"
      ],
      "metadata": {
        "id": "YoytUBBPEad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "095031ca-08e8-4158-e900-3e12d31577c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 419)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_svm :  0.9833\n",
            "ridge :  -0.0027216683383486373\n",
            "gradboost :  0.9821\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Ill-conditioned matrix (rcond=1.58848e-47): result may not be accurate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logistic :  0.9833\n",
            "randomforest :  0.9833\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'linear_svm': 0.9833,\n",
              " 'ridge': -0.0027216683383486373,\n",
              " 'gradboost': 0.9821,\n",
              " 'logistic': 0.9833,\n",
              " 'randomforest': 0.9833}"
            ]
          },
          "metadata": {},
          "execution_count": 232
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Dataset 1471\n",
        "\n",
        "***3 folds; 1:lsvm, 2:rtree; thr = 0.5*** <br>\n",
        "{'linear_svm': 0.5817757009345794, <br>\n",
        " 'ridge': -0.0019466091913913353, <br>\n",
        " 'gradboost': 0.8334445927903872, <br>\n",
        " 'logistic': 0.4706275033377837, <br>\n",
        " 'randomforest': 0.9329105473965287}\n",
        "\n",
        " ***without transformers*** <br>\n",
        "{'linear_svm': 0.5877837116154874, <br>\n",
        " 'ridge': -0.15428406305249354, <br>\n",
        " 'gradboost': 0.8064085447263017, <br>\n",
        " 'logistic': 0.5684245660881175, <br>\n",
        " 'randomforest': 0.9235647530040053}"
      ],
      "metadata": {
        "id": "4dy6Y7cvHfut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Глобальный тест"
      ],
      "metadata": {
        "id": "Dg23ZhyBAKtf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "iM27brwsBaBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbDVWvW0BOux",
        "outputId": "3c61223c-a390-43bd-eaaf-d005d6183418"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openml\n",
        "import random\n",
        "\n",
        "suite_id = 218\n",
        "benchmark_suite = openml.study.get_suite(suite_id)\n",
        "\n",
        "tasks_list = benchmark_suite.tasks\n",
        "\n",
        "for task_id_i in tqdm(range(37, len(tasks_list))):\n",
        "    if not (task_id_i in [7, 20, 23, 24, 25, 36]):\n",
        "\n",
        "        task_id = tasks_list[task_id_i]\n",
        "        result = {}\n",
        "        task = openml.tasks.get_task(task_id)\n",
        "        dataset = task.get_dataset()\n",
        "\n",
        "        try:\n",
        "            random.seed(42)\n",
        "            np.random.seed(42)\n",
        "            X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
        "\n",
        "            # Заполнения пропусков\n",
        "            # null -> 0.000001\n",
        "            for col_ind in X.dtypes[X.dtypes == 'category'].index:\n",
        "                X[col_ind] = X[col_ind].cat.add_categories([0.000001])\n",
        "            X.fillna(0.000001, inplace=True)\n",
        "\n",
        "            # Получение меток классов и их строковое представление\n",
        "            class_labels = set(y)\n",
        "\n",
        "            # Создание словаря для преобразования строковых меток в числовые индексы\n",
        "            class_labels_map = {label: i for i, label in enumerate(class_labels)}\n",
        "            y_numeric = [class_labels_map[label] for label in y]\n",
        "\n",
        "            # Разделяем на трейн и тест\n",
        "            X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_numeric), test_size=0.2, random_state=42)\n",
        "\n",
        "            # Кодируем и нормируем\n",
        "            enc = CustomEncoder(categorical_args={'encoder':'target_loo'})\n",
        "            try:\n",
        "                X_train = enc.fit_transform(X_train, y_train).to_numpy()\n",
        "                X_test = enc.transform(X_test).to_numpy()\n",
        "            except Exception as e:\n",
        "                X_train = enc.fit_transform(X_train.to_numpy(), y_train)\n",
        "                X_test = enc.transform(X_test.to_numpy())\n",
        "\n",
        "            result[task_id] = {}\n",
        "\n",
        "            # Считаем точность без схемы с генерацией и отбором\n",
        "            result[task_id]['before'] = calc_accuracy_lim(X_train, y_train, X_test, y_test)\n",
        "\n",
        "            #Считаем число фолдов\n",
        "            result[task_id]['k-fold'] = 2 if X_train.shape[0] < 3000 else 3\n",
        "\n",
        "            # Применяем схему с генерацией и отбором\n",
        "            trans = FeatProcessing('class', 2 if X_train.shape[0] < 3000 else 3, {'corr_gen': True}, sel_for_gen_kwargs={'typ': 'rtree'}, sel_from_gen_kwargs={'typ': 'rtree'})\n",
        "            trans.fit(X_train, y_train)\n",
        "            X_train_chgd = trans.transform(X_train)\n",
        "            X_test_chgd = trans.transform(X_test)\n",
        "\n",
        "            # Сохраняем размеры\n",
        "            result[task_id]['train_shape'] = X_train.shape\n",
        "            result[task_id]['test_shape'] = X_test.shape\n",
        "            result[task_id]['chgd_train_shape'] = X_train_chgd.shape\n",
        "            result[task_id]['chgd_test_shape'] = X_test_chgd.shape\n",
        "\n",
        "            # Считаем точность после схемы с генерацией и отбором\n",
        "            result[task_id]['after'] = calc_accuracy_lim(X_train_chgd, y_train, X_test_chgd, y_test)\n",
        "\n",
        "            with open('drive/MyDrive/ML_test/science/new_results/result_' + str(task_id) + '.dat', \"wb\") as file:\n",
        "                pickle.dump(result, file)\n",
        "        except Exception as e:\n",
        "            print(\"Ошибка на задаче с номером\", task_id)\n",
        "            print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "48d6a8976d2c41b0a4c8078e15476cc9",
            "65168248f79f471ea7f77c02b27c681f",
            "aaa742a35905491db54d60802e183d60",
            "dd63f1fcb3304999b0114d34e9daae4b",
            "d497d4cd4b714f50984981d47dc6f279",
            "5462588db9e54438931f7134b0a9683f",
            "2559274361764d149887467f87f3ff27",
            "0997af8b61c1449bae87f1d7068bf26c",
            "b9e893d873ba4eb9bfe836c88ff0f68c",
            "09b7e2e8db594819819949e3c1ad0959",
            "cf5c7a672ccf420287b31399da4d5a57"
          ]
        },
        "id": "S1BdS1mxASLX",
        "outputId": "c1850766-529b-4658-b0dd-25f2bdb104d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48d6a8976d2c41b0a4c8078e15476cc9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/30 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(27572, 118)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(864, 856)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
            "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(598, 4)\n",
            "Ошибка на задаче с номером 10101\n",
            "tuple index out of range\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(36168, 16)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(26215, 9)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(54045, 42)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(46400, 9)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(78440, 28)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(552, 14)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1382, 6)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1848, 16)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(35855, 6)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(77056, 21)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8000, 7200)\n",
            "Ошибка на задаче с номером 168332\n",
            "int() argument must be a string, a bytes-like object or a real number, not 'complex'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(104051, 50)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16000, 4296)\n",
            "Ошибка на задаче с номером 168337\n",
            "int() argument must be a string, a bytes-like object or a real number, not 'complex'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16000, 4296)\n",
            "Ошибка на задаче с номером 168338\n",
            "int() argument must be a string, a bytes-like object or a real number, not 'complex'\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60800, 170)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4334, 1636)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of f AND g EVALUATIONS EXCEEDS LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8000, 2000)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6589, 800)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2387, 144)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4099, 20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(431506, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbgmDKAkkU51",
        "outputId": "641e742a-60ed-4022-bba1-f1eea93fe3a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{12: {'before': {'linear_svm': 0.75,\n",
              "   'logistic': 0.7925,\n",
              "   'linear_discriminant_analysis': 0.2825,\n",
              "   'gradboost': 0.8175,\n",
              "   'randomforest': 0.695},\n",
              "  'k-fold': 2,\n",
              "  'train_shape': (1600, 1564),\n",
              "  'test_shape': (400, 1564),\n",
              "  'chgd_train_shape': (1600, 4224),\n",
              "  'chgd_test_shape': (400, 4224),\n",
              "  'after': {'linear_svm': 0.6975,\n",
              "   'logistic': 0.1175,\n",
              "   'linear_discriminant_analysis': 0.735,\n",
              "   'gradboost': 0.7875,\n",
              "   'randomforest': 0.71}}}"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('drive/MyDrive/ML_test/science/result_AML.dat', \"wb\") as file:\n",
        "    pickle.dump(result, file)"
      ],
      "metadata": {
        "id": "sqaCG8LuB7uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Тест с гугл диск"
      ],
      "metadata": {
        "id": "tHut2w-1wzpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELQ9JfIOw8VM",
        "outputId": "c2863e85-01b5-457c-8f4d-00e6687257e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openml\n",
        "\n",
        "suite_id = 218\n",
        "benchmark_suite = openml.study.get_suite(suite_id)\n",
        "\n",
        "tasks_list = benchmark_suite.tasks"
      ],
      "metadata": {
        "id": "yvkPZkdcw3Yf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d7e3a01-c745-493e-95d2-5f65a1049ca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:openml:No permission to create OpenML directory at /root/.config/openml! This can result in OpenML-Python not working properly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tasks_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiZvpb8GydzU",
        "outputId": "58c12900-b1e2-46af-d795-734b558eb19a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3,\n",
              " 12,\n",
              " 31,\n",
              " 53,\n",
              " 3917,\n",
              " 3945,\n",
              " 7592,\n",
              " 7593,\n",
              " 9952,\n",
              " 9977,\n",
              " 9981,\n",
              " 10101,\n",
              " 14965,\n",
              " 34539,\n",
              " 146195,\n",
              " 146212,\n",
              " 146606,\n",
              " 146818,\n",
              " 146821,\n",
              " 146822,\n",
              " 146825,\n",
              " 167119,\n",
              " 167120,\n",
              " 168329,\n",
              " 168330,\n",
              " 168331,\n",
              " 168332,\n",
              " 168335,\n",
              " 168337,\n",
              " 168338,\n",
              " 168868,\n",
              " 168908,\n",
              " 168909,\n",
              " 168910,\n",
              " 168911,\n",
              " 168912,\n",
              " 189354,\n",
              " 189355,\n",
              " 189356]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for i in range(len(tasks_list)):\n",
        "    try:\n",
        "        with open('drive/MyDrive/ML_test/science/new_results/result_' + str(tasks_list[i]) + '.dat', 'rb') as f:\n",
        "            results.append(pickle.load(f))\n",
        "    except Exception:\n",
        "        pass"
      ],
      "metadata": {
        "id": "cuEdUtqfydMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lsvm_p = 0\n",
        "logistic_p = 0\n",
        "lda_p = 0\n",
        "gb_p = 0\n",
        "rf_p = 0\n",
        "for res in results:\n",
        "    lsvm_p += 1 if res[list(res.keys())[0]]['after']['linear_svm'] - res[list(res.keys())[0]]['before']['linear_svm'] >= 0 else 0\n",
        "    logistic_p += 1 if res[list(res.keys())[0]]['after']['logistic'] - res[list(res.keys())[0]]['before']['logistic'] >= 0 else 0\n",
        "    lda_p += 1 if res[list(res.keys())[0]]['after']['linear_discriminant_analysis'] - res[list(res.keys())[0]]['before']['linear_discriminant_analysis'] >= 0 else 0\n",
        "    gb_p += 1 if res[list(res.keys())[0]]['after']['gradboost'] - res[list(res.keys())[0]]['before']['gradboost'] >= 0 else 0\n",
        "    rf_p += 1 if res[list(res.keys())[0]]['after']['randomforest'] - res[list(res.keys())[0]]['before']['randomforest'] >= 0 else 0"
      ],
      "metadata": {
        "id": "9Xv8SkiK0qBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('lsvm:', lsvm_p / len(results))\n",
        "print('logistic:', logistic_p / len(results))\n",
        "print('lda:', lda_p / len(results))\n",
        "print('gb:', gb_p / len(results))\n",
        "print('rf:', rf_p / len(results))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mm8wWRb21Mh",
        "outputId": "27ed6024-c72f-4b91-b08b-fb29d3e95c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lsvm: 0.5185185185185185\n",
            "logistic: 0.5185185185185185\n",
            "lda: 0.6296296296296297\n",
            "gb: 0.7037037037037037\n",
            "rf: 0.25925925925925924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "for res in results:\n",
        "    pr = 0\n",
        "    pr += 1 if res[list(res.keys())[0]]['after']['linear_svm'] - res[list(res.keys())[0]]['before']['linear_svm'] > 0 else 0\n",
        "    pr += 1 if res[list(res.keys())[0]]['after']['logistic'] - res[list(res.keys())[0]]['before']['logistic'] > 0 else 0\n",
        "    pr += 1 if res[list(res.keys())[0]]['after']['linear_discriminant_analysis'] - res[list(res.keys())[0]]['before']['linear_discriminant_analysis'] > 0 else 0\n",
        "    pr += 1 if res[list(res.keys())[0]]['after']['gradboost'] - res[list(res.keys())[0]]['before']['gradboost'] > 0 else 0\n",
        "    pr += 1 if res[list(res.keys())[0]]['after']['randomforest'] - res[list(res.keys())[0]]['before']['randomforest'] > 0 else 0\n",
        "    if pr == 1:\n",
        "        models.append(res)"
      ],
      "metadata": {
        "id": "Z-zLqdsJ8I0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models #9952, 146822, 3917"
      ],
      "metadata": {
        "id": "XA3oa9Hy9FQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "000ac237-c16b-48c8-d0be-bf2050d4d860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{3917: {'before': {'linear_svm': 0.8554502369668247,\n",
              "    'logistic': 0.8578199052132701,\n",
              "    'linear_discriminant_analysis': 0.8436018957345972,\n",
              "    'gradboost': 0.8364928909952607,\n",
              "    'randomforest': 0.8507109004739336},\n",
              "   'k-fold': 2,\n",
              "   'train_shape': (1687, 32),\n",
              "   'test_shape': (422, 32),\n",
              "   'chgd_train_shape': (1687, 90),\n",
              "   'chgd_test_shape': (422, 90),\n",
              "   'after': {'linear_svm': 0.8507109004739336,\n",
              "    'logistic': 0.8554502369668247,\n",
              "    'linear_discriminant_analysis': 0.8412322274881516,\n",
              "    'gradboost': 0.8483412322274881,\n",
              "    'randomforest': 0.8483412322274881}}},\n",
              " {167119: {'before': {'linear_svm': 0.6767068273092369,\n",
              "    'logistic': 0.6745872378402499,\n",
              "    'linear_discriminant_analysis': 0.6751450245426149,\n",
              "    'gradboost': 0.6647701918786256,\n",
              "    'randomforest': 0.8654618473895582},\n",
              "   'k-fold': 3,\n",
              "   'train_shape': (35855, 20),\n",
              "   'test_shape': (8964, 20),\n",
              "   'chgd_train_shape': (35855, 47),\n",
              "   'chgd_test_shape': (8964, 47),\n",
              "   'after': {'linear_svm': 0.6749219098616689,\n",
              "    'logistic': 0.6734716644355199,\n",
              "    'linear_discriminant_analysis': 0.6713520749665328,\n",
              "    'gradboost': 0.6645470771976796,\n",
              "    'randomforest': 0.8694779116465864}}}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy_lim(X, y, X_t, y_t):\n",
        "  models = [('linear_svm', svm.LinearSVC(max_iter=2000, random_state=42), 'decision_function'),\n",
        "            ('logistic', linear_model.LogisticRegression(solver = 'lbfgs', random_state=42, max_iter=1000, penalty='l2', C=1), 'predict_proba'),\n",
        "            ('linear_discriminant_analysis', LinearDiscriminantAnalysis(), 'predict_proba'),\n",
        "            ('gradboost', ensemble.GradientBoostingClassifier(random_state=42, n_estimators=10), 'predict_proba'),\n",
        "            ('randomforest', ensemble.RandomForestClassifier(random_state=42), 'predict_proba')]\n",
        "  ans = {}\n",
        "  for name, model, loss_func in models:\n",
        "      model.fit(X, y)\n",
        "      ans[name] = model.score(X_t, y_t)\n",
        "  return ans"
      ],
      "metadata": {
        "id": "fQqAqzHhGm3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Плохие датасеты"
      ],
      "metadata": {
        "id": "8alrymdcuKkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# плохие датасеты 146818, 9977\n",
        "\n",
        "small_datasets = [3917]\n",
        "for task_id in small_datasets:\n",
        "    task = openml.tasks.get_task(task_id)\n",
        "    dataset = task.get_dataset()\n",
        "\n",
        "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
        "\n",
        "    # Заполнения пропусков\n",
        "    # null -> 0.000001\n",
        "    for col_ind in X.dtypes[X.dtypes == 'category'].index:\n",
        "        X[col_ind] = X[col_ind].cat.add_categories([0.000001])\n",
        "    X.fillna(0.000001, inplace=True)\n",
        "\n",
        "    # Получение меток классов и их строковое представление\n",
        "    class_labels = set(y)\n",
        "\n",
        "    # Создание словаря для преобразования строковых меток в числовые индексы\n",
        "    class_labels_map = {label: i for i, label in enumerate(class_labels)}\n",
        "    y_numeric = [class_labels_map[label] for label in y]\n",
        "\n",
        "    # Разделяем на трейн и тест\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_numeric), test_size=0.2, random_state=42)\n",
        "\n",
        "    # Кодируем категориальные\n",
        "    enc = CategoricalEncoder(encoder='binary', category_rate=0.9)\n",
        "    X_train = enc.fit_transform(X_train)\n",
        "    X_test = enc.transform(X_test)\n",
        "\n",
        "    # Ищем и нормируем вещественные\n",
        "    enc = NumericalEncoder(numeric_rate=0.9)\n",
        "    enc.fit_transform(X_train)\n",
        "    X_train = X_train.to_numpy()\n",
        "    X_test = X_test.to_numpy()\n",
        "    if enc.get_cols().shape[0] > 0:\n",
        "        pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "        pipe_sc.fit(X_train[:, enc.get_cols()])\n",
        "        X_train[:, enc.get_cols()] = pipe_sc.transform(X_train[:, enc.get_cols()])\n",
        "        X_test[:, enc.get_cols()] = pipe_sc.transform(X_test[:, enc.get_cols()])\n",
        "\n",
        "    acc_b = calc_accuracy_lim(X_train, y_train, X_test, y_test)\n",
        "    print('Номер датасета:', task_id)\n",
        "\n",
        "    # feat_gen = FeatureGenerationTransformer(thr=0.5, corr_gen=False)\n",
        "    # start_time = time.time()\n",
        "    # feat_gen.fit_transform(X_train)\n",
        "\n",
        "    # Применяем схему с генерацией и отбором\n",
        "    trans = FeatProcessing('class', 2, {'thr': 0.5}, sel_for_gen_kwargs={'typ': 'null_importance'}, sel_from_gen_kwargs={'typ': 'skb_mutual_info_classif'})\n",
        "    trans.fit(X_train, y_train)\n",
        "    X_train_gen = trans.transform(X_train)\n",
        "    X_test_gen = trans.transform(X_test)\n",
        "\n",
        "    # print(np.array_equal(X_train_gen[:,:X_train.shape[1]], X_train))\n",
        "    # X_train_gen = feat_gen.transform(X_train)\n",
        "    # X_test_gen = feat_gen.transform(X_test)\n",
        "\n",
        "    # end_time = time.time()\n",
        "    # elapsed_time = end_time - start_time\n",
        "    # print(f'Время генерации: {elapsed_time:.5f}')\n",
        "    print('Размер до генерации', X_train.shape)\n",
        "    print('Размер после генерации', X_train_gen.shape)\n",
        "\n",
        "    pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "    pipe_sc.fit(X_train_gen[:, X_train.shape[1]:])\n",
        "    X_train_gen[:, X_train.shape[1]:] = pipe_sc.transform(X_train_gen[:,  X_train.shape[1]:])\n",
        "    X_test_gen[:,  X_train.shape[1]:] = pipe_sc.transform(X_test_gen[:,  X_train.shape[1]:])\n",
        "\n",
        "    acc_a = calc_accuracy_lim(X_train_gen, y_train, X_test_gen, y_test)\n",
        "\n",
        "    # print(X_train_gen[:, 18])\n",
        "    print('Качество до генерации', acc_b)\n",
        "    print('Качество после генерации', acc_a)\n",
        "\n",
        "    pr = 0\n",
        "    pr += 1 if acc_a['linear_svm'] - acc_b['linear_svm'] > 0 else 0\n",
        "    pr += 1 if acc_a['logistic'] - acc_b['logistic'] > 0 else 0\n",
        "    pr += 1 if acc_a['linear_discriminant_analysis'] - acc_b['linear_discriminant_analysis'] > 0 else 0\n",
        "    pr += 1 if acc_a['gradboost'] - acc_b['gradboost'] > 0 else 0\n",
        "    pr += 1 if acc_a['randomforest'] - acc_b['randomforest'] > 0 else 0\n",
        "\n",
        "    print('Количество моделей с приростом качества:', pr)\n",
        "    print('------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vgm2DnldtUKk",
        "outputId": "1307de5d-403d-4087-88ed-321545ce55d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Номер датасета: 3917\n",
            "(1687, 32)\n",
            "1340.9027945872003 2256.470829304424\n",
            "f 0.5204588983792683 g <class 'numpy.float64'>\n",
            "211.6794154731324 195.3753677904606\n",
            "f -0.08015026776788932 g <class 'numpy.float64'>\n",
            "117.28792165592313 401.3891294002533\n",
            "f 1.2302995736096887 g <class 'numpy.float64'>\n",
            "207.30212224274874 82.84988021850586\n",
            "f -0.9171469588245702 g <class 'numpy.float64'>\n",
            "734.2311150176392 2142.98640766833\n",
            "f 1.0711318031387822 g <class 'numpy.float64'>\n",
            "668.0772817566758 1159.9029235657654\n",
            "f 0.5516877359198187 g <class 'numpy.float64'>\n",
            "688.4075344189187 726.9559215103509\n",
            "f 0.054484835931134276 g <class 'numpy.float64'>\n",
            "945.3644563206472 1230.5580369085073\n",
            "f 0.2636525128173277 g <class 'numpy.float64'>\n",
            "1518.6490798913874 3545.691678947129\n",
            "f 0.8479120784556261 g <class 'numpy.float64'>\n",
            "938.6118811097695 840.8451754972339\n",
            "f -0.10999451430893356 g <class 'numpy.float64'>\n",
            "128.2105503231287 899.5684000551701\n",
            "f 1.9482412558938529 g <class 'numpy.float64'>\n",
            "387.69708674179856 315.7711209227564\n",
            "f -0.20520668016432042 g <class 'numpy.float64'>\n",
            "883.8484128836935 2129.607867800398\n",
            "f 0.8794075728356834 g <class 'numpy.float64'>\n",
            "0.0 0.0\n",
            "f nan g <class 'numpy.float64'>\n",
            "0.0 0.0\n",
            "f nan g <class 'numpy.float64'>\n",
            "109.18243226408958 202.00698792934418\n",
            "f 0.6152821168461973 g <class 'numpy.float64'>\n",
            "105.43996173143387 48.67957031726837\n",
            "f -0.7728822664110808 g <class 'numpy.float64'>\n",
            "50.53226286172867 167.7750506401062\n",
            "f 1.20001209703694 g <class 'numpy.float64'>\n",
            "0.0 0.0\n",
            "f nan g <class 'numpy.float64'>\n",
            "42.45979729294777 2.8425300121307373\n",
            "f -2.703863177248617 g <class 'numpy.float64'>\n",
            "148.9982771500945 297.4944797158241\n",
            "f 0.6914609261088994 g <class 'numpy.float64'>\n",
            "121.01768787205219 116.37665069103241\n",
            "f -0.039104795936621035 g <class 'numpy.float64'>\n",
            "168.2983205728233 214.44279825687408\n",
            "f 0.24230490563502974 g <class 'numpy.float64'>\n",
            "0.0 0.0\n",
            "f nan g <class 'numpy.float64'>\n",
            "10.604537218809128 13.576399803161621\n",
            "f 0.2470510277133449 g <class 'numpy.float64'>\n",
            "0.0 0.0\n",
            "f nan g <class 'numpy.float64'>\n",
            "17.347289741039276 5.412010192871094\n",
            "f -1.1648156896093755 g <class 'numpy.float64'>\n",
            "514.5698370188475 1453.1843335417216\n",
            "f 1.0381812359182105 g <class 'numpy.float64'>\n",
            "580.9833396892063 1003.8230132674798\n",
            "f 0.5468489218991054 g <class 'numpy.float64'>\n",
            "530.5856043817475 4820.943618687801\n",
            "f 2.20674364889003 g <class 'numpy.float64'>\n",
            "487.6620262149954 1905.1345469653606\n",
            "f 1.36268531671029 g <class 'numpy.float64'>\n",
            "104.30048026144505 86.95878982543945\n",
            "f -0.1818416403467585 g <class 'numpy.float64'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-1eea5e32194c>:91: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  feat_score = np.log(actual_imp/_sf_p)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found array with 0 feature(s) (shape=(844, 0)) while a minimum of 1 is required by StandardScaler.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-4f34559a4918>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# Применяем схему с генерацией и отбором\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mtrans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatProcessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'thr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel_for_gen_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'typ'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'null_importance'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msel_from_gen_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'typ'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'skb_mutual_info_classif'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0mX_train_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mX_test_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-022bb445aed7>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mpipe_sc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'std_scaler'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mX_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_gen\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mX_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;31m#2 SEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel_from_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureSelectionTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msel_from_gen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 445\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    446\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    862\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mensure_min_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 940\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    941\u001b[0m                 \u001b[0;34m\"Found array with %d feature(s) (shape=%s) while\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(844, 0)) while a minimum of 1 is required by StandardScaler."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество до генерации {'linear_svm': 0.8554502369668247, 'logistic': 0.8578199052132701, 'linear_discriminant_analysis': 0.8436018957345972, 'gradboost': 0.8364928909952607, 'randomforest': 0.8507109004739336} <br>\n",
        "Качество после генерации {'linear_svm': 0.8554502369668247, 'logistic': 0.8530805687203792, 'linear_discriminant_analysis': 0.8436018957345972, 'gradboost': 0.8483412322274881, 'randomforest': 0.8388625592417062}"
      ],
      "metadata": {
        "id": "teIQ9kEX2Log"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "######Результаты обычной генерации"
      ],
      "metadata": {
        "id": "1ZiAxfhruCWI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = openml.tasks.get_task(9952)\n",
        "task"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_H2YeXRPMFIc",
        "outputId": "7eda1584-d55a-4ee9-99a9-22f6a9b72f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OpenML Classification Task\n",
              "==========================\n",
              "Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION\n",
              "Task ID..............: 9952\n",
              "Task URL.............: https://www.openml.org/t/9952\n",
              "Estimation Procedure.: crossvalidation\n",
              "Target Feature.......: Class\n",
              "# of Classes.........: 2\n",
              "Cost Matrix..........: Available"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_datasets = [9952, 146822, 3917]\n",
        "for task_id in small_datasets:\n",
        "    task = openml.tasks.get_task(task_id)\n",
        "    dataset = task.get_dataset()\n",
        "\n",
        "    X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute)\n",
        "\n",
        "    # Заполнения пропусков\n",
        "    # null -> 0.000001\n",
        "    for col_ind in X.dtypes[X.dtypes == 'category'].index:\n",
        "        X[col_ind] = X[col_ind].cat.add_categories([0.000001])\n",
        "    X.fillna(0.000001, inplace=True)\n",
        "\n",
        "    # Получение меток классов и их строковое представление\n",
        "    class_labels = set(y)\n",
        "\n",
        "    # Создание словаря для преобразования строковых меток в числовые индексы\n",
        "    class_labels_map = {label: i for i, label in enumerate(class_labels)}\n",
        "    y_numeric = [class_labels_map[label] for label in y]\n",
        "\n",
        "    # Разделяем на трейн и тест\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, np.array(y_numeric), test_size=0.2, random_state=42)\n",
        "\n",
        "    # Кодируем категориальные\n",
        "    enc = CategoricalEncoder(encoder='binary', category_rate=0.9)\n",
        "    X_train = enc.fit_transform(X_train)\n",
        "    X_test = enc.transform(X_test)\n",
        "\n",
        "    # Ищем и нормируем вещественные\n",
        "    enc = NumericalEncoder(numeric_rate=0.9)\n",
        "    enc.fit_transform(X_train)\n",
        "    X_train = X_train.to_numpy()\n",
        "    X_test = X_test.to_numpy()\n",
        "    if enc.get_cols().shape[0] > 0:\n",
        "        pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "        pipe_sc.fit(X_train[:, enc.get_cols()])\n",
        "        X_train[:, enc.get_cols()] = pipe_sc.transform(X_train[:, enc.get_cols()])\n",
        "        X_test[:, enc.get_cols()] = pipe_sc.transform(X_test[:, enc.get_cols()])\n",
        "\n",
        "    acc_b = calc_accuracy_lim(X_train, y_train, X_test, y_test)\n",
        "    print('Номер датасета:', task_id)\n",
        "\n",
        "    feat_gen = FeatureGenerationTransformer(thr=0.5, corr_gen=False)\n",
        "    start_time = time.time()\n",
        "    feat_gen.fit_transform(X_train)\n",
        "\n",
        "    X_train_gen = feat_gen.transform(X_train)\n",
        "    X_test_gen = feat_gen.transform(X_test)\n",
        "\n",
        "    end_time = time.time()\n",
        "    elapsed_time = end_time - start_time\n",
        "    print(f'Время генерации: {elapsed_time:.5f}')\n",
        "    print('Размер до генерации', X_train.shape)\n",
        "    print('Размер после генерации', X_train_gen.shape)\n",
        "\n",
        "    pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "    pipe_sc.fit(X_train_gen[:, X_train.shape[1]:])\n",
        "    X_train_gen[:, X_train.shape[1]:] = pipe_sc.transform(X_train_gen[:,  X_train.shape[1]:])\n",
        "    X_test_gen[:,  X_train.shape[1]:] = pipe_sc.transform(X_test_gen[:,  X_train.shape[1]:])\n",
        "\n",
        "    acc_a = calc_accuracy_lim(X_train_gen, y_train, X_test_gen, y_test)\n",
        "\n",
        "    # print(X_train_gen[:, 18])\n",
        "    print('Качество до генерации', acc_b)\n",
        "    print('Качество после генерации', acc_a)\n",
        "\n",
        "    pr = 0\n",
        "    pr += 1 if acc_a['linear_svm'] - acc_b['linear_svm'] > 0 else 0\n",
        "    pr += 1 if acc_a['logistic'] - acc_b['logistic'] > 0 else 0\n",
        "    pr += 1 if acc_a['linear_discriminant_analysis'] - acc_b['linear_discriminant_analysis'] > 0 else 0\n",
        "    pr += 1 if acc_a['gradboost'] - acc_b['gradboost'] > 0 else 0\n",
        "    pr += 1 if acc_a['randomforest'] - acc_b['randomforest'] > 0 else 0\n",
        "\n",
        "    print('Количество моделей с приростом качества:', pr)\n",
        "    print('------------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eNrtIw4g-1Wc",
        "outputId": "ddacc6ff-447e-4dd4-d968-7b2655b57489"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Номер датасета: 9952\n",
            "Время генерации: 0.02014\n",
            "Размер до генерации (4323, 5)\n",
            "Размер после генерации (4323, 50)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Качество до генерации {'linear_svm': 0.7604070305272895, 'logistic': 0.755781683626272, 'linear_discriminant_analysis': 0.7622571692876966, 'gradboost': 0.793709528214616, 'randomforest': 0.9111933395004626}\n",
            "Качество после генерации {'linear_svm': 0.8251618871415356, 'logistic': 0.8279370952821462, 'linear_discriminant_analysis': 0.8233117483811286, 'gradboost': 0.8001850138760407, 'randomforest': 0.9074930619796485}\n",
            "Количество моделей с приростом качества: 4\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Номер датасета: 146822\n",
            "Время генерации: 0.02275\n",
            "Размер до генерации (1848, 16)\n",
            "Размер после генерации (1848, 160)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-179-21276b9f1a4c>:180: RuntimeWarning: overflow encountered in sinh\n",
            "  X[:, self.desc_dict['s_sinh'][1]] =  np.sinh(X[:,self.desc_dict['s_sinh'][0]])\n",
            "<ipython-input-179-21276b9f1a4c>:184: RuntimeWarning: overflow encountered in cosh\n",
            "  X[:, self.desc_dict['s_cosh'][1]] =  np.cosh(X[:,self.desc_dict['s_cosh'][0]])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Качество до генерации {'linear_svm': 0.6926406926406926, 'logistic': 0.8831168831168831, 'linear_discriminant_analysis': 0.816017316017316, 'gradboost': 0.8636363636363636, 'randomforest': 0.9199134199134199}\n",
            "Качество после генерации {'linear_svm': 0.7575757575757576, 'logistic': 0.8874458874458875, 'linear_discriminant_analysis': 0.8874458874458875, 'gradboost': 0.8831168831168831, 'randomforest': 0.9134199134199135}\n",
            "Количество моделей с приростом качества: 4\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py:3553: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
            "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
            "  return datasets.get_dataset(self.dataset_id)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Номер датасета: 3917\n",
            "Время генерации: 0.03634\n",
            "Размер до генерации (1687, 32)\n",
            "Размер после генерации (1687, 320)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-179-21276b9f1a4c>:180: RuntimeWarning: overflow encountered in sinh\n",
            "  X[:, self.desc_dict['s_sinh'][1]] =  np.sinh(X[:,self.desc_dict['s_sinh'][0]])\n",
            "<ipython-input-179-21276b9f1a4c>:184: RuntimeWarning: overflow encountered in cosh\n",
            "  X[:, self.desc_dict['s_cosh'][1]] =  np.cosh(X[:,self.desc_dict['s_cosh'][0]])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Качество до генерации {'linear_svm': 0.7701421800947867, 'logistic': 0.8412322274881516, 'linear_discriminant_analysis': 0.8436018957345972, 'gradboost': 0.8364928909952607, 'randomforest': 0.8507109004739336}\n",
            "Качество после генерации {'linear_svm': 0.8199052132701422, 'logistic': 0.8578199052132701, 'linear_discriminant_analysis': 0.8649289099526066, 'gradboost': 0.8436018957345972, 'randomforest': 0.8601895734597157}\n",
            "Количество моделей с приростом качества: 5\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SIN AND COS\n",
        "\n",
        "id = 9952 <br>\n",
        "Качество до генерации {'linear_svm': 0.7604070305272895, 'logistic': 0.755781683626272, 'linear_discriminant_analysis': 0.7622571692876966, 'gradboost': 0.793709528214616, 'randomforest': 0.9111933395004626} <br>\n",
        "Качество после генерации {'linear_svm': 0.8140610545790934, 'logistic': 0.8094357076780758, 'linear_discriminant_analysis': 0.8094357076780758, 'gradboost': 0.8001850138760407, 'randomforest': 0.910268270120259}\n",
        "\n",
        "id = 146822 <br>\n",
        "Качество до генерации {'linear_svm': 0.6926406926406926, 'logistic': 0.8831168831168831, 'linear_discriminant_analysis': 0.816017316017316, 'gradboost': 0.8636363636363636, 'randomforest': 0.9199134199134199} <br>\n",
        "Качество после генерации {'linear_svm': 0.6493506493506493, 'logistic': 0.8679653679653679, 'linear_discriminant_analysis': 0.8463203463203464, 'gradboost': 0.8787878787878788, 'randomforest': 0.9177489177489178}\n",
        "\n",
        "id = 3917 <br>\n",
        "Качество до генерации {'linear_svm': 0.7701421800947867, 'logistic': 0.8412322274881516, 'linear_discriminant_analysis': 0.8436018957345972, 'gradboost': 0.8364928909952607, 'randomforest': 0.8507109004739336} <br>\n",
        "Качество после генерации {'linear_svm': 0.7748815165876777, 'logistic': 0.8459715639810427, 'linear_discriminant_analysis': 0.8388625592417062, 'gradboost': 0.8459715639810427, 'randomforest': 0.8672985781990521}"
      ],
      "metadata": {
        "id": "GVvR8t8SIWmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "EXP\n",
        "\n",
        "id = 9952 <br>\n",
        "Качество до генерации {'linear_svm': 0.7604070305272895, 'logistic': 0.755781683626272, 'linear_discriminant_analysis': 0.7622571692876966, 'gradboost': 0.793709528214616, 'randomforest': 0.9111933395004626} <br>\n",
        "Качество после генерации {'linear_svm': 0.7798334875115633, 'logistic': 0.786308973172988, 'linear_discriminant_analysis': 0.7687326549491211, 'gradboost': 0.793709528214616, 'randomforest': 0.9000925069380203}\n",
        "\n",
        "id = 146822 <br>\n",
        "Качество до генерации {'linear_svm': 0.6926406926406926, 'logistic': 0.8831168831168831, 'linear_discriminant_analysis': 0.816017316017316, 'gradboost': 0.8636363636363636, 'randomforest': 0.9199134199134199} <br>\n",
        "Качество после генерации {'linear_svm': 0.7142857142857143, 'logistic': 0.8679653679653679, 'linear_discriminant_analysis': 0.8203463203463204, 'gradboost': 0.8636363636363636, 'randomforest': 0.9242424242424242}\n",
        "\n",
        "id = 3917 <br>\n",
        "Качество до генерации {'linear_svm': 0.7701421800947867, 'logistic': 0.8412322274881516, 'linear_discriminant_analysis': 0.8436018957345972, 'gradboost': 0.8364928909952607, 'randomforest': 0.8507109004739336} <br>\n",
        "Качество после генерации {'linear_svm': 0.8341232227488151, 'logistic': 0.8554502369668247, 'linear_discriminant_analysis': 0.8293838862559242, 'gradboost': 0.8364928909952607, 'randomforest': 0.8507109004739336}"
      ],
      "metadata": {
        "id": "kYDcjN3OEKx5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "X^2\n",
        "\n",
        "id = 9952 <br>\n",
        "Качество до генерации {'linear_svm': 0.7604070305272895, 'logistic': 0.755781683626272, 'linear_discriminant_analysis': 0.7622571692876966, 'gradboost': 0.793709528214616, 'randomforest': 0.9111933395004626} <br>\n",
        "Качество после генерации {'linear_svm': 0.7844588344125809, 'logistic': 0.7816836262719704, 'linear_discriminant_analysis': 0.7752081406105458, 'gradboost': 0.7974098057354302, 'randomforest': 0.906567992599445}\n",
        "\n",
        "id = 146822 <br>\n",
        "Качество до генерации {'linear_svm': 0.6926406926406926, 'logistic': 0.8831168831168831, 'linear_discriminant_analysis': 0.816017316017316, 'gradboost': 0.8636363636363636, 'randomforest': 0.9199134199134199} <br>\n",
        "Качество после генерации {'linear_svm': 0.6558441558441559, 'logistic': 0.8874458874458875, 'linear_discriminant_analysis': 0.854978354978355, 'gradboost': 0.8766233766233766, 'randomforest': 0.9177489177489178}\n",
        "\n",
        "id = 3917 <br>\n",
        "Качество до генерации {'linear_svm': 0.7701421800947867, 'logistic': 0.8412322274881516, 'linear_discriminant_analysis': 0.8436018957345972, 'gradboost': 0.8364928909952607, 'randomforest': 0.8507109004739336} <br>\n",
        "Качество после генерации {'linear_svm': 0.8317535545023697, 'logistic': 0.8412322274881516, 'linear_discriminant_analysis': 0.8412322274881516, 'gradboost': 0.8364928909952607, 'randomforest': 0.8459715639810427}"
      ],
      "metadata": {
        "id": "bNelHuOpFTsE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С corr_gen <br>\n",
        "Качество после генерации {'linear_svm': 0.8418131359851989, 'logistic': 0.8427382053654024, 'linear_discriminant_analysis': 0.8279370952821462, 'gradboost': 0.8122109158186864, 'randomforest': 0.910268270120259}\n",
        "\n",
        "Без corr_gen <br>\n",
        "Качество после генерации {'linear_svm': 0.8251618871415356, 'logistic': 0.8279370952821462, 'linear_discriminant_analysis': 0.8233117483811286, 'gradboost': 0.8001850138760407, 'randomforest': 0.9074930619796485}"
      ],
      "metadata": {
        "id": "3hf1_3r0TEwR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С corr_gen <br>\n",
        "Качество после генерации {'linear_svm': 0.8982683982683982, 'logistic': 0.9134199134199135, 'linear_discriminant_analysis': 0.9047619047619048, 'gradboost': 0.8787878787878788, 'randomforest': 0.9264069264069265}\n",
        "\n",
        "Без corr_gen <br>\n",
        "Качество после генерации {'linear_svm': 0.7575757575757576, 'logistic': 0.8874458874458875, 'linear_discriminant_analysis': 0.8874458874458875, 'gradboost': 0.8831168831168831, 'randomforest': 0.9134199134199135}"
      ],
      "metadata": {
        "id": "MW_wWhSyamvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "С corr_gen <br>\n",
        "Качество после генерации {'linear_svm': 0.8341232227488151, 'logistic': 0.8578199052132701, 'linear_discriminant_analysis': 0.7890995260663507, 'gradboost': 0.8554502369668247, 'randomforest': 0.8554502369668247}\n",
        "\n",
        "Без corr_gen <br>\n",
        "Качество после генерации {'linear_svm': 0.8199052132701422, 'logistic': 0.8578199052132701, 'linear_discriminant_analysis': 0.8649289099526066, 'gradboost': 0.8436018957345972, 'randomforest': 0.8601895734597157}"
      ],
      "metadata": {
        "id": "qI6utYpfarRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhYHYtVfzmMC",
        "outputId": "72b4604f-aef5-4b1c-8e83-e5607c6c1379"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{3: {'before': {'linear_svm': 0.95625,\n",
              "   'logistic': 0.946875,\n",
              "   'linear_discriminant_analysis': 0.9390625,\n",
              "   'gradboost': 0.9609375,\n",
              "   'randomforest': 0.9796875},\n",
              "  'k-fold': 2,\n",
              "  'train_shape': (2556, 71),\n",
              "  'test_shape': (640, 71),\n",
              "  'chgd_train_shape': (2556, 171),\n",
              "  'chgd_test_shape': (640, 171),\n",
              "  'after': {'linear_svm': 0.8125,\n",
              "   'logistic': 0.53125,\n",
              "   'linear_discriminant_analysis': 0.9390625,\n",
              "   'gradboost': 0.9703125,\n",
              "   'randomforest': 0.9859375}}}"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Форма"
      ],
      "metadata": {
        "id": "HDHKkjY4YLuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_chgd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxtQ9gl9mqrN",
        "outputId": "4d91c88b-00dc-4fca-b29d-11bbcd7e4ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11984, 36)"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_chgd[:3, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4htt3cJomwUx",
        "outputId": "61f90254-9b8e-41a8-a458-9ef363965d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-4.20562964e-02, -1.50942490e+00, -9.64779898e-01,\n",
              "        -1.31788977e-02, -2.26177954e-01, -9.72740187e-03,\n",
              "        -7.16522515e-03, -1.81312094e-01, -9.31750721e-03,\n",
              "        -6.15838471e-01, -9.47439156e-01, -8.82342746e-01,\n",
              "        -6.23732258e-02, -2.38734958e-02,  9.58815801e-01,\n",
              "         9.92860384e-01,  5.40187774e-01,  1.76873207e-03,\n",
              "         9.30800251e-01,  5.13404515e-05,  3.28740753e-02,\n",
              "        -7.43863203e-05, -1.15704651e-02, -3.67865894e-07,\n",
              "        -7.19101866e-03, -8.46476530e-02,  1.08153693e-02,\n",
              "         1.27147355e-02],\n",
              "       [-6.89682370e-03, -2.17611921e-01, -8.43409364e-02,\n",
              "        -7.81352736e-03,  9.54128628e-02, -1.30211618e-02,\n",
              "        -7.36546762e-03,  5.03051066e-01, -6.31138355e-03,\n",
              "         1.02632624e-03,  2.07395622e-01, -1.78031704e-02,\n",
              "        -4.64121801e-04, -1.03256285e-02,  9.93126905e-01,\n",
              "         9.92661591e-01,  1.00102685e+00,  4.75661772e-05,\n",
              "         7.11339355e-03,  5.42501132e-05,  2.53060375e-01,\n",
              "        -3.28055538e-07,  8.68601911e-04, -3.99577452e-07,\n",
              "        -7.39272661e-03, -8.58223026e-02,  1.60281356e-03,\n",
              "         6.59000214e-04],\n",
              "       [-1.35266906e-02, -2.03013547e-01, -5.12949700e-02,\n",
              "        -8.95724803e-03, -1.61922479e-01, -6.43364199e-03,\n",
              "        -1.16522117e-02, -2.95061038e-02, -6.31138355e-03,\n",
              "         8.92316919e-02, -2.61522527e-02, -1.79805559e-01,\n",
              "        -1.71800983e-02, -1.45298249e-02,  9.86564384e-01,\n",
              "         9.88415412e-01,  1.09333394e+00,  1.82971358e-04,\n",
              "         2.63117395e-03,  1.35774037e-04,  8.70610162e-04,\n",
              "        -2.47499695e-06, -4.24542755e-03, -1.58206782e-06,\n",
              "        -1.17206307e-02, -1.07945411e-01,  2.36555683e-03,\n",
              "         4.59461769e-04]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osZif_Hjm4pJ",
        "outputId": "db3ede4d-71b9-49ec-e741-aceaeefcbab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11984, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Тесты без схемы"
      ],
      "metadata": {
        "id": "G7S-EeUYepJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение меток классов и их строковое представление\n",
        "class_labels = set(y)\n",
        "# Создание словаря для преобразования строковых меток в числовые индексы\n",
        "class_labels_map = {label: i for i, label in enumerate(class_labels)}\n",
        "y_numeric = [class_labels_map[label] for label in y]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_numeric, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "93rEGzyTsWGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "9Co4hw3D8Urc",
        "outputId": "7012317a-0066-4885-95da-e9829ef026d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      loc  v(g)  ev(g)  iv(g)      n        v     l      d      i         e  \\\n",
              "220   4.0   1.0    1.0    1.0    4.0     8.00  0.67   1.50   5.33     12.00   \n",
              "69    7.0   1.0    1.0    1.0   29.0    67.34  0.12   8.25   8.16    555.52   \n",
              "374  50.0   3.0    1.0    3.0  124.0   614.32  0.06  15.89  38.66   9760.87   \n",
              "305  12.0   2.0    1.0    2.0   18.0    64.53  0.17   6.00  10.75    387.18   \n",
              "173  97.0   8.0    7.0    8.0  245.0  1375.60  0.05  19.60  70.18  26961.84   \n",
              "..    ...   ...    ...    ...    ...      ...   ...    ...    ...       ...   \n",
              "71    4.0   1.0    1.0    1.0    4.0     8.00  0.67   1.50   5.33     12.00   \n",
              "106  15.0   6.0    1.0    5.0   44.0   179.85  0.23   4.36  41.22    784.79   \n",
              "270  20.0   2.0    1.0    2.0   32.0   130.80  0.16   6.19  21.14    809.32   \n",
              "435  76.0   9.0    5.0    6.0  185.0  1064.65  0.05  20.36  52.30  21673.32   \n",
              "102   4.0   1.0    1.0    1.0    4.0     8.00  0.67   1.50   5.33     12.00   \n",
              "\n",
              "     ...        t  lOCode  lOComment  lOBlank  lOCodeAndComment  uniq_Op  \\\n",
              "220  ...     0.67     2.0          0        0                 0      3.0   \n",
              "69   ...    30.86     5.0          0        0                 0      2.0   \n",
              "374  ...   542.27    39.0          2        4                 0     13.0   \n",
              "305  ...    21.51     8.0          0        1                 0      8.0   \n",
              "173  ...  1497.88    72.0          1       20                 0     14.0   \n",
              "..   ...      ...     ...        ...      ...               ...      ...   \n",
              "71   ...     0.67     2.0          0        0                 0      3.0   \n",
              "106  ...    43.60    13.0          0        0                 0      6.0   \n",
              "270  ...    44.96    16.0          0        1                 0      9.0   \n",
              "435  ...  1204.07    56.0          3       10                 4     19.0   \n",
              "102  ...     0.67     2.0          0        0                 0      3.0   \n",
              "\n",
              "     uniq_Opnd  total_Op  total_Opnd  branchCount  \n",
              "220        1.0       3.0         1.0          1.0  \n",
              "69        10.0       8.0        11.0          1.0  \n",
              "374       18.0      80.0        44.0          5.0  \n",
              "305        4.0      12.0         6.0          3.0  \n",
              "173       35.0     147.0        98.0         15.0  \n",
              "..         ...       ...         ...          ...  \n",
              "71         1.0       3.0         1.0          1.0  \n",
              "106       11.0      28.0        16.0         11.0  \n",
              "270        8.0      21.0        11.0          3.0  \n",
              "435       35.0     110.0        75.0         17.0  \n",
              "102        1.0       3.0         1.0          1.0  \n",
              "\n",
              "[417 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c42a22f0-0f64-4248-a296-aabffa283e91\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loc</th>\n",
              "      <th>v(g)</th>\n",
              "      <th>ev(g)</th>\n",
              "      <th>iv(g)</th>\n",
              "      <th>n</th>\n",
              "      <th>v</th>\n",
              "      <th>l</th>\n",
              "      <th>d</th>\n",
              "      <th>i</th>\n",
              "      <th>e</th>\n",
              "      <th>...</th>\n",
              "      <th>t</th>\n",
              "      <th>lOCode</th>\n",
              "      <th>lOComment</th>\n",
              "      <th>lOBlank</th>\n",
              "      <th>lOCodeAndComment</th>\n",
              "      <th>uniq_Op</th>\n",
              "      <th>uniq_Opnd</th>\n",
              "      <th>total_Op</th>\n",
              "      <th>total_Opnd</th>\n",
              "      <th>branchCount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.50</td>\n",
              "      <td>5.33</td>\n",
              "      <td>12.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.67</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>67.34</td>\n",
              "      <td>0.12</td>\n",
              "      <td>8.25</td>\n",
              "      <td>8.16</td>\n",
              "      <td>555.52</td>\n",
              "      <td>...</td>\n",
              "      <td>30.86</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>50.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>614.32</td>\n",
              "      <td>0.06</td>\n",
              "      <td>15.89</td>\n",
              "      <td>38.66</td>\n",
              "      <td>9760.87</td>\n",
              "      <td>...</td>\n",
              "      <td>542.27</td>\n",
              "      <td>39.0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>12.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>64.53</td>\n",
              "      <td>0.17</td>\n",
              "      <td>6.00</td>\n",
              "      <td>10.75</td>\n",
              "      <td>387.18</td>\n",
              "      <td>...</td>\n",
              "      <td>21.51</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>97.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>245.0</td>\n",
              "      <td>1375.60</td>\n",
              "      <td>0.05</td>\n",
              "      <td>19.60</td>\n",
              "      <td>70.18</td>\n",
              "      <td>26961.84</td>\n",
              "      <td>...</td>\n",
              "      <td>1497.88</td>\n",
              "      <td>72.0</td>\n",
              "      <td>1</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>147.0</td>\n",
              "      <td>98.0</td>\n",
              "      <td>15.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.50</td>\n",
              "      <td>5.33</td>\n",
              "      <td>12.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.67</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>15.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>179.85</td>\n",
              "      <td>0.23</td>\n",
              "      <td>4.36</td>\n",
              "      <td>41.22</td>\n",
              "      <td>784.79</td>\n",
              "      <td>...</td>\n",
              "      <td>43.60</td>\n",
              "      <td>13.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>20.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>130.80</td>\n",
              "      <td>0.16</td>\n",
              "      <td>6.19</td>\n",
              "      <td>21.14</td>\n",
              "      <td>809.32</td>\n",
              "      <td>...</td>\n",
              "      <td>44.96</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>76.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>185.0</td>\n",
              "      <td>1064.65</td>\n",
              "      <td>0.05</td>\n",
              "      <td>20.36</td>\n",
              "      <td>52.30</td>\n",
              "      <td>21673.32</td>\n",
              "      <td>...</td>\n",
              "      <td>1204.07</td>\n",
              "      <td>56.0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>4</td>\n",
              "      <td>19.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>110.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>0.67</td>\n",
              "      <td>1.50</td>\n",
              "      <td>5.33</td>\n",
              "      <td>12.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.67</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>417 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c42a22f0-0f64-4248-a296-aabffa283e91')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c42a22f0-0f64-4248-a296-aabffa283e91 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c42a22f0-0f64-4248-a296-aabffa283e91');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-af2250e1-d7ee-4846-b3c6-428d68c123d6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-af2250e1-d7ee-4846-b3c6-428d68c123d6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-af2250e1-d7ee-4846-b3c6-428d68c123d6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "X_train"
            }
          },
          "metadata": {},
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "VpSJiK4DsnZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(X, y, X_t, y_t):\n",
        "  models = [('linear_svm', svm.LinearSVC(max_iter=2000, random_state=42), 'decision_function'), ('ridge', linear_model.Ridge(random_state=42), 'predict'),\n",
        "            ('gradboost', ensemble.GradientBoostingClassifier(random_state=42), 'predict_proba'), ('logistic', linear_model.LogisticRegression(tol = 1e-4, solver = 'newton-cholesky', random_state=42), 'predict_proba'),\n",
        "            ('randomforest', ensemble.RandomForestClassifier(random_state=42), 'predict_proba')]\n",
        "  for name, model, loss_func in models:\n",
        "    model.fit(X, y)\n",
        "    print(name, ': ', model.score(X_t, y_t))"
      ],
      "metadata": {
        "id": "1--50xf6s_-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_accuracy(X_train, y_train, X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tg4HYIczAWDS",
        "outputId": "e03862f1-90aa-4c1a-f5b9-101e7c1f18e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_svm :  0.7333333333333333\n",
            "ridge :  0.17821781887733434\n",
            "gradboost :  0.7714285714285715\n",
            "logistic :  0.819047619047619\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #13. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "randomforest :  0.780952380952381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_gen = FeatureGenerationTransformer(thr=0.5)\n",
        "start_time = time.time()\n",
        "X_train_gen = feat_gen.fit_transform(np.array(X_train))\n",
        "X_test_gen = feat_gen.transform(np.array(X_test))\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f'Время генерации: {elapsed_time:.5f}')\n",
        "print('Размер до генерации', X_train.shape)\n",
        "print('Размер после генерации', X_train_gen.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7l4zvbJyaBd",
        "outputId": "bdc42b93-028b-4149-ddf8-50e59e034d89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время генерации: 0.04655\n",
            "Размер до генерации (417, 21)\n",
            "Размер после генерации (417, 831)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INF = 1e30\n",
        "X_train_gen = np.clip(X_train_gen, -INF, INF)\n",
        "X_test_gen = np.clip(X_test_gen, -INF, INF)"
      ],
      "metadata": {
        "id": "RnvIxxUo9MCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_accuracy(X_train_gen, y_train, X_test_gen, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBHsJNCQ9EYc",
        "outputId": "54f51b6d-c523-447f-a830-57a0ab80c6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_ridge.py:255: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_svm :  0.45714285714285713\n",
            "ridge :  -3537520734.514072\n",
            "gradboost :  0.8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #1. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Ill-conditioned matrix (rcond=5.03664e-66): result may not be accurate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:195: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logistic :  0.8571428571428571\n",
            "randomforest :  0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "linear_svm :  0.45714285714285713<br>\n",
        "ridge :  -3537520734.514072<br>\n",
        "gradboost :  0.8<br>\n",
        "logistic :  0.8571428571428571<br>\n",
        "randomforest :  0.8"
      ],
      "metadata": {
        "id": "_co269jxaZIJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_sc = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler())])\n",
        "pipe_sc.fit(X_train, y_train)\n",
        "X_train_sc = pipe_sc.transform(X_train)\n",
        "X_test_sc = pipe_sc.transform(X_test)"
      ],
      "metadata": {
        "id": "Sgf4HwjXFO2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calc_accuracy(X_train_sc, y_train, X_test_sc, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKh2RJThFVjP",
        "outputId": "9db36723-32bd-49ef-d581-b9dde77050ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_svm :  0.8380952380952381\n",
            "ridge :  0.20326438493283838\n",
            "gradboost :  0.7714285714285715\n",
            "logistic :  0.8571428571428571\n",
            "randomforest :  0.7904761904761904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_m = pipeline.Pipeline([('std_scaler',preprocessing.StandardScaler()), ('feat_gen', FeatureGenerationTransformer(thr=0.5)), ('feat_sel', FeatureSelectionTransformer('rtree', X_train.shape[1]))])\n",
        "pipe_m.fit(X_train, y_train)\n",
        "X_train_m = pipe_m.transform(X_train)\n",
        "X_test_m = pipe_m.transform(X_test)"
      ],
      "metadata": {
        "id": "zjSQ3FjfEcOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_m.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P5eMB8yE8oO",
        "outputId": "96afb940-20ad-482d-aa0b-25a45fd74fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 21)"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "calc_accuracy(X_train_m, y_train, X_test_m, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeSR0_3aFDOS",
        "outputId": "4897a582-d916-4bd9-edb6-ae2c9ff3bca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "linear_svm :  0.819047619047619\n",
            "ridge :  -6.944000166999643\n",
            "gradboost :  0.7714285714285715\n",
            "logistic :  0.8285714285714286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_glm/_newton_solver.py:491: LinAlgWarning: The inner solver of NewtonCholeskySolver stumbled upon a singular or very ill-conditioned Hessian matrix at iteration #19. It will now resort to lbfgs instead.\n",
            "Further options are to use another solver or to avoid such situation in the first place. Possible remedies are removing collinear features of X or increasing the penalization strengths.\n",
            "The original Linear Algebra message was:\n",
            "Matrix is singular.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "randomforest :  0.7523809523809524\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Остальное\n"
      ],
      "metadata": {
        "id": "xSXMko7RMRI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feat_gen.desc_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20KHxe6enIyt",
        "outputId": "9ce49a1e-02c6-4fd4-c28d-bc5c56962fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'s_exp': [array([ 1, 10, 11, 90, 98, 99]),\n",
              "  array([100, 101, 102, 103, 104, 105])],\n",
              " 's_^2': [array([ 1, 10, 11, 90, 98, 99]),\n",
              "  array([106, 107, 108, 109, 110, 111])],\n",
              " 's_^3': [array([ 1, 10, 11, 90, 98, 99]),\n",
              "  array([112, 113, 114, 115, 116, 117])],\n",
              " 's_log': [array([10, 90, 98]), array([118, 119, 120])],\n",
              " 's_^0.5': [array([10, 90, 98]), array([121, 122, 123])],\n",
              " 'p_*': [array([[10, 90],\n",
              "         [10, 98],\n",
              "         [90, 98]]),\n",
              "  array([124, 125, 126])],\n",
              " 'p_/': [array([[10, 90],\n",
              "         [90, 10],\n",
              "         [10, 98],\n",
              "         [98, 10],\n",
              "         [90, 98],\n",
              "         [98, 90]]),\n",
              "  array([127, 128, 129, 130, 131, 132])],\n",
              " 'p_+': [array([[90, 10]]), array([133])],\n",
              " 'p_-': [array([[90, 10],\n",
              "         [10, 90]]),\n",
              "  array([134, 135])]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'df':12, 'rt': 44}\n",
        "for k, v in d.items():\n",
        "    print(k, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSxoyJ0haI3u",
        "outputId": "3b532cc7-a636-447b-9e04-4dde79cdee87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df 12\n",
            "rt 44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\n",
        "    [1, 2, 6],\n",
        "    [3, 4, 4]\n",
        "])\n",
        "b = np.array([\n",
        "    [11, 12],\n",
        "    [13, 14]\n",
        "])\n"
      ],
      "metadata": {
        "id": "GWGboG55XPRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.array([[0,1], [11, 12]])\n",
        "c[:, 0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m45cqup-gjhd",
        "outputId": "a93c8d1c-fabc-4258-bb3b-d895fdf21067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.T[[0, 1]].T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFPGv42ggZMs",
        "outputId": "c5e385df-87fa-41c0-8209-9f658ad17e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 2],\n",
              "       [3, 4]])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.prod(a.T[[[1,2], [0, 2]]], axis=1).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4drgRiIeQHO",
        "outputId": "16c99e4a-7ccc-42fa-fd74-e63358b0813a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12,  6],\n",
              "       [16, 12]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "X = load_iris()['data']\n",
        "y = load_iris()['target']"
      ],
      "metadata": {
        "id": "0TPZ06QL1lyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "result = scaler.fit_transform(X_train)\n",
        "result_t = scaler.transform(X_test)\n",
        "feat_gen = FeatureGenerationTransformer(thr=0.01)"
      ],
      "metadata": {
        "id": "T5Yof2aX1vZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = LogisticRegression(random_state=0, solver=\"newton-cg\")\n",
        "clf.fit(result, y_train)\n",
        "print('До генерации:', accuracy_score(y_test, clf.predict(result_t)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQ66oUPg3uGj",
        "outputId": "5698668c-d75d-4fee-ec6e-508b19337462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "До генерации: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp(np.clip(np.array([7000]), -750, 700))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbxjyoCG8Hnp",
        "outputId": "588088c9-ea6d-457e-8b62-c356b1c5c046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.01423205e+304])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.exp([750])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLd-9FIA8ivQ",
        "outputId": "7aeb02b1-bcbb-4269-8600-a33d1b2a5b09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-d2e302c63bff>:1: RuntimeWarning: overflow encountered in exp\n",
            "  np.exp([750])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([inf])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "result_2 = feat_gen.fit_transform(result)\n",
        "end_time = time.time()\n",
        "elapsed_time = end_time - start_time\n",
        "print(f'Время генерации: {elapsed_time:.5f}')\n",
        "print(result_2.shape)"
      ],
      "metadata": {
        "id": "KWD3qHlj3sxi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c936c33f-e9ea-4160-d2d1-840bd9f1f82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время генерации: 0.00145\n",
            "(120, 42)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf = LogisticRegression(random_state=0, solver=\"newton-cg\")\n",
        "clf.fit(result, y_train)\n",
        "print('После генерации:', accuracy_score(y_test, clf.predict(result_t)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjuTShlO2umv",
        "outputId": "6a0b773e-981e-40d6-c280-cfd6c0e89933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "После генерации: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8PfNY78NX6G",
        "outputId": "8df53c21-c76f-4a1c-e243-3a88c9458beb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 579)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_gen.desc_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d0jZTpvNcOJ",
        "outputId": "038171b4-165a-4e4e-a813-6b789bd54d5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'exp': [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "         51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "         68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "         85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "  array([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
              "         113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
              "         126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
              "         139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151,\n",
              "         152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164,\n",
              "         165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177,\n",
              "         178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190,\n",
              "         191, 192, 193, 194, 195, 196, 197, 198, 199])],\n",
              " '^2': [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "         51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "         68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "         85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "  array([200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212,\n",
              "         213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225,\n",
              "         226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238,\n",
              "         239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
              "         252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264,\n",
              "         265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277,\n",
              "         278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290,\n",
              "         291, 292, 293, 294, 295, 296, 297, 298, 299])],\n",
              " '^3': [array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
              "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
              "         34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
              "         51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67,\n",
              "         68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84,\n",
              "         85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]),\n",
              "  array([300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312,\n",
              "         313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
              "         326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338,\n",
              "         339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351,\n",
              "         352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364,\n",
              "         365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
              "         378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390,\n",
              "         391, 392, 393, 394, 395, 396, 397, 398, 399])],\n",
              " 'log': [array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 92]),\n",
              "  array([400, 401, 402, 403, 404, 405, 406, 407, 408, 409])],\n",
              " '^0.5': [array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 92]),\n",
              "  array([410, 411, 412, 413, 414, 415, 416, 417, 418, 419])],\n",
              " '*': [array([[ 1,  2],\n",
              "         [ 1,  3],\n",
              "         [ 1,  4],\n",
              "         [ 1,  5],\n",
              "         [ 1,  6],\n",
              "         [ 1,  7],\n",
              "         [ 1,  8],\n",
              "         [ 1,  9],\n",
              "         [ 1, 92],\n",
              "         [ 2,  3],\n",
              "         [ 2,  4],\n",
              "         [ 2,  5],\n",
              "         [ 2,  6],\n",
              "         [ 2,  7],\n",
              "         [ 2,  8],\n",
              "         [ 2,  9],\n",
              "         [ 2, 92],\n",
              "         [ 3,  4],\n",
              "         [ 3,  5],\n",
              "         [ 3,  6],\n",
              "         [ 3,  7],\n",
              "         [ 3,  8],\n",
              "         [ 3,  9],\n",
              "         [ 3, 92],\n",
              "         [ 4,  5],\n",
              "         [ 4,  6],\n",
              "         [ 4,  7],\n",
              "         [ 4,  8],\n",
              "         [ 4,  9],\n",
              "         [ 4, 92],\n",
              "         [ 5,  6],\n",
              "         [ 5,  7],\n",
              "         [ 5,  8],\n",
              "         [ 5,  9],\n",
              "         [ 5, 92],\n",
              "         [ 6,  7],\n",
              "         [ 6,  8],\n",
              "         [ 6,  9],\n",
              "         [ 6, 92],\n",
              "         [ 7,  8],\n",
              "         [ 7,  9],\n",
              "         [ 7, 92],\n",
              "         [ 8,  9],\n",
              "         [ 8, 92],\n",
              "         [ 9, 92]]),\n",
              "  array([420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432,\n",
              "         433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445,\n",
              "         446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458,\n",
              "         459, 460, 461, 462, 463, 464])],\n",
              " '/': [array([[ 1,  2],\n",
              "         [ 2,  1],\n",
              "         [ 1,  3],\n",
              "         [ 3,  1],\n",
              "         [ 1,  4],\n",
              "         [ 4,  1],\n",
              "         [ 1,  5],\n",
              "         [ 5,  1],\n",
              "         [ 1,  6],\n",
              "         [ 6,  1],\n",
              "         [ 1,  7],\n",
              "         [ 7,  1],\n",
              "         [ 1,  8],\n",
              "         [ 8,  1],\n",
              "         [ 1,  9],\n",
              "         [ 9,  1],\n",
              "         [ 1, 92],\n",
              "         [92,  1],\n",
              "         [ 2,  3],\n",
              "         [ 3,  2],\n",
              "         [ 2,  4],\n",
              "         [ 4,  2],\n",
              "         [ 2,  5],\n",
              "         [ 5,  2],\n",
              "         [ 2,  6],\n",
              "         [ 6,  2],\n",
              "         [ 2,  7],\n",
              "         [ 7,  2],\n",
              "         [ 2,  8],\n",
              "         [ 8,  2],\n",
              "         [ 2,  9],\n",
              "         [ 9,  2],\n",
              "         [ 2, 92],\n",
              "         [92,  2],\n",
              "         [ 3,  4],\n",
              "         [ 4,  3],\n",
              "         [ 3,  5],\n",
              "         [ 5,  3],\n",
              "         [ 3,  6],\n",
              "         [ 6,  3],\n",
              "         [ 3,  7],\n",
              "         [ 7,  3],\n",
              "         [ 3,  8],\n",
              "         [ 8,  3],\n",
              "         [ 3,  9],\n",
              "         [ 9,  3],\n",
              "         [ 3, 92],\n",
              "         [92,  3],\n",
              "         [ 4,  5],\n",
              "         [ 5,  4],\n",
              "         [ 4,  6],\n",
              "         [ 6,  4],\n",
              "         [ 4,  7],\n",
              "         [ 7,  4],\n",
              "         [ 4,  8],\n",
              "         [ 8,  4],\n",
              "         [ 4,  9],\n",
              "         [ 9,  4],\n",
              "         [ 4, 92],\n",
              "         [92,  4],\n",
              "         [ 5,  6],\n",
              "         [ 6,  5],\n",
              "         [ 5,  7],\n",
              "         [ 7,  5],\n",
              "         [ 5,  8],\n",
              "         [ 8,  5],\n",
              "         [ 5,  9],\n",
              "         [ 9,  5],\n",
              "         [ 5, 92],\n",
              "         [92,  5],\n",
              "         [ 6,  7],\n",
              "         [ 7,  6],\n",
              "         [ 6,  8],\n",
              "         [ 8,  6],\n",
              "         [ 6,  9],\n",
              "         [ 9,  6],\n",
              "         [ 6, 92],\n",
              "         [92,  6],\n",
              "         [ 7,  8],\n",
              "         [ 8,  7],\n",
              "         [ 7,  9],\n",
              "         [ 9,  7],\n",
              "         [ 7, 92],\n",
              "         [92,  7],\n",
              "         [ 8,  9],\n",
              "         [ 9,  8],\n",
              "         [ 8, 92],\n",
              "         [92,  8],\n",
              "         [ 9, 92],\n",
              "         [92,  9]]),\n",
              "  array([465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477,\n",
              "         478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490,\n",
              "         491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503,\n",
              "         504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516,\n",
              "         517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529,\n",
              "         530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542,\n",
              "         543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554])],\n",
              " '+': [array([[ 2,  1],\n",
              "         [ 5,  1],\n",
              "         [ 7,  3],\n",
              "         [ 7,  4],\n",
              "         [ 7,  5],\n",
              "         [ 8,  1],\n",
              "         [ 9,  1],\n",
              "         [92,  3]]),\n",
              "  array([555, 556, 557, 558, 559, 560, 561, 562])],\n",
              " '-': [array([[ 2,  1],\n",
              "         [ 1,  2],\n",
              "         [ 5,  1],\n",
              "         [ 1,  5],\n",
              "         [ 7,  3],\n",
              "         [ 3,  7],\n",
              "         [ 7,  4],\n",
              "         [ 4,  7],\n",
              "         [ 7,  5],\n",
              "         [ 5,  7],\n",
              "         [ 8,  1],\n",
              "         [ 1,  8],\n",
              "         [ 9,  1],\n",
              "         [ 1,  9],\n",
              "         [92,  3],\n",
              "         [ 3, 92]]),\n",
              "  array([563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575,\n",
              "         576, 577, 578])]}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_2[:,2] / result_2[:,1], result_2[:, 466]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs0kmWWuNwzy",
        "outputId": "a45beb3d-d096-4e0b-f6a6-44166c308d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ -0.74703308,   0.48833819,  -0.66317091, ...,  -2.08303506,\n",
              "         -4.14879989, -27.71464557]),\n",
              " array([ -0.74703308,   0.48833819,  -0.66317091, ...,  -2.08303506,\n",
              "         -4.14879989, -27.71464557]))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "0.865*0.865"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnptVhZaPesA",
        "outputId": "e8226ddb-7e30-41b3-d608-1adbf848203c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.748225"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(1,10,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpBv3aBJ0kHU",
        "outputId": "3c609e43-fdc6-4654-a7dd-e92cfcd65497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 3, 5, 7, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([[i, j] for j in range(10) for i in range(j - 1)]).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-TaJRt9vIcEw",
        "outputId": "2d6840bc-e1b9-4e65-d4e3-8f9b977830db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "np.array(list(itertools.combinations(range(10), 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im5PvEYDKaTs",
        "outputId": "76c47e3c-38ed-4e20-bca9-a562fc5a9a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1],\n",
              "       [0, 2],\n",
              "       [0, 3],\n",
              "       [0, 4],\n",
              "       [0, 5],\n",
              "       [0, 6],\n",
              "       [0, 7],\n",
              "       [0, 8],\n",
              "       [0, 9],\n",
              "       [1, 2],\n",
              "       [1, 3],\n",
              "       [1, 4],\n",
              "       [1, 5],\n",
              "       [1, 6],\n",
              "       [1, 7],\n",
              "       [1, 8],\n",
              "       [1, 9],\n",
              "       [2, 3],\n",
              "       [2, 4],\n",
              "       [2, 5],\n",
              "       [2, 6],\n",
              "       [2, 7],\n",
              "       [2, 8],\n",
              "       [2, 9],\n",
              "       [3, 4],\n",
              "       [3, 5],\n",
              "       [3, 6],\n",
              "       [3, 7],\n",
              "       [3, 8],\n",
              "       [3, 9],\n",
              "       [4, 5],\n",
              "       [4, 6],\n",
              "       [4, 7],\n",
              "       [4, 8],\n",
              "       [4, 9],\n",
              "       [5, 6],\n",
              "       [5, 7],\n",
              "       [5, 8],\n",
              "       [5, 9],\n",
              "       [6, 7],\n",
              "       [6, 8],\n",
              "       [6, 9],\n",
              "       [7, 8],\n",
              "       [7, 9],\n",
              "       [8, 9]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.com"
      ],
      "metadata": {
        "id": "apL5SildIrgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lh0pCj6iRCH",
        "outputId": "11fc3a81-bebc-48d0-db69-5c877ca3ff6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.09270676,  1.15687253, -0.4371196 , ..., -0.50569166,\n",
              "        -0.37784595, -2.64658122],\n",
              "       [ 0.42740856,  0.27523665, -0.99100843, ..., -0.27276184,\n",
              "        -3.60056857, -0.27773391],\n",
              "       [ 0.49683044, -1.16285266,  0.31423901, ..., -0.36541367,\n",
              "        -0.27023115, -3.70053564],\n",
              "       ...,\n",
              "       [-0.057246  , -1.06131555,  1.67341082, ..., -1.77601692,\n",
              "        -1.5767326 , -0.63422295],\n",
              "       [-0.74336481,  1.65313952, -1.24810276, ..., -2.063288  ,\n",
              "        -0.75498937, -1.32452197],\n",
              "       [ 0.3536813 , -0.4488348 ,  0.29054306, ..., -0.13040583,\n",
              "        -0.6473274 , -1.54481335]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feat_gen._corr_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kX3UHKN9yrG1",
        "outputId": "3bf45188-0196-48cf-af51-754bb6518321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        , -0.85964575],\n",
              "       [-0.85964575,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(np.zeros((0,0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYMOyg8BgDib",
        "outputId": "52bc1886-9fa8-4a39-d4c0-d8a9d101bc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(0, 0), dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pickle\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "0XAGBpqGElzl",
        "outputId": "70ed4ee2-e3aa-4da0-ceb4-9ae06be925aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-063f0a22cb6d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/MyDrive/sience/history.dat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/sience/history.dat'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in-0pK3S8_ya",
        "outputId": "dad9d478-a959-4178-f6b3-b833b6746116"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{10: {10: 0.002145528793334961,\n",
              "  100: 0.007488250732421875,\n",
              "  1000: 0.010437726974487305,\n",
              "  10000: 0.042025089263916016,\n",
              "  100000: 0.5531578063964844},\n",
              " 50: {10: 0.010045289993286133,\n",
              "  100: 0.016582250595092773,\n",
              "  1000: 0.0774075984954834,\n",
              "  10000: 1.4936797618865967,\n",
              "  100000: 18.395544290542603},\n",
              " 100: {10: 0.04611349105834961,\n",
              "  100: 0.04762005805969238,\n",
              "  1000: 0.6432921886444092,\n",
              "  10000: 10.36926007270813,\n",
              "  100000: 115.10663485527039}}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_history = {100:{}, 1000:{}, 10000:{}, 100000:{}}\n",
        "for i in [10, 50, 100]:\n",
        "    for j in [100, 1000, 10000, 100000]:\n",
        "      new_history[j][i] = history[i][j]"
      ],
      "metadata": {
        "id": "46flyS3gAOk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_history = {1000:{}, 10000:{}, 100000:{}}\n",
        "for i in history.keys():\n",
        "    for j in new_history.keys():\n",
        "      new_history[j][i] = history[i][j]"
      ],
      "metadata": {
        "id": "7GBAJD0gBr2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Зависимость длительности обучения от числа объектов и признаков')\n",
        "\n",
        "# plt.plot(np.array(list(history[100].keys())) / 100000 * 120, np.array(list(history[100].values())),label=\"10 features\")\n",
        "# plt.plot(np.array(list(history[10].keys())) / 100000 * 0.5, np.array(list(history[10].values())),label=\"10 features\")\n",
        "# plt.plot(np.array(list(history[10].keys())) / 100000 * 0.5, np.array(list(history[10].values())),label=\"10 features\")\n",
        "# plt.plot(history[50].keys(), history[50].values(), label=\"50 features\")\n",
        "# plt.plot(history[100].keys(), history[100].values(), label=\"100 features\")\n",
        "plt.legend()\n",
        "# for alpha_i in range(alphas.shape[0]):\n",
        "#     for beta_i in range(betas.shape[0]):\n",
        "#         ax[alpha_i][beta_i].plot(range(1, len(history_al_bet_st_batch[0][0][alpha_i][beta_i]['func']) + 1),\n",
        "#                                  history_al_bet_st_batch[0][0][alpha_i][beta_i]['func'])\n",
        "#         ax[alpha_i][beta_i].set_title('step_alpha='+str(alphas[alpha_i])+', step_beta='+str(betas[beta_i]))\n",
        "#         ax[alpha_i][beta_i].set_xlabel('Номер эпохи')\n",
        "#         ax[alpha_i][beta_i].set_ylabel('Функция потери')\n",
        "#         ax[alpha_i][beta_i].grid()\n",
        "plt.ylabel('Время(с)')\n",
        "plt.xlabel('Число объектов')\n",
        "plt.grid()\n",
        "# fig.savefig('history_SGD_1_0.svg')\n",
        "# fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "3gExKMA573vW",
        "outputId": "d4df6460-0db7-4fa4-fe51-535b81ac1f3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnYAAAHHCAYAAAAyKhW0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/cklEQVR4nO3deXhMZ/sH8O9km+yrrCQEsZOIfaeC2rdSpLW+jVbsRdHaaVDU0qC0pX0l9tJSVOxbEJLYlyCEkERE9m0y8/z+8Mu8RhImkphk8v1cV67LPGeZ+9xz5sztPOc8RyKEECAiIiKiMk9H0wEQERERUfFgYUdERESkJVjYEREREWkJFnZEREREWoKFHREREZGWYGFHREREpCVY2BERERFpCRZ2RERERFpCT9MBEFHZlpaWhoSEBJiamsLKykrT4RCpyMzMREJCAvT09GBnZ6fpcIhKHM/YEVGh7dy5Ex07doSZmRlMTU3h4uKCpUuXajosIgDAkSNH0KtXL1haWsLIyAgVK1bEhAkTNB0W0QdRqDN269evx549exAeHo6EhATY2NigZs2aGDVqFD777DPo6LBOJNJ206dPx5IlS9C7d29s3LgRFSpUgEQiQY0aNTQdGhHWrl2LcePGoXXr1li1ahUqVqwIAKhcubKGIyP6MCSFeVZsixYt4OjoiI8++gjm5uZITEzE+fPnsW3bNnz66afYunVrScZKRBp28uRJtG/fHn5+fpg+fbqmwyFSERERgfr162PEiBFYu3YtJBKJpkMi+uAKVdjJZDLo6+vnaR83bhx++uknREZGokqVKsUZHxGVIj179kRCQgLOnj2r6VCI8hg3bhz27duHiIiIfH+riMqDQvWdFvRFyS3mXu+K/euvv9C9e3c4OTlBKpWiWrVqWLBgAeRyucqy7du3h0QiUf5VqFAB3bt3x/Xr11Xmk0gkmDt3rkrbDz/8AIlEgvbt26u0Z2ZmYu7cuahRowYMDQ3h6OiIfv364f79+wCAhw8fQiKRYPPmzSrL+fr6QiKRYPjw4cq2zZs3QyKRwMDAAM+fP1eZPzg4WBn3pUuXVKbt3LkTjRo1gpGRESpUqIDPPvsM0dHReXJ3+/ZtDBw4ELa2tjAyMkLNmjXx7bffAgDmzp2rkpv8/k6cOKHMY7169fKsvzDe9R6vGz58eL7zvv4ZDR8+PE+h//jxYxgZGUEikeDhw4cAXu0/b9vG19ehUCiwcuVK1K1bF4aGhrC3t8fo0aPx8uXLPDGeOHHinevLnWfXrl1vzU3uZxEfH6/SfunSpXz3pWPHjqFNmzYwMTGBpaUlevfujVu3buVZb3R0NEaNGqX8nri6uuKrr75Cdna2ct9721/u+6qb67dRJ+bz58+jXr16GDRoEKytrWFkZIQmTZpg7969ynlSU1NhYmKS7zVNT548ga6uLvz8/AqMG8j/+x4dHY2RI0fC3t4eUqkUdevWxW+//aYyz9s+T1NT03y/26/nRqFQoEGDBvl+prt27ULjxo1hZmam8hksW7Ysz3u96cGDBxgwYACsra1hbGyM5s2b459//skT99v+3szH63L3zzdVqVKlSNv8tuPTm+/zrmOHur8JBQkLC0PXrl1hbm4OU1NTdOzYEefPn1eZ5/z582jUqBHGjBmj3E/q1auHjRs3KudJTEzME6c6n2FiYiImTpwIZ2dnSKVSVK9eHUuWLIFCoVDOk99vS0pKCho1agRXV1c8e/ZMOc/b/l7/zN617wB59x+pVIoaNWrAz88P7zp3k7vsm8f57t27v3O/y++937YtufvfqVOnMHr0aNjY2MDc3BxDhw7Ncwx/c98FXv2uvnkMv3PnDj766CM4ODhAKpXC2dkZX375JRISEvLEqM5xISEhAVOmTEH9+vVhamoKc3NzdO3aFVeuXHln3p4+fYoqVaqgcePGSE1NVbbHxcVh1KhRsLe3h6GhIdzd3fH777+rrO/N/UJfXx9VqlTB1KlTkZ2dXVD68/Ved8UmJiYiJycHKSkpuHz5MpYtW4ZBgwbBxcVFOc/mzZthamqKyZMnw9TUFMeOHcPs2bORnJyMH374QWV9tWrVwrfffgshBO7fv48VK1agW7duiIqKemsMuT8Or5PL5ejRoweOHj2KQYMGYcKECUhJSUFQUBCuX7+OatWq5bu+e/fuqXz536Srq4stW7Zg0qRJyrZNmzbB0NAQmZmZKvNu3rwZI0aMQJMmTeDn54fY2FisWrUKZ8+eRVhYGCwtLQEAV69eRZs2baCvrw8fHx9UqVIF9+/fx759+7Bo0SL069cP1atXV6530qRJqF27Nnx8fJRttWvXLjDm99GpUycMHToUABASEoLVq1cXOG+FChXw448/Kl9//vnn71z/7Nmz8+Rr5cqVyi/BrVu38P3332PmzJnKbTM1NVXOO3r0aGV+x48fj8jISPz0008ICwvD2bNn8/3Px+vr2rBhw1v3q+Jw5MgRdO3aFVWrVsXcuXORkZGBNWvWoFWrVggNDVUelJ4+fYqmTZsiMTERPj4+qFWrFqKjo7Fr1y6kp6ejbdu2+O9//6tc76JFiwBA5Ye1ZcuWBcaRX66LGvOLFy+wYcMGmJqaYvz48bC1tcWWLVvQr18/BAQEYPDgwTA1NUXfvn2xfft2rFixArq6usr32bp1K4QQ8Pb2VjedAIDY2Fg0b94cEokEY8eOha2tLQ4ePIhRo0YhOTkZEydOLNT6CvLf//4X165dy9MeHByMgQMHwt3dHYsXL4aFhQXi4+NVjgdvi71ly5ZIT0/H+PHjYWNjg99//x29evXCrl270LdvX9SuXVvls96wYQNu3bql8v1q0KBBsWzjmwra5ncdn97Upk0b5bEp93v8usL8Jrzpxo0baNOmDczNzTFt2jTo6+vj559/Rvv27XHy5Ek0a9YMwKv989KlS9DT04Ovry+qVauGvXv3wsfHBy9evMD06dNhYmKizLW6n2F6ejratWuH6OhojB49Gi4uLjh37hxmzJiBZ8+eYeXKlfkuJ5PJ0L9/f0RFReHs2bNwdHREWlqaymf9559/Ys+ePSptub9T6uw7r8s91mVkZGD79u2YOXMm7OzsMGrUqHdu4+tOnTqFAwcOFGqZ8ePHo0mTJipt//nPf/Kdd+zYsbC0tMTcuXNx584drFu3Do8ePVIWS/nJycnJ9z8VaWlpqFSpEnr27Alzc3Ncv34d/v7+iI6Oxr59+wq1DcCrQnrv3r0YMGAAXF1dERsbi59//hnt2rXDzZs34eTklO9ySUlJ6Nq1K/T19XHgwAHl71ZGRgbat2+Pe/fuYezYsXB1dcXOnTsxfPhwJCYm5vkPsI+PD9q0aYOsrCz8+++/WLZsGQwNDbFgwQL1N0K8h5o1awoAyr+hQ4cKmUymMk96enqe5UaPHi2MjY1FZmamsq1du3aiXbt2KvPNnDlTABBxcXHKNgBizpw5ytfTpk0TdnZ2olGjRirL//bbbwKAWLFiRZ73VygUQgghIiMjBQCxadMm5bSBAweKevXqCWdnZzFs2DBl+6ZNmwQAMXjwYFG/fn1le1pamjA3NxdDhgwRAERISIgQQojs7GxhZ2cn6tWrJzIyMpTz79+/XwAQs2fPVra1bdtWmJmZiUePHuUb55sqV66sEtvr2rVrJ+rWrZvvNHVkZ2cLAGLs2LHKtp07dwoA4vjx43nm9/b2Fq6uriptb35Gw4YNE5UrV1a+vn79utDR0RFdu3YVAERkZGSe9R4/frzA9zx9+rQAIAICAlTaDx06lG97UFCQACBOnjxZYEy577dz58487/e6OXPmCADi+fPnKu0hISF59iUPDw9hZ2cnXrx4oWy7cuWK0NHREUOHDlW2DR06VOjo6Cj3ndfltw/k910paLvUyfXr1I059zt/4sQJZVt6erqoXbu2cHBwENnZ2UIIIf79918BQBw8eFDlfRo0aKCyDSNGjBAuLi554nlzXxo1apRwdHQU8fHxKvMNGjRIWFhYKI83b/s8TUxM8v1u5+YmMzNTuLi4KHP2+mc6Y8YMAUA8e/ZM2ZZ7HPnhhx/yvNfrJk6cKACI06dPK9tSUlKEq6urqFKlipDL5XmWefPzfJd58+YJAHn2mzePGYXZ5sIcnypWrChGjBihfJ3f91jd34T89OnTRxgYGIj79+8r254+fSrMzMxE27ZtVbYXgNi8ebOyLScnR3Ts2FFIpdI8+4+6n+GCBQuEiYmJuHv3rkr79OnTha6uroiKilJZ36ZNm4RCoRDe3t7C2NhYXLhwocB15x5b8qPuvpNfvjMzM4WOjo4YM2bMW7ctv2WbNWum3Cde/x6+bfnCfOcaNWqkPFYIIcTSpUsFAPHXX38p297cd9euXSukUqno0KHDO78bY8aMEaampu8VY2ZmZp7vZGRkpJBKpWL+/Pl51nn8+HGRmZkp2rdvL+zs7MS9e/dUll25cqUAILZs2aJsy87OFi1atBCmpqYiOTlZ+R5vfgeFEMLJyUl069btrdv7pve6jXXTpk0ICgpCQEAARo0ahYCAAJWzSABgZGSk/HdKSgri4+PRpk0bpKen4/bt2yrzymQyxMfH4/nz5wgODsaePXvQoEEDVKhQId/3j46Oxpo1azBr1iyVszkAsHv3blSoUAHjxo3Ls1xB/xO4fPkydu7cCT8/vwLv7P38889x+/ZtZZfr7t27YWFhgY4dO6rMd+nSJcTFxWHMmDEwNDRUtnfv3h21atVSnkJ//vw5Tp06hZEjR6qc6XxbnO8il8sRHx+P+Pj4Qp+6zT2z83rMb5OdnQ2pVFqo95gxYwY8PT0xYMCAQi2Xa+fOnbCwsECnTp2U2xkfH49GjRrB1NQUx48fzxMjALXizN1HExMT3zpfQkKCynsnJSWpTH/27BnCw8MxfPhwWFtbK9sbNGiATp06Kf8XrFAosHfvXvTs2RONGzfO8z5Fvei7MLlWN+ZcTZo0Qbt27ZSvjYyMMGbMGMTExCA0NBQA4OXlBScnJwQEBCjnu379Oq5evYrPPvtM2WZnZ4e4uLi37q9CCOzevRs9e/aEEEIl/126dEFSUpLyfXPlfp6v/72Lv78/Xrx4gTlz5uSZlpKSAh0dHeXZ9sI4cOAAmjZtitatWyvbTE1N4ePjg4cPH+LmzZuFXuebcsdne/LkSaGWK2ibC3t8Uud4UJjfhNfJ5XIcPnwYffr0QdWqVZXtjo6OGDJkCM6cOYPk5GRlu729vUrvga6uLiZOnIisrCwcOXIk3/dIT09HfHw8Xr58mW/X5c6dO9GmTRtYWVmp7FNeXl6Qy+U4depUnmWmTp2KgIAA7NixA02bNn1rbgpS2H0nKSkJ8fHxiIqKwtKlS6FQKPDRRx8V6j3//PNPhISEYPHixe8Vszp8fHxUele++uor6OnpFXiWMD09HfPnz8fYsWPz7I+5kpKSEBsbi6NHj+Kff/5B27Zt88yjznFBKpUq6wC5XI4XL17A1NQUNWvWzHOcAV4dy4cOHYrz58/jwIEDeXoFDxw4AAcHBwwePFjZpq+vj/HjxyM1NRUnT55UmT81NRXx8fGIjo7Ghg0bEBMTk6fOeJf3KuxatGgBLy8vDBkyBL/88gvmz5+PTZs2qVxQfePGDfTt2xcWFhYwNzeHra2t8oD+5o/huXPnYGtrCzs7O7Rs2RI5OTnKvvT8zJkzB05OThg9enSeaffv30fNmjWhp6d+L/P06dPRpk0b9OjRo8B5bG1t0b17d+U1Pb/99huGDRuWpxB89OgRAKBmzZp51lGrVi3l9AcPHgBAka+Le93t27dha2urcj1MYGCgWsvm7uAWFhZqzZ+YmJinqH6bM2fOYN++fViyZMl7Fy0RERFISkqCnZ2dcjtz/1JTUxEXF5cnRgBqxTly5EjY2trCysoKZmZmGDJkCGJjY/PMV7NmTZX39fLyUpn+ts+/du3aiI+PR1paGp4/f47k5ORi/fxzFTbX6sacq1atWvnOB0B57ZaOjg68vb2xd+9epKenAwACAgJgaGioUmy2bNkSmZmZ+O677/DkyZN8D7bPnz9HYmIiNmzYkOdzHzFiBADk+exzP8/X/17fhjclJSXh+++/x+TJk2Fvb59neosWLaBQKDBhwgTcv39fWQSo49GjRwXmNnd6UbVo0QISiQQzZszAw4cPlXl8/fqvN71tmwt7fEpKSnrn96wwvwmve/78OdLT0wvMoUKhwOPHjwFAOezOm8flN/fPN82ZMwe2trbK69i6d++OiIgI5fSIiAgcOnQozz6V+/1/c//7+eefsXz5cgBQez/JT2H3nT59+sDW1haVK1fG3Llz8d1336F///5qv59cLsfMmTPh7e1dYl3/AODm5qby2tTUFI6OjgV+PitWrEBmZiZmzpxZ4Dq7dOkCBwcHeHl5oXbt2ti+fXueedQ5LigUCvz4449wc3ODVCpFhQoVYGtri6tXr+a7n3777bfYsWMHsrKylMe61z169Ahubm4F7pNvfobjxo2Dra0tKlWqhNGjR2PYsGFqXS7wumJ58sQnn3yCb7/9FhcuXECrVq2QmJiIdu3awdzcHPPnz0e1atVgaGiI0NBQfPPNN3kONg0aNFB+CZ4/f47Vq1ejffv2CA0NhYODg8q8t27dwubNm7Fly5Ziuevp8OHDOHLkCIKDg98578iRIzF06FCMGzcOp06dwi+//ILTp08XOYbiUqVKFeV1gi9evMDq1avx+eefo2rVqmjevPlbl339RgZ1xMTEFGpcqG+++QZdunTBRx99lOcCbXUpFArY2dmpnAV6na2tbZ4YAeTZh/Ize/ZstGnTBjKZDJcvX8b8+fORmJiY53+Qu3fvhrm5ufL13bt34evrW9hNKVHFkeuCvH7W5V2GDh2KH374AXv37sXgwYMRGBiIHj16qPznoVevXhg5ciR++OGHAq+zyj1efPbZZxg2bFi+87z5I5T7eb6uZ8+eBca6ZMkS6OjoYOrUqXjx4kWe6YMGDUJoaCjWrFmDDRs2FLgeTXF3d8ecOXMwb968Ar8fb3rXNqsrISEB2dnZb/2eFfY34X0VZv98nY+PDwYMGAC5XI5bt25h3rx56NOnD27cuAHg1T7YqVMnTJs2Ld/l3xzD8fz581i0aBFCQkIwadIkfPzxxwX2QBWnZcuWwd3dHTKZDCEhIVi4cCH09PTyPQudn19//RUPHz7Ev//+W8KRqi8+Ph4//PADZsyYodKj8KY1a9YgPj4eN2/ehJ+fH7788kts2bJFZR51jgvff/89Zs2ahZEjR2LBggWwtraGjo4OJk6cmO9+euHCBWzevBk//fQTfHx8EB4eXujerNdNnToVnTt3hlwux40bNzB//nwIIbBp0ya111EshV1GRgYAKC+SPnHiBF68eIE///xT5XRoZGRkvstbWVmpnPlo3749nJycsGnTJsyYMUNl3hkzZsDDwwOffvppvuuqVq0aLly4UODQLK8TQmD69Ono27fvOwsfAOjatSsMDQ0xaNAgtG7dGtWqVctT2OUWO7l36rzuzp07yum5XQpv3v1bFCYmJip5bNOmDSpWrIjDhw+/c/tyu5jz6xZ8k0wmw7179/Dxxx+rFdfevXsRHByc72nswqhWrRqOHDmCVq1aqXUAv3nzJmxtbWFjY/POeevXr6/MXdeuXREVFYXff/8dOTk5Kmd/27Ztq3KAfrNr7vXP/023b99GhQoVYGJiAiMjI+WFvsXpfXKtbswA4OrqWuB8gOp/DOrVq4eGDRsiICAAlSpVQlRUFNasWZNn2V9//RWzZ8/G/fv3lQfOTp06Kafb2trCzMwMcrk8zxnSgrz+eeZ6/SaO1z19+hSrVq2Cn58fzMzM8i1ydHR0sGzZMly7dg2RkZFYu3YtYmNjVbqVC1K5cuW35qy4Bs6dM2cOfHx8cPv2beWdpgXF965tLszxKbc78G03chX2N+F1tra2MDY2LjCHOjo6cHZ2BvBq/wwNDYVCoVA5Q5Lf/vk6Nzc35f7SpUsXZGRkYObMmYiKioKLiwuqVauG1NRUtfe/kSNHYubMmXj69Cnq1KmDSZMmqdwcoa7C7juNGjVSjhLRtWtXREdHY8mSJZg1a9Y7HyCQnp6OefPmYcyYMSU+mHNERAQ6dOigfJ2amopnz56hW7dueeZduHAhzMzM3vnkkNwbN7p27Qo7OzsMHToU3377rcp+qc5xYdeuXejQoQN+/fVXlfbExMR8i/N58+Zh2LBh8PDwQOPGjbFw4UKVGx0qV66Mq1evFrhPvpnrOnXqqOyLWVlZmDlzJhYtWlTgjRtvKlRXbEH93xs3boREIlEWMrmJev1ahezsbKxdu1at98ktFLOyslTag4OD8ddff2Hx4sUFdjH1798f8fHx+Omnn/JMe/PaiW3btuHq1av53l2bHz09PQwdOhRXr17FyJEj852ncePGsLOzw/r161XiP3jwIG7duoXu3bsDeHWwatu2LX777bc8d2nmd43H+8j9kSzoB+11u3btQs2aNfPtZnvTX3/9hYyMDLWu3cg9tT9kyBB4eHi8c/63GThwIORyeb53B+Xk5KhcH5eSkoIDBw4U+vqSXLlfwsJ2Gzs6OsLDwwO///67SjzXr1/H4cOHlQcuHR0d9OnTB/v27cszVA7wfvvA++Za3ZgBoFu3brh48SLOnTunbMvMzMS6devg4OCARo0aqaz7888/x+HDh7Fy5UrY2Niga9eu+cZQuXJlfPTRR/Dy8sr3wNu/f3/s3r0730LjzWGICmvevHmwt7fHl19++db51qxZg2PHjiEgIABeXl5o1aqVWuvPzdnrvQJpaWnYsGEDqlSpgjp16hQp/tc5OjqiQ4cOyjwWdM3su7a5MMenbdu2wcDAQOU6sDcV5TdBV1cXnTt3xl9//aXSVRcbG4vAwEC0bt1aeRa9W7duiImJUemGUygUWLVqFaRSqdqFWe41x7lxDxw4EMHBwfmeycodJeJ1uWeFnJycsGTJEmzZsgWHDx9W671fV9R9JyMjAzk5OXniy8+qVauQlpaW752nxW3Dhg2QyWTK1+vWrUNOTk6e48PDhw+xbt06zJ07t1BnY3Mv53izhlCHrq5unn18586d+Q5XBvzvs3Z3d8eUKVOwZMkSleNUfvtkTk4O1qxZA1NTU5XrlfOTWw8V5rr5Qp2xGzJkCGrVqoW+ffvC3t4ez58/x8GDB3H8+HF8++23qF+/PoBX181YWVlh2LBhGD9+PCQSCf773/8W+GMVGxurPGUaHx+Pn3/+GXp6enmueTt8+DA6der01i/n0KFD8ccff2Dy5Mm4ePEi2rRpg7S0NBw5cgRjxoxB7969Vdb3xRdf5HsNQ0EWLFiAqVOnFviwc319fSxZsgQjRoxAu3btMHjwYOVwJ1WqVFHpK1+9ejVat24NT09P+Pj4wNXVFQ8fPsQ///yD8PBwtWPKlZqaikOHDgF41T2yevVq6OvrK4vJ/Dx48ABLly7FxYsX0a9fP5VT1yEhIQCAoKAguLi4wMHBAXPmzMHatWvRsmVLdO7c+Z0xPXnyBAYGBoW+dT4/7dq1w+jRo+Hn54fw8HB07twZ+vr6iIiIwM6dO7Fq1Sp88skn2LFjB+bNm4eXL1+q/XSE8PBwmJqaIicnB5cvX8Yff/yB3r17q1UUv+mHH35A165d0aJFC4waNUo5dIiFhYXKmFDff/89Dh8+jHbt2sHHxwe1a9fGs2fPsHPnTpw5c6bQF+oXJdfqxjxt2jQEBASga9euGD9+PCpUqIAtW7bg5s2bCAgIyHNt65AhQzBt2jTs2bMHX3311XtfPrF48WIcP34czZo1wxdffIE6deogISEBoaGhOHLkiMqYVYV1+PBhBAQEwMDAoMB5bty4gWnTpmHu3Ll5hnR4l+nTp2Pr1q3KnFlbW+P3339HZGQkdu/erZFHMaqzze86PkVERGDOnDnYunUrpk+frnKJwpsK+5vwpoULFyIoKAitW7fGmDFjoKenh59//hlZWVkqzygeNWoU1q1bh+HDh+PSpUtwdXXF3r17cfToUSxevLjAs/ehoaHYsmULFAoFbt68idWrV6NJkybKx5FNnToVf//9N3r06IHhw4ejUaNGSEtLw7Vr17Br1y48fPiwwK5WHx8fBAYG4ssvv8T169dhbGys1jYDhd93goKC8OTJE2VXbEBAAHr16vXWzznX4cOHsWjRIrV6OIoqOzsbHTt2xMCBA3Hnzh2sXbsWrVu3Rq9evVTmO3nyJGrXrq28ljY/8+fPR3R0NOrVqwepVIrQ0FBs2rQJDRo0eK/rBHv06IH58+djxIgRaNmyJa5du4aAgACVG3cKMmfOHOzevRtffPEFzp49Cx0dHfj4+ODnn3/G8OHDcfnyZVSpUgW7du3C2bNnsXLlSpiZmamsIzg4GHp6esqu2DVr1qBhw4aFe/hDYW6hXbdunejWrZtwcnISenp6wtLSUnTp0kUcOHAgz7xnz54VzZs3F0ZGRsLJyUlMmzZNOQTC67dVt2vXTmXoFEtLS9GqVas86wQgJBKJuHz5skp7fkNApKeni2+//Va4uroKfX194eDgID755BPlrfK5txUbGRmJ6OholWULGh4gvyEp3jZ9+/btomHDhkIqlQpra2vh7e0tnjx5kmf569evi759+wpLS0thaGgoatasKWbNmpXve71ruJP88vjmcBMFxf+uv02bNoknT54IZ2dnMXHiRJGUlJRnXchnuBMAYsKECfm+Z2GHO8m1YcMG0ahRI2FkZCTMzMxE/fr1xbRp08TTp0+FEEL07dtXdO3aNd8hBgoa7iT3T09PT1SuXFmMHz9evHz5UjlfYYY7EUKII0eOiFatWgkjIyNhbm4uevbsKW7evJknnkePHomhQ4cKW1tbIZVKRdWqVYWvr6/IysrKM++7hjspbK7fpG7M9+/fF5988omwsLAQhoaGokmTJmLv3r0Frrdbt24CgDh37tw7Y8j15r4khBCxsbHC19dXODs7K7/XHTt2FBs2bFDO8z5DL3h4eKgM4fHmsAOZmZmiQYMGonXr1iInJyfPfO8aKkOI/+Us93vetGlTsX///gLnL+xwJwUp6Hj2rm3O9bbj09atW0W9evXEqlWr8gyBkt/3WN3fhIKEhoaKLl26CFNTU2FsbCw6dOiQ7z4VFxcnRo4cKSpUqCAMDAxEvXr1xMaNG/NdZ+525/7p6OiISpUqiWHDhuU5XqekpIgZM2aI6tWrCwMDA1GhQgXRsmVLsWzZMuXQHQXl8c6dO8LQ0FBMmjQpTwxvG+5ECPX2HXWPY/nJXdbR0VGkpaWpTMvve1jQ8oX5zp08eVL4+PgIKysrYWpqKry9vVWGWhLif0PX7NmzR6X9ze/Grl27RJMmTYS5ubkwMjIS1atXF19//bXKsbqww518/fXXwtHRURgZGYlWrVqJ4ODgPMffgn6rTpw4ISQSiVi1apWyLTY2VowYMUK5T9avXz/PPlKYffFdCvVIMdI+mzdvxty5c9/6ZIL27dtj+PDheUYBJ1JH3759ce3aNdy7d0/ToRCRBuUOLh8SEqLW9dz0fj58HwARlRvPnj3DP//8o9ZTSYiIqOiK5a5YKruqVauW57E0b+rUqVOBj2Ijyk9kZCTOnj2LX375Bfr6+vmOOUlERMWPhV0516ZNmzzj+rzpQ9wlRdrl5MmTGDFiBFxcXPD777+rNZYgEREVHa+xIyIiItISvMaOiIiISEuwsCMiIiLSEqXiGrtTp07hhx9+wOXLl/Hs2TPs2bMHffr0AfDq8VXfffcdDhw4gAcPHsDCwgJeXl5YvHixyuM1EhISMG7cOOzbtw86Ojro378/Vq1apfaD6hUKBZ4+fQozM7P3fkg9ERERfVhCCKSkpMDJyUkjA36XNqWisEtLS4O7uztGjhyJfv36qUxLT09HaGgoZs2aBXd3d7x8+RITJkxAr169VB7F5O3tjWfPniEoKAgymQwjRoxQjvitjqdPnyqfN0hERERly+PHj1GpUiVNh6Fxpe7mCYlEonLGLj8hISFo2rQpHj16BBcXF9y6dQt16tRRGfTw0KFD6NatG548eaLWg3OTkpJgaWmJx48fv/XROO9DJpPh8OHDykdgUcGYK/UxV+pjrtTHXKmPuSqckspXcnIynJ2dkZiYCAsLi2Jbb1lVKs7YFVZSUhIkEonyWZrBwcGwtLRUGcnay8sLOjo6uHDhQr7jtGVlZak8IDglJQUAYGRkVKiHDatDT08PxsbGMDIy4pf/HZgr9TFX6mOu1MdcqY+5KpySypdMJgMAXkb1/8pcYZeZmYlvvvkGgwcPVp5Zi4mJgZ2dncp8enp6sLa2RkxMTL7r8fPzw7x58/K0Hz58uFAPaS6MoKCgElmvNmKu1MdcqY+5Uh9zpT7mqnCKO1/p6enFur6yrkwVdjKZDAMHDoQQAuvWrSvSumbMmIHJkycrX+eeyu3cuXOJdMUGBQWhU6dO/F/dOzBX6mOu1MdcqY+5Uh9zVTglla/k5ORiW5c2KDOFXW5R9+jRIxw7dkyl+HJwcEBcXJzK/Dk5OUhISChwxHupVAqpVJqnXV9fv8S+oCW5bm3DXKmPuVIfc6U+5kp9zFXhFHe+mHtVZaKwyy3qIiIicPz4cdjY2KhMb9GiBRITE3H58mU0atQIAHDs2DEoFAo0a9asWGORy+XK/nx1yWQy6OnpITMzE3K5vFjj0TalNVf6+vrQ1dXVdBhERERvVSoKu9TUVNy7d0/5OjIyEuHh4bC2toajoyM++eQThIaGYv/+/ZDL5crr5qytrWFgYIDatWvj448/xhdffIH169dDJpNh7NixGDRokFp3xKpDCIGYmBgkJia+17IODg54/PgxL+58h9KcK0tLSzg4OJS6uIiIiHKVisLu0qVL6NChg/J17rVvw4YNw9y5c/H3338DADw8PFSWO378ONq3bw8ACAgIwNixY9GxY0flAMWrV68uthhzizo7OzsYGxsX6sddoVAgNTUVpqamHDzxHUpjroQQSE9PV3b3Ozo6ajgiIiKi/JWKwq59+/Z423B66gy1Z21trfZgxIUll8uVRd2b3cDqUCgUyM7OhqGhYakpVkqr0pqr3CFw4uLiYGdnx25ZIiIqlUrPL2cplntNXUkNg0JlQ+7nX9hrLImIiD4UFnaFwGuryjd+/kREVNqxsCMiIiLSEizsqNCEEPDx8YG1tTUkEgnCw8M1HRIRERGBhZ1WO3XqFHr27AknJydIJBLs3bs3zzxCCMyePRuOjo4wMjKCl5cXIiIi3rreQ4cOYfPmzdi/fz+ePXuGevXqFUu8w4cPz/e5vkRERKQeFnZaLC0tDe7u7vD39y9wnqVLl2L16tVYv349Lly4ABMTE3Tp0gWZmZkFLnP//n04OjqiZcuWcHBwgJ5eqbi5Wkkul0OhUGg6DCIies2Ju8+hePcgF1RELOy0WNeuXbFw4cICz4IJIbBy5Up899136N27Nxo0aIA//vgDT58+zffsHvDqrNq4ceMQFRUFiUSCKlWqAHg1TImfnx9cXV1hZGQEd3d37Nq1S7mcXC7HqFGjlNNr1qyJVatWKafPnTsXv//+O/7++29YWVlBV1cXJ06cwIkTJyCRSFQGhg4PD4dEIsHDhw8BAJs3b4alpSX+/vtv1KlTB1KpFFFRUcjKysKUKVNQsWJFmJiYoFmzZjhx4oRyPY8ePULPnj1hZWUFExMT1K1bFwcOHHivXBMRUf4ysuWYuvMKvvhvGA49YdlR0krXqZYyRAiBDJl6j7xSKBTIyJZDLzunyGOzGenrFtvdmZGRkYiJiYGXl5eyzcLCAs2aNUNwcDAGDRqUZ5lVq1ahWrVq2LBhA0JCQpTjufn5+WHLli1Yv3493NzccOrUKXz22WewtbVFu3btoFAoUKlSJezcuRM2NjY4d+4cfHx84OjoiIEDB2LKlCm4desWkpKSsGrVKpiZmaFChQo4d+6cWtuSnp6OJUuW4JdffoGNjQ3s7OwwduxY3Lx5E9u2bYOTkxP27NmDjz/+GNeuXYObmxt8fX2RnZ2NU6dOwcTEBDdv3oSpqWmx5JaIiIB7cSkYExCKu7Gp0JEAehKesitpLOzeU4ZMjjqz//3g73tzfhcYGxTPx5b7aDZ7e3uVdnt7e+W0N1lYWMDMzAy6urpwcHAAAGRlZeH777/HkSNH0KJFCwBA1apVcebMGfz8889o164d9PX1MW/ePOV6XF1dERwcjB07dmDgwIEwNTWFkZERMjMzYW9vD3Nz80IVwTKZDGvXroW7uzsAICoqCps2bUJUVJTysXJTpkzBoUOHsGnTJnz//feIiopC//79Ub9+fWXMRERUPPaEPcG3e64jPVuOCqZS/DigPhJun9d0WFqPhR0V2b1795Ceno5OnTqptGdnZ6Nhw4bK1/7+/vjtt98QFRWFjIwMZGdn53lM3PsyMDBAgwYNlK+vXbsGuVyOGjVqqMyXlZWlfHrI+PHj8dVXX+Hw4cPw8vJC//79VdZBRESFlymTY96+G9h68TEAoGU1G6wc5AErQ10cuK3h4MoBFnbvyUhfFzfnd1FrXoVCgZTkFJiZmxVLV2xxyT3jFhsbq/L809jY2EIVXKmpqQCAf/75BxUrVlSZJpVKAQDbtm3DlClTsHz5crRo0QJmZmb44YcfcOHChbeuOzdfrz9WLr8nPxgZGal0UaempkJXVxeXL1/O8/iv3O7W//znP+jSpQv++ecfHD58GH5+fli+fDnGjRun7qYTEdFrHjxPxZiAUNyOSYFEAoz/yA3jO7pBV0fCp/Z8ICzs3pNEIlG7S1ShUCDHQBfGBnql6vmnrq6ucHBwwNGjR5WFXHJyMi5cuICvvvpK7fW8fsNCu3bt8p3n7NmzaNmyJcaMGaNsu3//vso8BgYGkMtVr1u0tbUFADx79gxWVlYAoNa4eQ0bNoRcLkdcXBzatGlT4HzOzs748ssv8eWXX2LGjBnYuHEjCzsiovfw95WnmLH7KtKy5ahgaoCVnzZEa7cKmg6r3GFhp8VSU1Nx79495evIyEiEh4fD2toaLi4ukEgkmDhxIhYuXAg3Nze4urpi1qxZcHJyQp8+fdR+HzMzM0yZMgWTJk2CQqFA69atkZSUhLNnz8Lc3BzDhg2Dm5sb/vjjD/z7779wdXXFf//7X4SEhMDV1VW5nipVquDff/9FREQEKleuDCsrK1SvXh3Ozs6YO3cuFi1ahLt372L58uXvjKlGjRrw9vbG0KFDsXz5cjRs2BDPnz/H0aNH0aBBA3Tv3h0TJ05E165dUaNGDbx8+RLHjx9H7dq1C5VjIqLyLlMmx4L9NxFwIQoA0MzVGqsHN4S9uaGGIyufWNhpsUuXLqFDhw7K15MnTwYADBs2DJs3bwYATJs2DWlpafDx8UFiYiJat26NQ4cOwdCwcF/IBQsWwNbWFn5+fnjw4AEsLS3h6emJmTNnAgBGjx6NsLAwfPrpp5BIJBg8eDDGjBmDgwcPKtfxxRdf4Pjx4/joo4+QmpqK48ePo3379ti6dSu++uorNGjQAE2aNMHChQsxYMCAd8a0adMmLFy4EF9//TWio6NRoUIFNG/eHD169ADwaggWX19fPHnyBObm5vj444/x448/Fmq7iYjKs4fxafANDMWNp8mQSADf9tUx0csNerqlp3eqvJGI1y9eKseSk5NhYWGBpKQkmJubq0zLzMxEZGQkXF1dC13wAK+6YpOTkwt9p2d5VJpzVdT9oLjJZDIcOHAA3bp1g76+vqbDKdWYK/UxV+or77n65+ozfLP7KlKzcmBtYoAfP/VAuxq2Bc5fUvl62+93ecQzdkRERKS2rBw5vv/nFn4PfgQAaFLFCqsHN4SjhZGGIyOAhR0RERGpKepFOsZuDcXVJ0kAgK/aV8PXnWqw67UUYWFHRERE73Toegym7rqClMwcWBrr48eBHuhQy07TYdEbWNgRERFRgbJzFPA7eAubzj4EAHi6WGLNEE9UtGTXa2nEwq4QeJ9J+cbPn4jKm8cJ6Ri7NQxXHicCAHzaVsXULjWhz67XUouFnRpy795JT0+HkRH/h1JepaenA0C5vPuNiMqfoJux+HpHOJIzc2BhpI/lA9zhVcf+3QuSRrGwU4Ouri4sLS0RFxcHADA2NlZ5fNW7KBQKZGdnIzMzs9QN4VHalMZcCSGQnp6OuLg4WFpa5nlEGRGRNpHJFVh66DY2no4EALg7W8J/SENUsjLWcGSkDhZ2asp9rmpucVcYQghkZGTkeZ4p5VWac2VpaancD4iItNHTxAyMDQxFaFQiAGBkK1dM71oLBnql4z/a9G4s7NQkkUjg6OgIOzu7Qj/IWCaT4dSpU2jbti278d6htOZKX1+fZ+qISKsdvx2HSTvCkZgug5mhHn74xB0f1+N/ZssaFnaFpKurW+gfeF1dXeTk5MDQ0LBUFSulEXNFRPRhyeQKLD98F+tP3gcA1K9oAf8hnnCxYddrWcTCjoiIqJyKScrEuK2hCHn4EgAwrEVlzOxeG1I99lCUVSzsiIiIyqGTd59j0vZwJKRlw0yqhyWfNEC3+o6aDouKiIUdERFROZIjV+DHI3fhf/xV12tdJ3P4D/FElQomGo6MigMLOyIionIiNjkT47eG4UJkAgDgs+Yu+K57HRjqs+tVW7CwIyIiKgfORMRjwrYwvEjLhomBLvz6N0AvdydNh0XFjIUdERGRFpMrBFYdjcCaYxEQAqjlYIa13p6oamuq6dCoBLCwIyIi0lJxKZmYuC0c5+6/AAAMbuqMOT3rsutVi7GwIyIi0kLn7sdj/NZwxKdmwdhAF9/3rY8+DStqOiwqYSzsiIiItIhcIeB//B5WHrkLhQBq2pvB39sT1e3Y9VoesLAjIiLSEvGpWZi0PRynI+IBAAMaVcL83vVgZMCu1/KChR0REZEWuPDgBcZtDUNcShYM9XWwsE99fNKokqbDog+MhR0REVEZplAIrDt5H8sP34FCANXtTLHW2xM17M00HRppAAs7IiKiMiohLRuTtofj5N3nAIB+nhWxsE89GBvw57284idPRERUBl16mICxgWGISc6EVE8HC3rXw4DGlSCRSDQdGmkQCzsiIqIyRKEQ2HD6AX749w7kCoGqtiZY6+2JWg7mmg6NSgEWdkRERGXEy7RsfL3zCo7djgMA9PZwwqK+9WEq5c85vcI9gYiIqAwIjXqJsQGheJqUCQM9HcztWReDmzqz65VUsLAjIiIqxYQQ+PVMJBYfvI0chUAVG2P4e3uirpOFpkOjUoiFHRERUSmVlC7DlF1XEHQzFgDQvYEjFverDzNDfQ1HRqUVCzsiIqJSKPxxInwDQhGdmAEDXR3M6lkHnzVzYdcrvRULOyIiolJECIHN5x7i+wO3IJMLuFgbY623J+pVZNcrvRsLOyIiolIiKUOGb3ZdxaEbMQCArvUcsOSTBjBn1yupSUfTAQDAqVOn0LNnTzg5OUEikWDv3r0q04UQmD17NhwdHWFkZAQvLy9ERESozJOQkABvb2+Ym5vD0tISo0aNQmpq6gfcCiIiovd37UkSeq45g0M3YqCvK8HcnnWw1tuTRR0VSqko7NLS0uDu7g5/f/98py9duhSrV6/G+vXrceHCBZiYmKBLly7IzMxUzuPt7Y0bN24gKCgI+/fvx6lTp+Dj4/OhNoGIiOi9CCHwR/BD9F93DlEJ6ahkZYRdX7bE8FauvJ6OCq1UdMV27doVXbt2zXeaEAIrV67Ed999h969ewMA/vjjD9jb22Pv3r0YNGgQbt26hUOHDiEkJASNGzcGAKxZswbdunXDsmXL4OTk9MG2hYiISF0pmTJM330N/1x7BgDoVMceyz5xh4Uxz9LR+ykVhd3bREZGIiYmBl5eXso2CwsLNGvWDMHBwRg0aBCCg4NhaWmpLOoAwMvLCzo6Orhw4QL69u2bZ71ZWVnIyspSvk5OTgYAyGQyyGSyYt2G3PUV93q1EXOlPuZKfcyV+pgr9RU1VzefJWP8tqt4lJAOPR0JpnWpgeEtXCCRaGf+S2rf0sZcFUWpL+xiYl5dQGpvb6/Sbm9vr5wWExMDOzs7lel6enqwtrZWzvMmPz8/zJs3L0/74cOHYWxsXByh5xEUFFQi69VGzJX6mCv1MVfqY67UV9hcCQGci5Pgz0gd5AgJrAwEhtfIgX3iDRw8eKOEoiw9invfSk9PL9b1lXWlvrArKTNmzMDkyZOVr5OTk+Hs7IzOnTvD3Lx4H6Qsk8kQFBSETp06QV+fp9ffhrlSH3OlPuZKfcyV+t4nV6lZOZj1103sf/DqpEOHmhWwtF99WJaDrteS2rdye9zolVJf2Dk4OAAAYmNj4ejoqGyPjY2Fh4eHcp64uDiV5XJycpCQkKBc/k1SqRRSqTRPu76+fokdzEpy3dqGuVIfc6U+5kp9zJX61M3VrWfJ8A0IxYP4NOjqSDCtS0180aYqdHTK1w0Sxb1vcT9VVSruin0bV1dXODg44OjRo8q25ORkXLhwAS1atAAAtGjRAomJibh8+bJynmPHjkGhUKBZs2YfPGYiIqJcQghsuxiFPv5n8SA+DY4WhtgxujlGt6tW7oo6Knml4oxdamoq7t27p3wdGRmJ8PBwWFtbw8XFBRMnTsTChQvh5uYGV1dXzJo1C05OTujTpw8AoHbt2vj444/xxRdfYP369ZDJZBg7diwGDRrEO2KJiEhj0rJy8N3e69gTFg0AaF/TFisGesDaxEDDkZG2KhWF3aVLl9ChQwfl69xr34YNG4bNmzdj2rRpSEtLg4+PDxITE9G6dWscOnQIhoaGymUCAgIwduxYdOzYETo6Oujfvz9Wr179wbeFiIgIAO7GpuCrLZdx//mrrtevO9fAl215lo5KVqko7Nq3bw8hRIHTJRIJ5s+fj/nz5xc4j7W1NQIDA0siPCIiokLZeekxZv11HZkyBezNpVgz2BNNXa01HRaVA6WisCMiItIGGdlyzPrrOnZdfgIAaONWAT9+6oEKpnlv1iMqCSzsiIiIisG9uBSMCQjF3dhU6EiASV414NuhOrte6YNiYUdERFREe8Ke4Ns915GeLYetmRSrBnmgZbUKmg6LyiEWdkRERO8pWw58u/cGdlx+dddry2o2WDWoIWzN2PVKmsHCjoiI6D1Exqfhx+u6eJoeDYkEGP+RG8Z3dIMuu15Jg1jYERERFdLfV55ixu6rSMuWwMbEAKsGNURrN3a9kuaxsCMiIlJTpkyOBftvIuBCFACgurkCv3/ZAhWtTTUcGdErLOyIiIjU8DA+DWMCQnHzWTIkEuCrtlVRPesu7Hg9HZUipf5ZsURERJr2z9Vn6LHmDG4+S4a1iQE2j2iKSV7VocvL6aiU4Rk7IiKiAmTlyLHon1v4I/gRAKBpFWusHtwQDhaGkMlkGo6OKC8WdkRERPmIepEO38BQXItOAgB81b4avu5UA3q67Oyi0ouFHRER0RsOXY/B1F1XkJKZA0tjffw40AMdatlpOiyid2JhR0RE9P+ycxTwO3gLm84+BAB4uljipyGecLI00mxgRGpiYUdERATgcUI6xm4Nw5XHiQCA0W2rYkqXmtBn1yuVISzsiIio3Dt8IwZTdl5BcmYOLIz0sXyAO7zq2Gs6LKJCY2FHRETllkyuwJKDt/HLmUgAgLuzJfyHNEQlK2MNR0b0fljYERFRuRSdmIGxgaEIi0oEAIxq7YpvPq4FAz12vVLZxcKOiIjKnWO3YzF5xxUkpstgZqiHZQPc0aWug6bDIioyFnZERFRuyOQKLDt8Bz+ffAAAaFDJAv5DPOFsza5X0g4s7IiIqFx4lpSBcYFhuPToJQBgeMsqmNGtFqR6uhqOjKj4sLAjIiKtd+JOHCbvuIKEtGyYSfWw5JMG6FbfUdNhERU7FnZERKS1cuQK/HjkLvyP3wcA1HUyh/8QT1SpYKLhyIhKBgs7IiLSSrHJmRi/NQwXIhMAAJ81d8F33evAUJ9dr6S9WNgREZHWOR3xHBO3heNFWjZMpXrw61cfPd2dNB0WUYljYUdERFpDrhBYdeQu1hy/ByGAWg5mWOvtiaq2ppoOjeiDYGFHRERaIS4lExO2hiP4wQsAwOCmLpjTk12vVL6wsCMiojLv3L14jN8WjvjULBgb6OL7vvXRp2FFTYdF9MGxsCMiojJLrhD46dg9rDp6FwoB1LQ3g7+3J6rbseuVyicWdkREVCbFp2Zh4rZwnLkXDwAY2LgS5vWqByMDdr1S+cXCjoiIypzzD15g/NYwxKVkwUhfFwv71EP/RpU0HRaRxrGwIyKiMkOhEFh38j6WH74DhQDc7Eyx1tsTbvZmmg6NqFRgYUdERGXCi9QsTNpxBafuPgcA9POsiIV96sHYgD9lRLn4bSAiolIv5GECxgWGISY5E1I9HSzoXQ8DGleCRCLRdGhEpQoLOyIiKrUUCoENpx/gh3/vQK4QqGprgrXenqjlYK7p0IhKJRZ2RERUKr1My8bXO6/g2O04AEBvDyd837c+TKT86SIqCL8dRERU6lx+9BLjAkPxNCkTBno6mNuzLgY3dWbXK9E7sLAjIqJSQwiBX05HYsmh28hRCLhWMIH/EE/UcWLXK5E6WNgREVGpkJQuw9c7r+DIrVgAQI8GjvDrVx9mhvoajoyo7GBhR0REGhf+OBG+AaGITsyAga4OZvWsg8+aubDrlaiQWNgREZHGCCGw6exD+B28BZlcwMXaGGu9PVGvooWmQyMqk1jYERGRRiRlyPDNrqs4dCMGANC1ngOWfNIA5ux6JXpvLOyIiOiDu/okEb6BoXickAF9XQm+7VYbw1pWYdcrURGxsCMiog9GCIH/nn+EhftvIVuuQCUrI/gP8YS7s6WmQyPSCizsiIjog0jOlGHG7mv459ozAEDnOvb44RN3WBiz65WouLCwIyKiEnc9Ogm+gaF49CIdejoSzOhWGyNbseuVqLixsCMiohIjhEDAhSjM338T2TkKVLQ0wpohDeHpYqXp0Ii0Egs7IiIqEalZOZj55zX8feUpAMCrth2WDXCHpbGBhiMj0l46mg5AHXK5HLNmzYKrqyuMjIxQrVo1LFiwAEII5TxCCMyePRuOjo4wMjKCl5cXIiIiNBg1EVH5detZMnqtOYO/rzyFro4EM7vVwsahjVnUEZWwMnHGbsmSJVi3bh1+//131K1bF5cuXcKIESNgYWGB8ePHAwCWLl2K1atX4/fff4erqytmzZqFLl264ObNmzA0NNTwFhARlQ9CCGwPeYw5f99AVo4CjhaG+GlIQzSqbK3p0IjKhTJR2J07dw69e/dG9+7dAQBVqlTB1q1bcfHiRQCvDiQrV67Ed999h969ewMA/vjjD9jb22Pv3r0YNGiQxmInIiov0rJy8N3e69gTFg0AaF/TFisGesDahGfpiD6UMlHYtWzZEhs2bMDdu3dRo0YNXLlyBWfOnMGKFSsAAJGRkYiJiYGXl5dyGQsLCzRr1gzBwcH5FnZZWVnIyspSvk5OTgYAyGQyyGSyYo0/d33FvV5txFypj7lSH3OlvvfN1d3YFIzbdhUP4tOgqyPBpI7V8UXrKtDRkWht3rlfFU5J5Yv5VyURr1+oVkopFArMnDkTS5cuha6uLuRyORYtWoQZM2YAeHVGr1WrVnj69CkcHR2Vyw0cOBASiQTbt2/Ps865c+di3rx5edoDAwNhbGxcchtDRKRlLsRJsDNSBzKFBBb6AsNqyFHNXNNRUXmRnp6OIUOGICkpCebm3PHKxBm7HTt2ICAgAIGBgahbty7Cw8MxceJEODk5YdiwYe+1zhkzZmDy5MnK18nJyXB2dkbnzp2LfceQyWQICgpCp06doK/PgTjfhrlSH3OlPuZKfYXJVUa2HHP338Kf91/d9dq6ug2W9a8HG1PphwhV47hfFU5J5Su3x41eKROF3dSpUzF9+nRll2r9+vXx6NEj+Pn5YdiwYXBwcAAAxMbGqpyxi42NhYeHR77rlEqlkErzHnz09fVL7AtakuvWNsyV+pgr9TFX6ntXru7FpWBMQCjuxqZCRwJM7lQDY9pXh45O+RtwmPtV4RR3vph7VWViuJP09HTo6KiGqqurC4VCAQBwdXWFg4MDjh49qpyenJyMCxcuoEWLFh80ViIibfdn6BP0XHMWd2NTYWsmRcB/mmPsR27lsqgjKm3KxBm7nj17YtGiRXBxcUHdunURFhaGFStWYOTIkQAAiUSCiRMnYuHChXBzc1MOd+Lk5IQ+ffpoNngiIi2RKZNjzl83sP3SYwBAq+o2WPlpQ9ialY+uV6KyoEwUdmvWrMGsWbMwZswYxMXFwcnJCaNHj8bs2bOV80ybNg1paWnw8fFBYmIiWrdujUOHDnEMOyKiYnD/eSp8A0JxOyYFEgkwoaMbxn3kBl2epSMqVcpEYWdmZoaVK1di5cqVBc4jkUgwf/58zJ8//8MFRkRUDvwVHo2Zf15DWrYcFUwNsGpQQ7SqXkHTYRFRPspEYUdERB9epkyO+ftvIvBCFACgeVVrrB7UEHbm7AkhKq1Y2BERUR6PXqRj/ParuPksGRIJMLZDdUzo6AY93TJxzx1RucXCjoiIVIS9kGDmumCkZclhbWKAlZ96oG0NW02HRURqYGFHREQAgKwcORbsv4Utd3UByNG0ijVWD24IBwt2vRKVFSzsiIgIUS/SMSbwMq5HvxrFf3QbV0z9uBa7XonKGBZ2RETl3KHrzzB111WkZObAylgfA10yMaUzr6cjKov4rSUiKqeycxSY+/cNfLklFCmZOWhU2Qp/jWmBOlZC06ER0XviGTsionLocUI6xgaG4sqTJADA6LZVMaVLTUAhR5iGYyOi98fCjoionDl8IwZTdl5BcmYOLIz0sXyAO7zq2AMAZAq5hqMjoqJgYUdEVE7I5AosOXgbv5yJBAB4OFvipyENUcnKWMOREVFxYWFHRFQORCdmYGxgKMKiEgEAo1q74puPa8FAj5daE2kTFnZERFru2O1YTN5xBYnpMpgZ6mHZAHd0qeug6bCIqASwsCMi0lIyuQLLDt/BzycfAAAaVLKA/xBPOFuz65VIW7GwIyLSQs+SMjAuMAyXHr0EAAxvWQUzutWCVE9Xw5ERUUliYUdEpGVO3InDpO3heJkug5lUD0s+aYBu9R01HRYRfQAs7IiItESOXIEfj9yF//H7AIB6Fc3hP8QTlW1MNBwZEX0oLOyIiLRAbHImxm0Nw8XIBADA580r49vutWGoz65XovKEhR0RURl3OuI5Jm4Lx4u0bJhK9eDXrz56ujtpOiwi0gAWdkREZZRcIbDqyF2sOX4PQgC1Hc2x1tsTrhXY9UpUXrGwIyIqg+JSMjFhaziCH7wAAAxu6oI5Peuw65WonGNhR0RUxpy7F4/x28IRn5oFYwNd+PWrj94eFTUdFhGVAizsiIjKCLlC4Kdj97Dy6F0IAdS0N4O/tyeq25lqOjQiKiVY2BERlQHxqVmYuC0cZ+7FAwA+beyMub3qwsiAXa9E9D8s7IiISrnzD15g/NYwxKVkwUhfFwv71EP/RpU0HRYRlUIs7IiISimFQmDdyftYfvgOFAJwszPFWm9PuNmbaTo0IiqlWNgREZVCL1KzMGnHFZy6+xwA0M+zIhb2qQdjAx62iahgPEIQEZUyIQ8TMC4wDDHJmTDU18H83vUwsLGzpsMiojKAhR0RUSmhUAj8fOoBlh2+A7lCoKqtCdZ5N0JNB3a9EpF6WNgREZUCL9OyMXlHOI7fedX12sfDCYv61oeJlIdpIlIfjxhERBp2+dFLjAsMxdOkTBjo6WBer7oY1MQZEolE06ERURnDwo6ISEOEEPjldCSWHLqNHIWAawUT+A/xRB0nc02HRkRlVJELO5lMhpiYGKSnp8PW1hbW1tbFERcRkVZLSpfh651XcORWLACgRwNH+PWrDzNDfQ1HRkRl2XsVdikpKdiyZQu2bduGixcvIjs7G0IISCQSVKpUCZ07d4aPjw+aNGlS3PESEZV54Y8T4RsQiujEDBjo6mBWzzr4rJkLu16JqMh0CrvAihUrUKVKFWzatAleXl7Yu3cvwsPDcffuXQQHB2POnDnIyclB586d8fHHHyMiIqIk4iYiKnOEEPj1TCQGrD+H6MQMVLYxxp9jWuLz5pVZ1BFRsSj0GbuQkBCcOnUKdevWzXd606ZNMXLkSKxfvx6bNm3C6dOn4ebmVuRAiYjKsqQMGabtuoJ/b7zqeu1W3wGL+zeAObteiagYFbqw27p1q1rzSaVSfPnll4UOiIhI21x9kgjfwFA8TsiAvq4E33Wvg6EteJaOiIpfkW6eSEpKglwuz3PDREJCAvT09GBuzju7iKj8EkLgj+BHWPTPLWTLFXC2NoL/EE80qGSp6dCISEsV+hq71w0aNAjbtm3L075jxw4MGjSoKKsmIirTkjNlGBsYhjl/30C2XIHOdeyxf1wbFnVEVKKKVNhduHABHTp0yNPevn17XLhwoSirJiIqs65HJ6HnmjP459oz6OlIMKtHHfz8eSNYGPF6OiIqWUXqis3KykJOTk6edplMhoyMjKKsmoiozBFCIOBCFObvv4nsHAUqWhrhpyEN0dDFStOhEVE5UaQzdk2bNsWGDRvytK9fvx6NGjUqyqqJiMqU1KwcjN8Wju/2Xkd2jgJete3wz/jWLOqI6IMq0hm7hQsXwsvLC1euXEHHjh0BAEePHkVISAgOHz5cLAESEZV2t54lwzcgFA/i06CrI8E3H9fEF22q8q5XIvrginTGrlWrVggODoazszN27NiBffv2oXr16rh69SratGlTXDESEZVKQghsuxiFPv5n8SA+DY4Whtgxujl82lZjUUdEGlHkZ8V6eHggICCgOGIhIioz0rJy8N3e69gTFg0A6FDTFisGesDKxEDDkRFReVbowi4tLQ0mJiYlNj8RUWl3JyYFYwIu4/7zV12vUzrXxOi2VaGjw7N0RKRZhe6KrV69OhYvXoxnz54VOI8QAkFBQejatStWr15dpACJiEqTHZceo7f/Gdx/ngZ7cym2ftEcX7WvxqKOiEqFQp+xO3HiBGbOnIm5c+fC3d0djRs3hpOTEwwNDfHy5UvcvHkTwcHB0NPTw4wZMzB69OiSiJuI6INKz87BrL03sDv0CQCgbQ1b/DjQHTamUg1HRkT0P4Uu7GrWrIndu3cjKioKO3fuxOnTp3Hu3DlkZGSgQoUKaNiwITZu3IiuXbtCV1e3JGImIvqgImJTMCYgFBFxqdCRAJM71cCY9tV5lo6ISp33vnnCxcUFX3/9Nb7++uvijKdA0dHR+Oabb3Dw4EGkp6ejevXq2LRpExo3bgzgVffvnDlzsHHjRiQmJqJVq1ZYt24d3NzcPkh8RKSd/gx9gm/3XEeGTA5bMylWD2qIFtVsNB0WEVG+ijTcyYfy8uVLtGrVCvr6+jh48CBu3ryJ5cuXw8rqfwN/Ll26FKtXr8b69etx4cIFmJiYoEuXLsjMzNRg5ERUVmXK5Phm11VM3nEFGTI5WlW3wYHxbVjUEVGpVqThTvr16/fW6X/++WdRVq+0ZMkSODs7Y9OmTco2V1dX5b+FEFi5ciW+++479O7dGwDwxx9/wN7eHnv37sWgQYOKJQ4iKh/uP0+Fb0AobsekQCIBJnasgbEfVYcuu16JqJQrUmG3d+9eDBw4EEZGRgCAwMBA9OzZE2ZmZsUSXK6///4bXbp0wYABA3Dy5ElUrFgRY8aMwRdffAEAiIyMRExMDLy8vJTLWFhYoFmzZggODs63sMvKykJWVpbydXJyMoBXz7mVyWTFGn/u+op7vdqIuVIfc6W+wuTq7yvPMOvvm0jPlsPGxAArBtRHy2o2UMhzoJCXdKSax/1KfcxV4ZRUvph/VRIhhHjfhXV0dBATEwM7OzsAgJmZGa5cuYKqVasWW4AAYGhoCACYPHkyBgwYgJCQEEyYMAHr16/HsGHDcO7cObRq1QpPnz6Fo6OjcrmBAwdCIpFg+/btedY5d+5czJs3L097YGAgjI2NizV+Iir9ZArgz0gdnIt7dYVKdXMFhropYMHxholKtfT0dAwZMgRJSUkwNzfXdDgaV6QzdoaGhspr2IQQyM7OxqpVq7BixYpivSNWoVCgcePG+P777wEADRs2xPXr15WF3fuYMWMGJk+erHydnJwMZ2dndO7cudh3DJlMhqCgIHTq1An6+vrFum5tw1ypj7lS37ty9fBFGsZtu4rbca+6Xse0q4pxHaqVy65X7lfqY64Kp6TyldvjRq8UqbCrUaMGVq5ciWnTpmHr1q0wMzPD5cuX0aFDB+zcuRP29vbFEqSjoyPq1Kmj0la7dm3s3r0bAODg4AAAiI2NVTljFxsbCw8Pj3zXKZVKIZXmHX9KX1+/xL6gJblubcNcqY+5Ul9+udp/9Smm776G1Kwc2JgY4MdPPdC2hq2GIiw9uF+pj7kqnOLOF3Ovqkh3xS5cuBAbNmxAxYoVMX36dCxduhQnTpyAh4cHGjZsWFwxolWrVrhz545K2927d1G5cmUAr26kcHBwwNGjR5XTk5OTceHCBbRo0aLY4iAi7ZGVI8esvdcxNjAMqVk5aFrFGv+Mb8OijojKtCKdsevRoweio6Nx9+5dODs7K8+crV69Gi1btiyWAAFg0qRJaNmyJb7//nsMHDgQFy9exIYNG7BhwwYAgEQiwcSJE7Fw4UK4ubnB1dUVs2bNgpOTE/r06VNscRCRdnj0Ig2+gaG4Hv2qC2dM+2qY3KkG9HTLxAhQREQFKlJhB7y6+7RJkyZ52otziJEmTZpgz549mDFjBubPnw9XV1esXLkS3t7eynmmTZuGtLQ0+Pj4IDExEa1bt8ahQ4eUN14QEQHAwWvPMG3XVaRk5cDKWB8rPvVAh5p2mg6LiKhYFKmwO3Xq1Funt23btiirV9GjRw/06NGjwOkSiQTz58/H/Pnzi+09iUh75CiABf/cxh/nowAAjSpbYc3ghnCyNNJwZERExadIhV379u0hkby6a+zNUVMkEgnk8nIw6BMRlXpPXmZg1XVdRKW9KupGt62KKV1qQp9dr0SkZYpU2Lm7uyM+Ph6jRo3C0KFDYWPDR+0QUely+EYMpuy8guRMCSyM9LBioAc61i6eO/aJiEqbIv13NSwsDH/++Seio6PRrFkzjBkzBuHh4bCwsICFhUVxxUhEVGjZOQos2H8TPv+9jOTMHFQxFfh7TAsWdUSk1YrcD9GkSRNs3LgRDx48QMuWLdG7d2+sXLmyGEIjIno/0YkZGPhzMH49EwkAGNmyMsbVlfN6OiLSekW+KxYAHj9+jF9++QW//fYbPD090bp16+JYLRFRoR29FYvJO64gKUMGc0M9LBvgjg41bHDgwH1Nh0ZEVOKKVNjt3bsXGzZsQFhYGD7//HMcO3YMbm5uxRUbEZHaZHIFlv17Bz+fegAAcK9kgZ+GeMLZ2pgPCSeicqNIhV2/fv1QqVIl9O/fHzk5OVi3bp3K9BUrVhQpOCIidTxLysDYwDBcfvQSADC8ZRXM6FYLUr3ie2Y1EVFZUKTCrm3btpBIJLhx40aeabnDoBARlaTjd+IweXs4XqbLYCbVw9JPGqBrfcd3L0hEpIWKVNidOHGimMIgIiqcHLkCK4LuYu2JV9fO1atoDv8hnqhsY6LhyIiINKdYbp64d+8e7t+/j7Zt28LIyAhCCJ6xI6ISE5OUifFbw3DxYQIA4PPmlfFt99ow1GfXKxGVb0Uq7F68eIGBAwfi+PHjkEgkiIiIQNWqVTFq1ChYWVlh+fLlxRUnEREA4NTd55i0PRwv0rJhKtWDX7/66OnupOmwiIhKhSKNYzdp0iTo6+sjKioKxsbGyvZPP/0Uhw4dKnJwRES55AqBFYfvYNimi3iRlo06jubYN641izoiotcU6Yzd4cOH8e+//6JSpUoq7W5ubnj06FGRAiMiyhWXnInx28Jw/sGrrtchzVwwu0cddr0SEb2hSIVdWlqaypm6XAkJCZBKpUVZNRERAODcvXiM3xaO+NQsGBvowq9fffT2qKjpsIiISqUidcW2adMGf/zxh/K1RCKBQqHA0qVL0aFDhyIHR0Tll1whsPLIXXj/egHxqVmo5WCGfeNas6gjInqLIp2xW7p0KTp27IhLly4hOzsb06ZNw40bN5CQkICzZ88WV4xEVM48T8nCpO3hOHMvHgDwaWNnzO1VF0YG7HolInqbIhV29erVw927d/HTTz/BzMwMqamp6NevH3x9feHoyAFCiajwzj94gXFbw/A8JQtG+rpY2Kce+jeq9O4FiYio6OPYWVhY4Ntvvy2OWIioHFMoBNaeuIcVQXehEICbnSnWenvCzd5M06EREZUZRS7sXr58iV9//RW3bt0CANSpUwcjRoyAtbV1kYMjovLhRWoWJu24glN3nwMA+ntWwoI+dWFsUCxjqBMRlRtFunni1KlTqFKlClavXo2XL1/i5cuXWL16NVxdXXHq1KniipGItNjFyAR0W30ap+4+h6G+DpZ+0gDLB7qzqCMieg9FOnL6+vri008/xbp166Cr++qiZrlcjjFjxsDX1xfXrl0rliCJSPsoFAI/n3qAZYfvQK4QqGZrgrXejVDTgV2vRETvq0iF3b1797Br1y5lUQcAurq6mDx5ssowKEREr3uZlo3JO8Jx/M6rrtc+Hk5Y1Lc+TKQ8S0dEVBRFOop6enri1q1bqFmzpkr7rVu34O7uXqTAiEg7XX6UgLGBYXiWlAkDPR3M71UXnzZxhkQi0XRoRERlXpEKu/Hjx2PChAm4d+8emjdvDgA4f/48/P39sXjxYly9elU5b4MGDYoWKRGVaUIIbDz9AEsP3UGOQsC1ggn8h3iijpO5pkMjItIaRSrsBg8eDACYNm1avtMkEgmEEJBIJJDL5UV5KyIqwxLTszFl5xUcuRUHAOjp7gS/fvVhyq5XIqJiVaSjamRkZHHFQURaKizqJcYGhiE6MQMGejqY3aMOvJu5sOuViKgEFKmwMzU1hY2NDQDg8ePH2LhxIzIyMtCrVy+0adOmWAIkorJJCIHfzj7E4oO3IJMLVLYxhv8QT9SraKHp0IiItNZ7FXbXrl1Dz5498fjxY7i5uWHbtm34+OOPkZaWBh0dHfz444/YtWsX+vTpU8zhElFZkJQhw7RdV/DvjVgAQLf6DljcvwHMDfU1HBkRkXZ7rwGKp02bhvr16+PUqVNo3749evToge7duyMpKQkvX77E6NGjsXjx4uKOlYjKgKtPEtFjzWn8eyMWBro6mNerLvyHeLKoIyL6AN7rjF1ISAiOHTuGBg0awN3dHRs2bMCYMWOgo/OqThw3bpzyLlkiKh+EEPj93EMsOvCq69XZ2gj+QzzRoJKlpkMjIio33quwS0hIgIODA4BX19mZmJjAyspKOd3KygopKSnFEyERlXrJmTJM330VB67FAAC61LXH0k/cYWHEs3RERB/Se9888eYdbbzDjah8uh6dBN/AUDx6kQ59XQlmdK2NEa2q8JhARKQB713YDR8+HFKpFACQmZmJL7/8EiYmJgCArKys4omOiEotIQS2XIjCgn03kS1XoKKlEfy9PeHhbKnp0IiIyq33KuyGDRum8vqzzz7LM8/QoUPfLyIiKvVSs3IwffdV7L/6DADgVdsOywa4w9LYQMORERGVb+9V2G3atKm44yCiMuLm02T4BoYiMj4NejoSfPNxLfynjSu7XomISgE+z4eI1CKEwLaQx5j79w1k5SjgZGGINUM80aiy1bsXJiKiD4KFHRG9U1pWDr7dcw17w58CADrUtMWKgR6wMmHXKxFRacLCjoje6k5MCsYEXMb952nQ1ZFgSueaGN22KnR02PVKRFTasLAjogLtuPQYs/+6jkyZAg7mhlgzpCGaVLHWdFhERFQAFnZElEd6dg5m7b2B3aFPAABta9jix4HusDGVajgyIiJ6GxZ2RKQiIjYFYwJCERGXCh0JMLlTDYxpX51dr0REZQALOyJS+jP0Cb7dcx0ZMjnszKRYPbghmle10XRYRESkJhZ2RISMbDnm/H0dOy696nptXb0CfvzUA7Zm7HolIipLWNgRlXP3n6dizJZQ3IlNgUQCTOxYA2M/qg5ddr0SEZU5LOyIyrG/wqMx489rSM+Wo4KpFKsHeaBl9QqaDouIiN4TCzuicihTJse8fTex9WIUAKBFVRusGuwBOzNDDUdGRERFwcKOqJyJjE/DmIBQ3HqWDIkEGNehOiZ41WDXKxGRFtDRdADvY/HixZBIJJg4caKyLTMzE76+vrCxsYGpqSn69++P2NhYzQVJVArtv/oUPdecwa1nybAxMcDvI5picueaLOqIiLREmSvsQkJC8PPPP6NBgwYq7ZMmTcK+ffuwc+dOnDx5Ek+fPkW/fv00FCVR6ZIpk2PW3usYGxiG1KwcNHW1xoEJbdC2hq2mQyMiomJUpgq71NRUeHt7Y+PGjbCyslK2JyUl4ddff8WKFSvw0UcfoVGjRti0aRPOnTuH8+fPazBiIs179CINn6w/h/+efwQAGNO+GgL/0wz25ryejohI25Spa+x8fX3RvXt3eHl5YeHChcr2y5cvQyaTwcvLS9lWq1YtuLi4IDg4GM2bN8+zrqysLGRlZSlfJycnAwBkMhlkMlmxxp27vuJerzZirtSnTq4O3YjFjD03kJqVAytjffzQvx7a1bCFUMghU8g/VKgax/1KfcyV+pirwimpfDH/qspMYbdt2zaEhoYiJCQkz7SYmBgYGBjA0tJSpd3e3h4xMTH5rs/Pzw/z5s3L03748GEYGxsXS8xvCgoKKpH1aiPmSn355SpHAfz1SAenYl6dlHc1ExjuloG0eyE4cO9DR1h6cL9SH3OlPuaqcIo7X+np6cW6vrKuTBR2jx8/xoQJExAUFARDw+LpPpoxYwYmT56sfJ2cnAxnZ2d07twZ5ubmxfIeuWQyGYKCgtCpUyfo6+sX67q1DXOlvoJy9fhlOiZuv4qrMa/OQn/RugomeVWHvm6ZuvKiWHG/Uh9zpT7mqnBKKl+5PW70Spko7C5fvoy4uDh4enoq2+RyOU6dOoWffvoJ//77L7Kzs5GYmKhy1i42NhYODg75rlMqlUIqzfu4JH19/RL7gpbkurUNc6W+13P1740YTN15BcmZObAw0seKge7oWNtewxGWHtyv1MdcqY+5Kpzizhdzr6pMFHYdO3bEtWvXVNpGjBiBWrVq4ZtvvoGzszP09fVx9OhR9O/fHwBw584dREVFoUWLFpoImeiDys5RYMmh2/j1TCQAoKGLJX4a4omKlkYajoyIiD6kMlHYmZmZoV69eiptJiYmsLGxUbaPGjUKkydPhrW1NczNzTFu3Di0aNEi3xsniLRJdGIGJu64hvDHiQCA/7R2xbSPa8FAr/x2vRIRlVdlorBTx48//ggdHR30798fWVlZ6NKlC9auXavpsIhK1PWXEsxeG4ykjByYG+ph2QB3dK6b/+UHRESk/cpsYXfixAmV14aGhvD394e/v79mAiL6gGRyBZb8exe/3NYFkAP3Shb4aYgnnK1L5o5uIiIqG8psYUdUXj1NzMC4rWG4/OglAGBYCxd8270uu16JiIiFHVFZcvxOHCZvD8fLdBnMDPUwwCULM7rVgj6LOiIiQhl7pBhReZUjf3XX64hNIXiZLkO9iubY+1VzuNsITYdGRESlCM/YEZVyMUmZGL81DBcfJgAAhraojG+714aOUOC6hmMjIqLShYUdUSl26u5zTNoejhdp2TCV6mFx//ro0cAJACCTKTQcHRERlTYs7IhKIblCYOWRu/jp+D0IAdRxNIe/tydcK5hoOjQiIirFWNgRlTJxyZkYvy0M5x+86nod0swFs3vUgaG+roYjIyKi0o6FHVEpcvZePCZsC0d8ahZMDHTxfb/66O1RUdNhERFRGcHCjqgUkCsE1hyLwKqjERACqOVgBn9vT1SzNdV0aEREVIawsCPSsOcpWZi4PQxn770AAHza2Blze9WFkQG7XomIqHBY2BFpUPD9Fxi/LQzPU7JgpK+LRX3roZ9nJU2HRUREZRQLOyINUCgE/I/fw49H7kIhgBr2pljr7YnqdmaaDo2IiMowFnZEH9iL1CxM3B6O0xHxAIBPGlXC/N51YWzAryMRERUNf0mIPqCLkQkYtzUUsclZMNTXwYLe9TCgsbOmwyIiIi3Bwo7oA1AoBNafuo/lh+9CrhCoZmuCtd6NUNOBXa9ERFR8WNgRlbCEtGx8vSMcx+88BwD0bVgRC/vUg4mUXz8iIipe/GUhKkGXHyVgbGAYniVlQqqng3m96uLTJs6QSCSaDo2IiLQQCzuiEiCEwMbTD7D00B3kKASqVjCBv7cnajuaazo0IiLSYizsiIpZYno2puy8giO34gAAPd2d4NevPkzZ9UpERCWMvzRExSgs6iXGBoYhOjEDBno6mN2jDrybubDrlYiIPggWdkTFQAiB384+xOKDtyCTC1S2MYb/EE/Uq2ih6dCIiKgcYWFHVERJ6TJM3XUFh2/GAgC613fE4v71YWaor+HIiIiovGFhR1QEVx4nwjcwFE9eZsBAVwff9aiNz5tXZtcrERFpBAs7ovcghMDv5x5i0YFXXa/O1kbwH+KJBpUsNR0aERGVYyzsiAopOVOG6buv4sC1GABAl7r2WPqJOyyM2PVKRESaxcKOqBCuRyfBNzAUj16kQ19Xghlda2NEqyrseiUiolKBhR2RGoQQ2HIhCgv23US2XIGKlkbw9/aEh7OlpkMjIiJSYmFH9A4pmTLM+PMa9l99BgDwqm2PZQMawNLYQMORERERqWJhR/QWN58mwzcwFJHxadDTkWB611oY1dqVXa9ERFQqsbAjyocQAlsvPsbcfTeQnaOAk4Uh1gzxRKPKVpoOjYiIqEAs7IjekJaVg5l7ruGv8KcAgA41bbFioAesTNj1SkREpRsLO6LX3I5JxpiAUDx4ngZdHQmmdqkJnzZVoaPDrlciIir9WNgR4VXX685LTzD77+vIlCngYG6INUMaokkVa02HRkREpDYWdlTupWfn4Lu91/FnaDQAoG0NW/w40B02plINR0ZERFQ4LOyoXIuITcGYgFBExKVCRwJ83bkmvmpXjV2vRERUJrGwo3Jr9+Un+G7vdWTI5LAzk2L14IZoXtVG02ERERG9NxZ2VO5kZMsx5+/r2HHpCQCgdfUK+PFTD9iaseuViIjKNhZ2VK7ci0uFb0Ao7sSmQCIBJnasgbEfVYcuu16JiEgLsLCjcuOv8GjM+PMa0rPlqGAqxepBHmhZvYKmwyIiIio2LOxI62XK5Ji37wa2XnwMAGhR1QarBnvAzsxQw5EREREVLxZ2pNUePE+Fb2AYbj1LhkQCjPvIDRM6urHrlYiItBILO9Ja+648xfTdV5GWLYeNiQFWDvJAGzdbTYdFRERUYljYkdbJlMmx8J+b2HI+CgDQ1NUaawY3hL05u16JiEi7sbAjrfLoRRrGBITixtNkAIBvh2qY5FUDero6Go6MiIio5LGwI61x8NozTNt1FSlZObAy1sePn3qgfU07TYdFRET0wbCwozIvK0cOvwO3sfncQwBA48pWWDOkIRwtjDQbGBER0QfGwo7KtMcJ6fANDMXVJ0kAgNHtqmJK55rQZ9crERGVQyzsqMz690YMpu68guTMHFga62P5AHd0rG2v6bCIiIg0pkyc1vDz80OTJk1gZmYGOzs79OnTB3fu3FGZJzMzE76+vrCxsYGpqSn69++P2NhYDUVMJSk7R4EF+29i9H8vIzkzB54ulvhnfBsWdUREVO6VicLu5MmT8PX1xfnz5xEUFASZTIbOnTsjLS1NOc+kSZOwb98+7Ny5EydPnsTTp0/Rr18/DUZNJeHJy3QM/DkYv56JBAB80cYV20e3QEVLXk9HRERUJrpiDx06pPJ68+bNsLOzw+XLl9G2bVskJSXh119/RWBgID766CMAwKZNm1C7dm2cP38ezZs310TYVMyO3IzF1zuvIClDBnNDPSwb4I7OdR00HRYREVGpUSYKuzclJb26UN7a2hoAcPnyZchkMnh5eSnnqVWrFlxcXBAcHJxvYZeVlYWsrCzl6+TkV+OeyWQyyGSyYo03d33FvV5tlF+uZHIFlgdF4NezjwAADSqZY9VAd1SyMirXOeV+pT7mSn3MlfqYq8IpqXwx/6okQgih6SAKQ6FQoFevXkhMTMSZM2cAAIGBgRgxYoRKoQYATZs2RYcOHbBkyZI865k7dy7mzZuXpz0wMBDGxsYlEzwV2sss4PcIXUSmvHq2azsHBXpVVkCvTFxEQEREJS09PR1DhgxBUlISzM3NNR2OxpW5M3a+vr64fv26sqh7XzNmzMDkyZOVr5OTk+Hs7IzOnTsX+44hk8kQFBSETp06QV9fv1jXrW1ez9W5yETM3X0dL9NlMDPUg1+fuuhSlzdI5OJ+pT7mSn3MlfqYq8IpqXzl9rjRK2WqsBs7diz279+PU6dOoVKlSsp2BwcHZGdnIzExEZaWlsr22NhYODjkfw2WVCqFVCrN066vr19iX9CSXLc2kQtg1fGH+Pn0qxsk6le0gP8QT7jY8ExqfrhfqY+5Uh9zpT7mqnCKO1/Mvaoy0aElhMDYsWOxZ88eHDt2DK6urirTGzVqBH19fRw9elTZdufOHURFRaFFixYfOlwqgpjkTPjf0FUWdcNaVMaur1qwqCMiIlJDmThj5+vri8DAQPz1118wMzNDTEwMAMDCwgJGRkawsLDAqFGjMHnyZFhbW8Pc3Bzjxo1DixYteEdsGXLy7nNM3BaGl+kSmEh1sbS/O7o3cNR0WERERGVGmSjs1q1bBwBo3769SvumTZswfPhwAMCPP/4IHR0d9O/fH1lZWejSpQvWrl37gSOl9yFXCKw8chc/Hb8HIYCKxgKbfZrDzcFS06ERERGVKWWisFPnxl1DQ0P4+/vD39//A0RExSUuORPjt4Xh/IMEAMDgJpXQSOchqtiYaDgyIiKisqdMXGNH2unsvXh0W30a5x8kwMRAF6sGeWB+rzrQ515JRET0XsrEGTvSLnKFwOqjEVh9LAJCALUczODv7YlqtqYcaJKIiKgIWNjRB/U8JQsTt4fh7L0XAIBBTZwxt1ddGOrrajgyIiKiso+FHX0wwfdfYPy2MDxPyYKRvi6+71cPfRtWeveCREREpBYWdlTiFAoB/+P38OORu1AIoIa9KdZ6e6K6nZmmQyMiItIqLOyoRL1IzcLE7eE4HREPAPikUSXM710Xxgbc9YiIiIobf12pxFyMTMC4raGITc6Cob4OFvSuhwGNnTUdFhERkdZiYUfFTqEQWHfyPlYE3YVcIVDN1gRrvRuhpgO7XomIiEoSCzsqVglp2Zi8Ixwn7jwHAPRtWBEL+9SDiZS7GhERUUnjry0Vm0sPEzBuaxieJWVCqqeD+b3rYmBjZ0gkEk2HRkREVC6wsKMiUygENp5+gKX/3oFcIVC1ggn8vT1R29Fc06ERERGVKyzsqEgS07Px9Y4rOHo7DgDQ090Jfv3qw5Rdr0RERB8cf33pvYVGvcS4wDBEJ2bAQE8Hc3rWwZCmLux6JSIi0hAWdlRoQgj8eiYSiw/eRo5CoIqNMX4a4ol6FS00HRoREVG5xsKOCiUpXYYpu64g6GYsAKB7fUcs7l8fZob6Go6MiIiIWNiR2q48ToRvYCievMyAga4OvutRG583r8yuVyIiolKChR29kxACv597iEUHbkEmF3C2NsLaIY1QvxK7XomIiEoTFnb0VsmZMnyz6yoOXo8BAHSpa4+ln7jDwohdr0RERKUNCzsq0PXoJIwJCEVUQjr0dSWY0bU2RrSqwq5XIiKiUoqFHeUhhMCWC1FYsO8msuUKVLQ0gr+3JzycLTUdGhEREb0FCztS8SI1C9P/vKa867VTHXss+8QdFsbseiUiIirtWNiR0rHbsZi26xriU7OgryvBNx/XwqjWrux6JSIiKiNY2BHSs3Ow6J9bCLgQBQCoYW+KHz/1QF0n3vVKRERUlrCwK+euPE7EpO3heBCfBgAY2coV0z6uCUN9XQ1HRkRERIXFwq6cypErsPbEfaw6GgG5QsDB3BDLBrijtVsFTYdGRERE74mFXTn06EUaJm4PR1hUIgCgRwNHLOxTD5bGBpoNjIiIiIqEhV05IoTA9pDHmL//JtKz5TCT6mFBn3ro7eHEGySIiIi0AAu7ciI+NQvTd1/DkVuvhjFp5mqN5QPdUcnKWMORERERUXFhYVcOvBrG5CriU7OhryvBlM418Z82VaGrw7N0RERE2oSFnRbLbxiTlZ82RB0ncw1HRkRERCWBhZ2WCv//YUwi/38Yk1GtXTG1C4cxISIi0mYs7LRMjlwB/+P3sfrY/4YxWT7QHa2qcxgTIiIibcfCTos8jE/DpB3/G8akp7sTFvaux+e8EhERlRMs7LSAEALbQh5jQe4wJoZ6WNinHnp7VNR0aERERPQBsbAr494cxqR5VWssH+iBipZGGo6MiIiIPjQWdmXY0Vux+Gb3q2FMDHR1MKVLDfyndVXocBgTIiKicomFXRmUnp2Dhf/cQuD/D2NS094MKwd5oLYjhzEhIiIqz1jYlTFvDmPyn9aumMJhTIiIiAgs7MqMHLkCPx2/hzXH7kGuEHC0MMTyAe5oyWFMiIiI6P+xsCsDIuPTMGl7OMIfJwIAerk7YQGHMSEiIqI3sLArxYQQ2Hrx1TAmGTIOY0JERERvx8KulHo1jMlVHLkVB4DDmBAREdG7sbArhd4cxmRql5oY1dqVw5gQERHRW7GwK0XSs3OwYP8tbL3IYUyIiIio8FjYlRJhUS8xaXs4Hr5IB8BhTIiIiKjwWNhpWI5cgTXH7uGn4xzGhIiIiIqGhZ0GRcanYeL2cFzhMCZERERUDHQ0HUBx8vf3R5UqVWBoaIhmzZrh4sWLmg4pX0IIBF6IQrdVp3HlcSLMDPWwapAHVg9uyKKOiIiI3pvWnLHbvn07Jk+ejPXr16NZs2ZYuXIlunTpgjt37sDOzk7T4QEAFAqB43fisPHUA5y7/wIA0KKqDZYNdOcwJkRERFRkWnPGbsWKFfjiiy8wYsQI1KlTB+vXr4exsTF+++03jcaVmpWDRy/SceqZBF1Wn8WITSE4d/8FDHR18G232gj4TzMWdURERFQstOKMXXZ2Ni5fvowZM2Yo23R0dODl5YXg4OB8l8nKykJWVpbydXJyMgBAJpNBJpMVW2yB5x/h+4N3AOgCSIepVA+feDrh8+YucLE2hlyeA7m82N6uzMvNfXF+BtqKuVIfc6U+5kp9zFXhlFS+mH9VWlHYxcfHQy6Xw97eXqXd3t4et2/fzncZPz8/zJs3L0/74cOHYWxsXGyx3Y2RQF+igwqGQCsHBZra5kCKB7h+/gGuF9u7aJ+goCBNh1BmMFfqY67Ux1ypj7kqnOLOV3p6erGur6zTisLufcyYMQOTJ09Wvk5OToazszM6d+4Mc/PiGxC4G4D5MhmCgoLQqVMn6Ovz5oi3kTFXamOu1MdcqY+5Uh9zVTglla/cHjd6RSsKuwoVKkBXVxexsbEq7bGxsXBwcMh3GalUCqlUmqddX1+/xL6gJblubcNcqY+5Uh9zpT7mSn3MVeEUd76Ye1VacfOEgYEBGjVqhKNHjyrbFAoFjh49ihYtWmgwMiIiIqIPRyvO2AHA5MmTMWzYMDRu3BhNmzbFypUrkZaWhhEjRmg6NCIiIqIPQmsKu08//RTPnz/H7NmzERMTAw8PDxw6dCjPDRVERERE2kprCjsAGDt2LMaOHavpMIiIiIg0QiuusSMiIiIiFnZEREREWoOFHREREZGWYGFHREREpCVY2BERERFpCRZ2RERERFqChR0RERGRlmBhR0RERKQlWNgRERERaQmtevJEUQghAADJycnFvm6ZTIb09HQkJydDX1+/2NevTZgr9TFX6mOu1MdcqY+5KpySylfu73bu73h5x8Lu/6WkpAAAnJ2dNRwJERERFVZKSgosLCw0HYbGSQRLXACAQqHA06dPYWZmBolEUqzrTk5OhrOzMx4/fgxzc/NiXbe2Ya7Ux1ypj7lSH3OlPuaqcEoqX0IIpKSkwMnJCTo6vMKMZ+z+n46ODipVqlSi72Fubs4vv5qYK/UxV+pjrtTHXKmPuSqcksgXz9T9D0tbIiIiIi3Bwo6IiIhIS7Cw+wCkUinmzJkDqVSq6VBKPeZKfcyV+pgr9TFX6mOuCof5+jB48wQRERGRluAZOyIiIiItwcKOiIiISEuwsCMiIiLSEizsiIiIiLQEC7sS5u/vjypVqsDQ0BDNmjXDxYsXNR2Sxvn5+aFJkyYwMzODnZ0d+vTpgzt37qjMk5mZCV9fX9jY2MDU1BT9+/dHbGyshiIuPRYvXgyJRIKJEycq25ir/4mOjsZnn30GGxsbGBkZoX79+rh06ZJyuhACs2fPhqOjI4yMjODl5YWIiAgNRqwZcrkcs2bNgqurK4yMjFCtWjUsWLBA5Vmb5TlXp06dQs+ePeHk5ASJRIK9e/eqTFcnNwkJCfD29oa5uTksLS0xatQopKamfsCt+DDeliuZTIZvvvkG9evXh4mJCZycnDB06FA8ffpUZR3lJVcfCgu7ErR9+3ZMnjwZc+bMQWhoKNzd3dGlSxfExcVpOjSNOnnyJHx9fXH+/HkEBQVBJpOhc+fOSEtLU84zadIk7Nu3Dzt37sTJkyfx9OlT9OvXT4NRa15ISAh+/vlnNGjQQKWduXrl5cuXaNWqFfT19XHw4EHcvHkTy5cvh5WVlXKepUuXYvXq1Vi/fj0uXLgAExMTdOnSBZmZmRqM/MNbsmQJ1q1bh59++gm3bt3CkiVLsHTpUqxZs0Y5T3nOVVpaGtzd3eHv75/vdHVy4+3tjRs3biAoKAj79+/HqVOn4OPj86E24YN5W67S09MRGhqKWbNmITQ0FH/++Sfu3LmDXr16qcxXXnL1wQgqMU2bNhW+vr7K13K5XDg5OQk/Pz8NRlX6xMXFCQDi5MmTQgghEhMThb6+vti5c6dynlu3bgkAIjg4WFNhalRKSopwc3MTQUFBol27dmLChAlCCObqdd98841o3bp1gdMVCoVwcHAQP/zwg7ItMTFRSKVSsXXr1g8RYqnRvXt3MXLkSJW2fv36CW9vbyEEc/U6AGLPnj3K1+rk5ubNmwKACAkJUc5z8OBBIZFIRHR09AeL/UN7M1f5uXjxogAgHj16JIQov7kqSTxjV0Kys7Nx+fJleHl5Kdt0dHTg5eWF4OBgDUZW+iQlJQEArK2tAQCXL1+GTCZTyV2tWrXg4uJSbnPn6+uL7t27q+QEYK5e9/fff6Nx48YYMGAA7Ozs0LBhQ2zcuFE5PTIyEjExMSq5srCwQLNmzcpdrlq2bImjR4/i7t27AIArV67gzJkz6Nq1KwDm6m3UyU1wcDAsLS3RuHFj5TxeXl7Q0dHBhQsXPnjMpUlSUhIkEgksLS0BMFclQU/TAWir+Ph4yOVy2Nvbq7Tb29vj9u3bGoqq9FEoFJg4cSJatWqFevXqAQBiYmJgYGCg/OLnsre3R0xMjAai1Kxt27YhNDQUISEheaYxV//z4MEDrFu3DpMnT8bMmTMREhKC8ePHw8DAAMOGDVPmI7/vZHnL1fTp05GcnIxatWpBV1cXcrkcixYtgre3NwAwV2+hTm5iYmJgZ2enMl1PTw/W1tblOn+ZmZn45ptvMHjwYJibmwNgrkoCCzvSKF9fX1y/fh1nzpzRdCil0uPHjzFhwgQEBQXB0NBQ0+GUagqFAo0bN8b3338PAGjYsCGuX7+O9evXY9iwYRqOrnTZsWMHAgICEBgYiLp16yI8PBwTJ06Ek5MTc0UlQiaTYeDAgRBCYN26dZoOR6uxK7aEVKhQAbq6unnuToyNjYWDg4OGoipdxo4di/379+P48eOoVKmSst3BwQHZ2dlITExUmb885u7y5cuIi4uDp6cn9PT0oKenh5MnT2L16tXQ09ODvb09c/X/HB0dUadOHZW22rVrIyoqCgCU+eB3Epg6dSqmT5+OQYMGoX79+vj8888xadIk+Pn5AWCu3kad3Dg4OOS5SS4nJwcJCQnlMn+5Rd2jR48QFBSkPFsHMFclgYVdCTEwMECjRo1w9OhRZZtCocDRo0fRokULDUameUIIjB07Fnv27MGxY8fg6uqqMr1Ro0bQ19dXyd2dO3cQFRVV7nLXsWNHXLt2DeHh4cq/xo0bw9vbW/lv5uqVVq1a5Rk25+7du6hcuTIAwNXVFQ4ODiq5Sk5OxoULF8pdrtLT06Gjo3r419XVhUKhAMBcvY06uWnRogUSExNx+fJl5TzHjh2DQqFAs2bNPnjMmpRb1EVERODIkSOwsbFRmc5clQBN372hzbZt2yakUqnYvHmzuHnzpvDx8RGWlpYiJiZG06Fp1FdffSUsLCzEiRMnxLNnz5R/6enpynm+/PJL4eLiIo4dOyYuXbokWrRoIVq0aKHBqEuP1++KFYK5ynXx4kWhp6cnFi1aJCIiIkRAQIAwNjYWW7ZsUc6zePFiYWlpKf766y9x9epV0bt3b+Hq6ioyMjI0GPmHN2zYMFGxYkWxf/9+ERkZKf78809RoUIFMW3aNOU85TlXKSkpIiwsTISFhQkAYsWKFSIsLEx5J6c6ufn4449Fw4YNxYULF8SZM2eEm5ubGDx4sKY2qcS8LVfZ2dmiV69eolKlSiI8PFzleJ+VlaVcR3nJ1YfCwq6ErVmzRri4uAgDAwPRtGlTcf78eU2HpHEA8v3btGmTcp6MjAwxZswYYWVlJYyNjUXfvn3Fs2fPNBd0KfJmYcdc/c++fftEvXr1hFQqFbVq1RIbNmxQma5QKMSsWbOEvb29kEqlomPHjuLOnTsailZzkpOTxYQJE4SLi4swNDQUVatWFd9++63Kj215ztXx48fzPUYNGzZMCKFebl68eCEGDx4sTE1Nhbm5uRgxYoRISUnRwNaUrLflKjIyssDj/fHjx5XrKC+5+lAkQrw21DgRERERlVm8xo6IiIhIS7CwIyIiItISLOyIiIiItAQLOyIiIiItwcKOiIiISEuwsCMiIiLSEizsiKjckslkmg6BiKhYsbAjonLjt99+w0cffQQXFxcYGxvj888/13RIRETFioUdEaFKlSpYuXKlStuJEycgkUiQmJiokZiK2+jRozFv3jyMHDkShw8fxtWrV7FhwwZNh0VEVKz0NB0AEVFJO336NPbs2YMrV67A0dFR0+EQEZUYnrEjIkgkknfOs3nzZlhaWqq0tW3bFhKJBOHh4cq2GzduoEePHjA3N4eZmRnatGmD+/fvK6fnngl8/e/19SoUCsyfPx+VKlWCVCqFh4cHDh069NbYsrKyMH78eNjZ2cHQ0BCtW7dGSEiIcvr+/ftRv359/Oc//4GlpSWsra0xfPhwJCUlAQCWLVumEs/evXsLfC+FQgE/Pz+4urrCyMgI7u7u2LVrV57tyz3T+fLlSzRo0ABDhw6FEALDhw/Ps/25f8OHD1dre17PoY6ODuzs7DBq1ChkZma+NU9EpP1Y2BERKlSogPj4+EIt8+effyIsLEylLTo6Gm3btoVUKsWxY8dw+fJljBw5Ejk5Ocp5ch9PfefOHTx79ixPF/CqVauwfPlyLFu2DFevXkWXLl3Qq1cvREREFBjLtGnTsHv3bvz+++8IDQ1F9erV0aVLFyQkJAAAnj9/jmPHjsHQ0BCnT5/G3r17cf78eYwcORIAMGbMGDx79gzPnj1753b7+fnhjz/+wPr163Hjxg1MmjQJn332GU6ePJln3tTUVHTr1g1Vq1bFb7/9BolEglWrVinfa+DAgRg4cKDy9apVq9Tanlx37txBdHQ0tmzZgu3bt2PTpk3vjJ+ItJwgonJv4sSJomrVquLRo0fKtuPHjwsA4uXLl0IIITZt2iQsLCyEEEJkZ2eL6tWriwULFggAIiwsTAghxIwZM4Srq6vIzs4u8L3+/fdfAUCkpqbmWa8QQjg5OYlFixapLNOkSRMxZsyYfNeXmpoq9PX1RUBAgLItOztbODk5iaVLlwohhBg2bJiwsrJSvqcQQpw+fVoAEBERESrrAyD27NmT73tlZmYKY2Njce7cOZX2UaNGicGDBwsh/pe3mJgY0bFjR/HRRx+JzMzMfNc3bNgwMWzYsEJvz5ufTUREhLCyslJZhojKJ56xIyJ89913qFKlCipXrgxTU1OYmpqia9euBc7v7+8PCwsLeHt7q7SHh4ejTZs20NfXL3DZ5ORk6OjowMjIKN9pT58+RatWrVTaW7VqhVu3buW7vvv370Mmk6kso6+vj6ZNm6os4+7uDhMTE+Xr5s2bQ1dXFzdv3syzzsGDB8PU1BQODg7o0qWL8szkvXv3kJ6ejk6dOinzZGpqij/++EOluxkAvL29cfToUbRr1w5SqbTAfLzv9gBApUqVYGJiAjc3N3Tr1g2DBw9W+32ISDvx5gkigo2NDY4ePYqXL1/ixYsXAIALFy7gs88+yzPvy5cvsWDBAuzZsyfPtXn5FWtvevr0Kezt7aGj8+H+X2llZYVHjx7lOy2/6wt//PFHeHl5ITk5GQsXLkSvXr3w+PFjpKamAgD++ecfVKxYUWWZN4u3mJgY7N69G0OGDEHfvn1Rv379Ytqa/zl9+jTMzMwQGRkJHx8frFixAl9//XWxvw8RlR08Y0dESlZWVqhevTqqV6+ep3DJtWDBArRp0wZt27bNM61BgwY4ffr0Wwf+DQkJQcOGDfOdZm5uDicnJ5w9e1al/ezZs6hTp06+y1SrVg0GBgYqy8hkMoSEhCiXqVWrFq5cuYK0tDTlPOfPn4dcLkft2rXzrNPBwQHVq1eHp6cnJk+ejCdPniA+Ph516tSBVCpFVFSUMk+5f87Ozirr+Pvvv9GvXz988cUXGDFihMp1hm+jzvbkcnV1RfXq1dGpUyf0798fe/bsUes9iEh78YwdEaktPT0dGzZsQGhoaL7Tx44dizVr1mDQoEGYMWMGLCwscP78eTRt2hQVK1bEL7/8gsDAQGzfvr3A95g6dSrmzJmDatWqwcPDA5s2bUJ4eDgCAgLynd/ExARfffUVpk6dCmtra7i4uGDp0qVIT0/HqFGjAABDhgzB7NmzMXToUMydOxeJiYnw8fFBv379UL169TzrTExMRExMDFJSUrB+/Xo4OjqiQoUKAIApU6Zg0qRJUCgUaN26NZKSknD27FmYm5tj2LBhynVYW1sDABYvXowGDRpg8eLF+O67796ZY3W2J1dcXBwyMzPx6NEj7Nu3D23atHnn+olIu7GwIyK1yWQyjB49GjVq1Mh3uo2NDY4dO4apU6eiXbt20NXVhYeHB1q1aoWgoCBs3LgRP//8Mz755JMC32P8+PFISkrC119/jbi4ONSpUwd///033NzcClxm8eLFUCgU+Pzzz5GSkoLGjRvj33//hZWVFQDAzMwMBw8exOTJk9GkSRMYGxujd+/eee7IzTVixAgAgKmpKTw8PFSGP1mwYAFsbW3h5+eHBw8ewNLSEp6enpg5c2a+6zIxMcFvv/2Gjz/+GH369EG9evUK3A51tydXzZo1Aby6q7lz585YunTpO9dNRNpNIsT/jz1ARERERGUar7EjIiIi0hIs7IiIiIi0BAs7IiIiIi3Bwo6IiIhIS7CwIyIiItISLOyIiIiItAQLOyIiIiItwcKOiIiISEuwsCMiIiLSEizsiIiIiLQECzsiIiIiLcHCjoiIiEhL/B9w+rrBSM2P/AAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Зависимость длительности обучения от числа объектов и признаков')\n",
        "\n",
        "plt.plot(np.array(list(new_history[10000].keys())), np.array(list(new_history[10000].values())),label=\"10000 objects\")\n",
        "# plt.plot(np.array(list(history[10].keys())) / 100000 * 0.5, np.array(list(history[10].values())),label=\"10 features\")\n",
        "# plt.plot(np.array(list(history[10].keys())) / 100000 * 0.5, np.array(list(history[10].values())),label=\"10 features\")\n",
        "# plt.plot(history[50].keys(), history[50].values(), label=\"50 features\")\n",
        "# plt.plot(history[100].keys(), history[100].values(), label=\"100 features\")\n",
        "plt.legend()\n",
        "# for alpha_i in range(alphas.shape[0]):\n",
        "#     for beta_i in range(betas.shape[0]):\n",
        "#         ax[alpha_i][beta_i].plot(range(1, len(history_al_bet_st_batch[0][0][alpha_i][beta_i]['func']) + 1),\n",
        "#                                  history_al_bet_st_batch[0][0][alpha_i][beta_i]['func'])\n",
        "#         ax[alpha_i][beta_i].set_title('step_alpha='+str(alphas[alpha_i])+', step_beta='+str(betas[beta_i]))\n",
        "#         ax[alpha_i][beta_i].set_xlabel('Номер эпохи')\n",
        "#         ax[alpha_i][beta_i].set_ylabel('Функция потери')\n",
        "#         ax[alpha_i][beta_i].grid()\n",
        "plt.ylabel('Время(с)')\n",
        "plt.xlabel('Число признаков')\n",
        "plt.grid()\n",
        "# fig.savefig('history_SGD_1_0.svg')\n",
        "# fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "nkiayKLIApFz",
        "outputId": "16ef520b-1eed-43ce-ca91-c3dd38f3819d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10000 объектов и 200 признаков -> 6 минут"
      ],
      "metadata": {
        "id": "7OIlnd7zV4rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\n",
        "    [1, 0.2, 0.3],\n",
        "    [0.2, 1, 0.8],\n",
        "    [0.3, 0.8, 1],\n",
        "])\n",
        "b = np.array([\n",
        "    [12, 0.2, 0.33],\n",
        "    [0.32, 31, 0.84],\n",
        "    [0.35, 0.38, 21],\n",
        "    [0.13, 0.18, -1],\n",
        "])\n",
        "c = np.concatenate([a[0] < 0.4, np.full((b.shape[1] - a.shape[0],), False)])\n",
        "b = np.concatenate([b, b.T[0].reshape(-1, 1) + b.T[c].T], axis=1)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dJKJE7_z7d_",
        "outputId": "f61494f6-ce5e-4748-fc9e-e708f3b434e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.  ,  0.2 ,  0.33, 12.2 , 12.33],\n",
              "       [ 0.32, 31.  ,  0.84, 31.32,  1.16],\n",
              "       [ 0.35,  0.38, 21.  ,  0.73, 21.35],\n",
              "       [ 0.13,  0.18, -1.  ,  0.31, -0.87]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([[1,0], [1, 1]]) + 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSkRXBowDbvE",
        "outputId": "e4889d1d-f023-4f97-e607-993065e2d061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2, 1],\n",
              "       [2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rE66J0OHIb6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHQM_DhjIbfB",
        "outputId": "20f05484-541e-4899-94f1-de8b13042dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.302585092994046"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,:2][a[:,:2] < 0.3] = 100"
      ],
      "metadata": {
        "id": "Im8mvyOoFxSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvZrQvYtH2jE",
        "outputId": "8f3f8460-e6e7-421b-e7f5-edacb7ac4713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1. , 0.2, 0. ],\n",
              "       [0. , 1. , 0. ],\n",
              "       [1. , 0.8, 0. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[[0, 1],[0, 1]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-agbMj4XNxc",
        "outputId": "157f5bbe-0943-4a64-c1f9-f62a71e7de33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([\n",
        "    [2, 0.2, 100],\n",
        "    [0, 1, 100],\n",
        "    [4, 0.8, 100],\n",
        "])"
      ],
      "metadata": {
        "id": "GHLMWHZ7X7gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,0].reshape(-1, 1) != 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1ZMjSXlK2RS",
        "outputId": "cb02fbf6-a8a5-4c04-d06d-bc4409d48ea4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [False],\n",
              "       [ True]])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,[10]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        },
        "id": "5-k1QkbkXvT8",
        "outputId": "0c1ccce8-be5b-4e02-d4fe-3b8443b93efc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-cb34dc91fd6c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 10 is out of bounds for axis 1 with size 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,[1]] + np.zeros(())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLhrYy_kRCQn",
        "outputId": "df61fc2b-0f95-45f5-d658-4dee126c3f73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.2],\n",
              "       [1. ],\n",
              "       [0.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[:,[0, 0]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEPuWmBBRjQY",
        "outputId": "d344ead2-3f89-4705-a133-468480ae8f03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2., 2.],\n",
              "       [0., 0.],\n",
              "       [4., 4.]])"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.repeat(a[:,[1]], 0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhFdojZIQf3c",
        "outputId": "c5640f18-014a-435f-8722-9df67f3822a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([], shape=(3, 0), dtype=float64)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.divide(np.repeat(a[:,1].reshape(-1, 1), a[:,[0, 2]].shape[1], axis=1), a[:,[0, 2]], out=np.repeat(a[:,1].reshape(-1, 1), a[:,[0, 2]].shape[1], axis=1), where=(a[:,[0, 2]] != 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI3CQgpiX-A0",
        "outputId": "0ce78dd4-c5eb-4199-fc41-2493931bc16f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1  , 0.002],\n",
              "       [1.   , 0.01 ],\n",
              "       [0.2  , 0.008]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.log(a, where=(a > 0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48tpavD9MVIP",
        "outputId": "85a6fc40-9a7f-46cc-e3de-2f4d034a9f1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  4.60517019, -1.2039728 ],\n",
              "       [ 4.60517019,  0.        , -0.22314355],\n",
              "       [-1.2039728 , -0.22314355,  0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a[0][0] = 0"
      ],
      "metadata": {
        "id": "f7uA0kslJEN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "8mDXB69EJIXR",
        "outputId": "10cebe2c-a50e-4ec0-dbe3-b82a37a0633e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-3f786850e387>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.where(a[:,:2] == 0, -10, (1/(a[:,:2][a[:,:2] != 0] =  1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "L9mQa4B9GGQR",
        "outputId": "4fab05fe-2f43-426e-c791-78aad460ac91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5c2d0c756296>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mwhere\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) () (5,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "c = np.concatenate([a[0] < 0.4, np.full((b.shape[1] - a.shape[0],), False)])\n",
        "b = np.concatenate([b, b.T[0].reshape(-1, 1) + b.T[c].T], axis=1)\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfijxHfD6HGR",
        "outputId": "8ec020ef-61ed-4aa8-8e11-d86315658d7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12.  ,  0.2 ,  0.33, 12.2 , 12.33, 12.2 , 12.33, 12.2 , 12.33,\n",
              "        12.2 , 12.33],\n",
              "       [ 0.32, 31.  ,  0.84, 31.32,  1.16, 31.32,  1.16, 31.32,  1.16,\n",
              "        31.32,  1.16],\n",
              "       [ 0.35,  0.38, 21.  ,  0.73, 21.35,  0.73, 21.35,  0.73, 21.35,\n",
              "         0.73, 21.35],\n",
              "       [ 0.13,  0.18, -1.  ,  0.31, -0.87,  0.31, -0.87,  0.31, -0.87,\n",
              "         0.31, -0.87]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corr = np.array([\n",
        "    [1.0, 0.2, 0],\n",
        "    [0.2, 1.0, 0.4],\n",
        "    [0, 0.4, 1.0],\n",
        "])\n",
        "x = np.array([\n",
        "    [0, 0, 10],\n",
        "    [1, -1, 20],\n",
        "    [12, 30, 33],\n",
        "    [100, 36, 443],\n",
        "])"
      ],
      "metadata": {
        "id": "ArYMQAlSyg2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "FeatureGenerationTransformer(thr=0.01, features_mask=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "yjMHSq-VvRXM",
        "outputId": "9918f87d-788b-4639-f0ec-de2867d0c445"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeatureGenerationTransformer(thr=0.01)"
            ],
            "text/html": [
              "<style>#sk-container-id-9 {color: black;background-color: white;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FeatureGenerationTransformer(thr=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureGenerationTransformer</label><div class=\"sk-toggleable__content\"><pre>FeatureGenerationTransformer(thr=0.01)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "   feat_gen = FeatureGenerationTransformer(thr=0.01)\n",
        "   feat_gen.fit(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ZfXi9pCdI5Cp",
        "outputId": "d699c42a-2569-403f-cb08-a7c08d5b5496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FeatureGenerationTransformer(features_mask=array([0, 1, 2]), thr=0.01)"
            ],
            "text/html": [
              "<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>FeatureGenerationTransformer(features_mask=array([0, 1, 2]), thr=0.01)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FeatureGenerationTransformer</label><div class=\"sk-toggleable__content\"><pre>FeatureGenerationTransformer(features_mask=array([0, 1, 2]), thr=0.01)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.corrcoef(x.T)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpkAWX3TJ76c",
        "outputId": "b788033d-3eef-4cc8-bd20-64583a56e55d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 0.75374649, 0.99730317],\n",
              "       [0.75374649, 1.        , 0.70375939],\n",
              "       [0.99730317, 0.70375939, 1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sub(arr):\n",
        "    return arr[-1] - arr[0]\n",
        "\n",
        "def div(arr):\n",
        "    if arr[0] == 0:\n",
        "        return arr[-1] / EPS\n",
        "    return arr[-1] / arr[0]"
      ],
      "metadata": {
        "id": "-Skjk0X-_gUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indxs_mat = np.array([[ [i,j] for j in range(3)] for i in range(3)])\n",
        "indxs_mat = indxs_mat[corr < 0.3]\n",
        "indxs_mat = indxs_mat[indxs_mat[:, 0] > indxs_mat[:, 1]]\n",
        "np.sum(x.T[indxs_mat], axis=1).T\n",
        "print(x.T[indxs_mat] - x.T[indxs_mat][:,::-1])\n",
        "print(\"---------------\")\n",
        "print(x.T[indxs_mat] / (x.T[indxs_mat][:,::-1] + EPS))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DB5-NM0H1RMx",
        "outputId": "bca72395-dd3d-41b6-d2fc-1d42468702c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[   0   -2   18  -64]\n",
            "  [   0    2  -18   64]]\n",
            "\n",
            " [[  10   19   21  343]\n",
            "  [ -10  -19  -21 -343]]]\n",
            "---------------\n",
            "[[[ 0.00000000e+00 -1.00000000e+00  2.50000000e+00  3.60000000e-01]\n",
            "  [ 0.00000000e+00 -1.00000000e+00  4.00000000e-01  2.77777778e+00]]\n",
            "\n",
            " [[ 1.00000000e+21  2.00000000e+01  2.75000000e+00  4.43000000e+00]\n",
            "  [ 0.00000000e+00  5.00000000e-02  3.63636364e-01  2.25733634e-01]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x.T[indxs_mat] - x.T[indxs_mat][:,::-1]).reshape(indxs_mat.shape[0] * 2, x.shape[0]).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNyQr8k2p_Qq",
        "outputId": "35a2b142-30eb-471d-d84c-bec6e0ba6e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,   10,  -10],\n",
              "       [  -2,    2,   19,  -19],\n",
              "       [  18,  -18,   21,  -21],\n",
              "       [ -64,   64,  343, -343]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x.T[indxs_mat] / (x.T[indxs_mat][:,::-1] + EPS)).reshape(indxs_mat.shape[0] * 2, x.shape[0]).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7pLFBs3arO6R",
        "outputId": "1f92602b-9e77-4bd3-b6a4-856360a43bbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.00000000e+00,  0.00000000e+00,  1.00000000e+21,\n",
              "         0.00000000e+00],\n",
              "       [-1.00000000e+00, -1.00000000e+00,  2.00000000e+01,\n",
              "         5.00000000e-02],\n",
              "       [ 2.50000000e+00,  4.00000000e-01,  2.75000000e+00,\n",
              "         3.63636364e-01],\n",
              "       [ 3.60000000e-01,  2.77777778e+00,  4.43000000e+00,\n",
              "         2.25733634e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.T[indxs_mat]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DtydJ3cpP9E",
        "outputId": "0fa50055-a337-40c2-d2be-5ae0738229b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[  0,  -1,  30,  36],\n",
              "        [  0,   1,  12, 100]],\n",
              "\n",
              "       [[ 10,  20,  33, 443],\n",
              "        [  0,   1,  12, 100]]])"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(x.T[indxs_mat], axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T4ErUo_orQT",
        "outputId": "3f50c7c3-277f-459b-c6fd-79c7adf7e82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,  42, 136],\n",
              "       [ 10,  21,  45, 543]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.apply_along_axis(sub, 1, x.T[indxs_mat]).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "ocX1vW5CBj2y",
        "outputId": "9008f12b-2597-4cb4-e1d1-0f8839b6e685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-60131905db5f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindxs_mat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         ) from None\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: sub() missing 1 required positional argument: 'b'"
          ]
        }
      ]
    }
  ]
}